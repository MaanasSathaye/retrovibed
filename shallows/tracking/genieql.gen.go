//go:build !genieql.ignore
// +build !genieql.ignore

package tracking

import (
	"context"
	"database/sql"
	"time"

	"github.com/gofrs/uuid/v5"
	"github.com/retrovibed/retrovibed/internal/ducktype"
	"github.com/retrovibed/retrovibed/internal/sqlx"
)

// DO NOT EDIT: This File was auto generated by the following command:
// genieql auto -v -o genieql.gen.go
// invoked by go generate @ tracking/10_generate.genieql.go line 3

// Metadata generated by genieql
//
//easyjson:json
type Metadata struct {
	Archivable      bool      `json:"archivable"`
	AutoDescription string    `json:"auto_description"`
	Bytes           uint64    `json:"bytes"`
	CreatedAt       time.Time `json:"created_at"`
	Description     string    `json:"description"`
	Downloaded      uint64    `json:"downloaded"`
	EncryptionSeed  string    `json:"encryption_seed"`
	HiddenAt        time.Time `json:"hidden_at"`
	ID              string    `json:"id"`
	Infohash        []byte    `json:"infohash"`
	InitiatedAt     time.Time `json:"initiated_at"`
	KnownMediaID    string    `json:"known_media_id"`
	NextAnnounceAt  time.Time `json:"next_announce_at"`
	PausedAt        time.Time `json:"paused_at"`
	Peers           uint16    `json:"peers"`
	Private         bool      `json:"private"`
	Seeding         bool      `json:"seeding"`
	Tracker         string    `json:"tracker"`
	UpdatedAt       time.Time `json:"updated_at"`
	Uploaded        uint64    `json:"uploaded"`
	VerifyAt        time.Time `json:"verify_at"`
}

// RSS generated by genieql
//
//easyjson:json
type RSS struct {
	Autoarchive    bool      `json:"autoarchive"`
	Autodownload   bool      `json:"autodownload"`
	Contributing   bool      `json:"contributing"`
	CreatedAt      time.Time `json:"created_at"`
	Description    string    `json:"description"`
	DisabledAt     time.Time `json:"disabled_at"`
	EncryptionSeed string    `json:"encryption_seed"`
	ID             string    `json:"id"`
	LastBuiltAt    time.Time `json:"last_built_at"`
	NextCheck      time.Time `json:"next_check"`
	UpdatedAt      time.Time `json:"updated_at"`
	URL            string    `json:"url"`
}

// UnknownHash generated by genieql
//
//easyjson:json
type UnknownHash struct {
	Attempts  uint64    `json:"attempts"`
	CreatedAt time.Time `json:"created_at"`
	ID        string    `json:"id"`
	Infohash  []byte    `json:"infohash"`
	NextCheck time.Time `json:"next_check"`
	UpdatedAt time.Time `json:"updated_at"`
}

// Peer generated by genieql
//
//easyjson:json
type Peer struct {
	Bep51          bool      `json:"bep_51"`
	Bep51Available uint64    `json:"bep_51_available"`
	Bep51TTL       uint16    `json:"bep_51_ttl"`
	CreatedAt      time.Time `json:"created_at"`
	ID             string    `json:"id"`
	IP             string    `json:"ip"`
	Network        string    `json:"network"`
	NextCheck      time.Time `json:"next_check"`
	Peer           []byte    `json:"peer"`
	Port           uint16    `json:"port"`
	UpdatedAt      time.Time `json:"updated_at"`
}

// MetadataScanner scanner interface.
type MetadataScanner interface {
	Scan(i *Metadata) error
	Next() bool
	Close() error
	Err() error
}

type errMetadataScanner struct {
	e error
}

func (t errMetadataScanner) Scan(i *Metadata) error {
	return t.e
}

func (t errMetadataScanner) Next() bool {
	return false
}

func (t errMetadataScanner) Err() error {
	return t.e
}

func (t errMetadataScanner) Close() error {
	return nil
}

// MetadataScannerStaticColumns generated by genieql
const MetadataScannerStaticColumns = `torrents_metadata."archivable",torrents_metadata."auto_description",torrents_metadata."bytes",torrents_metadata."created_at",torrents_metadata."description",torrents_metadata."downloaded",torrents_metadata."encryption_seed",torrents_metadata."hidden_at",torrents_metadata."id",torrents_metadata."infohash",torrents_metadata."initiated_at",torrents_metadata."known_media_id",torrents_metadata."next_announce_at",torrents_metadata."paused_at",torrents_metadata."peers",torrents_metadata."private",torrents_metadata."seeding",torrents_metadata."tracker",torrents_metadata."updated_at",torrents_metadata."uploaded",torrents_metadata."verify_at"`

// NewMetadataScannerStatic creates a scanner that operates on a static
// set of columns that are always returned in the same order.
func NewMetadataScannerStatic(rows *sql.Rows, err error) MetadataScanner {
	if err != nil {
		return errMetadataScanner{e: err}
	}

	return metadataScannerStatic{
		Rows: rows,
	}
}

// metadataScannerStatic generated by genieql
type metadataScannerStatic struct {
	Rows *sql.Rows `json:"rows"`
}

// Scan generated by genieql
func (t metadataScannerStatic) Scan(i *Metadata) error {
	var (
		c0  sql.NullBool
		c1  sql.NullString
		c2  ducktype.NullUint64
		c3  sql.NullTime
		c4  sql.NullString
		c5  ducktype.NullUint64
		c6  sql.NullString
		c7  sql.NullTime
		c8  sql.NullString
		c9  []byte
		c10 sql.NullTime
		c11 sql.NullString
		c12 sql.NullTime
		c13 sql.NullTime
		c14 sql.NullInt32
		c15 sql.NullBool
		c16 sql.NullBool
		c17 sql.NullString
		c18 sql.NullTime
		c19 ducktype.NullUint64
		c20 sql.NullTime
	)

	if err := t.Rows.Scan(&c0, &c1, &c2, &c3, &c4, &c5, &c6, &c7, &c8, &c9, &c10, &c11, &c12, &c13, &c14, &c15, &c16, &c17, &c18, &c19, &c20); err != nil {
		return err
	}

	if c0.Valid {
		tmp := c0.Bool
		i.Archivable = tmp
	}

	if c1.Valid {
		tmp := string(c1.String)
		i.AutoDescription = tmp
	}

	if c2.Valid {
		i.Bytes = c2.V
	}

	if c3.Valid {
		tmp := c3.Time
		i.CreatedAt = tmp
	}

	if c4.Valid {
		tmp := string(c4.String)
		i.Description = tmp
	}

	if c5.Valid {
		i.Downloaded = c5.V
	}

	if c6.Valid {
		if uid, err := uuid.FromBytes([]byte(c6.String)); err != nil {
			return err
		} else {
			i.EncryptionSeed = uid.String()
		}
	}

	if c7.Valid {
		tmp := c7.Time
		i.HiddenAt = tmp
	}

	if c8.Valid {
		if uid, err := uuid.FromBytes([]byte(c8.String)); err != nil {
			return err
		} else {
			i.ID = uid.String()
		}
	}

	i.Infohash = c9

	if c10.Valid {
		tmp := c10.Time
		i.InitiatedAt = tmp
	}

	if c11.Valid {
		if uid, err := uuid.FromBytes([]byte(c11.String)); err != nil {
			return err
		} else {
			i.KnownMediaID = uid.String()
		}
	}

	if c12.Valid {
		tmp := c12.Time
		i.NextAnnounceAt = tmp
	}

	if c13.Valid {
		tmp := c13.Time
		i.PausedAt = tmp
	}

	if c14.Valid {
		tmp := uint16(c14.Int32)
		i.Peers = tmp
	}

	if c15.Valid {
		tmp := c15.Bool
		i.Private = tmp
	}

	if c16.Valid {
		tmp := c16.Bool
		i.Seeding = tmp
	}

	if c17.Valid {
		tmp := string(c17.String)
		i.Tracker = tmp
	}

	if c18.Valid {
		tmp := c18.Time
		i.UpdatedAt = tmp
	}

	if c19.Valid {
		i.Uploaded = c19.V
	}

	if c20.Valid {
		tmp := c20.Time
		i.VerifyAt = tmp
	}

	return t.Rows.Err()
}

// Err generated by genieql
func (t metadataScannerStatic) Err() error {
	return t.Rows.Err()
}

// Close generated by genieql
func (t metadataScannerStatic) Close() error {
	if t.Rows == nil {
		return nil
	}
	return t.Rows.Close()
}

// Next generated by genieql
func (t metadataScannerStatic) Next() bool {
	return t.Rows.Next()
}

// NewMetadataScannerStaticRow creates a scanner that operates on a static
// set of columns that are always returned in the same order, only scans a single row.
func NewMetadataScannerStaticRow(row *sql.Row) MetadataScannerStaticRow {
	return MetadataScannerStaticRow{
		row: row,
	}
}

// MetadataScannerStaticRow generated by genieql
type MetadataScannerStaticRow struct {
	err error
	row *sql.Row
}

// Scan generated by genieql
func (t MetadataScannerStaticRow) Scan(i *Metadata) error {
	var (
		c0  sql.NullBool
		c1  sql.NullString
		c2  ducktype.NullUint64
		c3  sql.NullTime
		c4  sql.NullString
		c5  ducktype.NullUint64
		c6  sql.NullString
		c7  sql.NullTime
		c8  sql.NullString
		c9  []byte
		c10 sql.NullTime
		c11 sql.NullString
		c12 sql.NullTime
		c13 sql.NullTime
		c14 sql.NullInt32
		c15 sql.NullBool
		c16 sql.NullBool
		c17 sql.NullString
		c18 sql.NullTime
		c19 ducktype.NullUint64
		c20 sql.NullTime
	)

	if t.err != nil {
		return t.err
	}

	if err := t.row.Scan(&c0, &c1, &c2, &c3, &c4, &c5, &c6, &c7, &c8, &c9, &c10, &c11, &c12, &c13, &c14, &c15, &c16, &c17, &c18, &c19, &c20); err != nil {
		return err
	}

	if c0.Valid {
		tmp := c0.Bool
		i.Archivable = tmp
	}

	if c1.Valid {
		tmp := string(c1.String)
		i.AutoDescription = tmp
	}

	if c2.Valid {
		i.Bytes = c2.V
	}

	if c3.Valid {
		tmp := c3.Time
		i.CreatedAt = tmp
	}

	if c4.Valid {
		tmp := string(c4.String)
		i.Description = tmp
	}

	if c5.Valid {
		i.Downloaded = c5.V
	}

	if c6.Valid {
		if uid, err := uuid.FromBytes([]byte(c6.String)); err != nil {
			return err
		} else {
			i.EncryptionSeed = uid.String()
		}
	}

	if c7.Valid {
		tmp := c7.Time
		i.HiddenAt = tmp
	}

	if c8.Valid {
		if uid, err := uuid.FromBytes([]byte(c8.String)); err != nil {
			return err
		} else {
			i.ID = uid.String()
		}
	}

	i.Infohash = c9

	if c10.Valid {
		tmp := c10.Time
		i.InitiatedAt = tmp
	}

	if c11.Valid {
		if uid, err := uuid.FromBytes([]byte(c11.String)); err != nil {
			return err
		} else {
			i.KnownMediaID = uid.String()
		}
	}

	if c12.Valid {
		tmp := c12.Time
		i.NextAnnounceAt = tmp
	}

	if c13.Valid {
		tmp := c13.Time
		i.PausedAt = tmp
	}

	if c14.Valid {
		tmp := uint16(c14.Int32)
		i.Peers = tmp
	}

	if c15.Valid {
		tmp := c15.Bool
		i.Private = tmp
	}

	if c16.Valid {
		tmp := c16.Bool
		i.Seeding = tmp
	}

	if c17.Valid {
		tmp := string(c17.String)
		i.Tracker = tmp
	}

	if c18.Valid {
		tmp := c18.Time
		i.UpdatedAt = tmp
	}

	if c19.Valid {
		i.Uploaded = c19.V
	}

	if c20.Valid {
		tmp := c20.Time
		i.VerifyAt = tmp
	}

	return nil
}

// Err set an error to return by scan
func (t MetadataScannerStaticRow) Err(err error) MetadataScannerStaticRow {
	t.err = err
	return t
}

// NewMetadataScannerDynamic creates a scanner that operates on a dynamic
// set of columns that can be returned in any subset/order.
func NewMetadataScannerDynamic(rows *sql.Rows, err error) MetadataScanner {
	if err != nil {
		return errMetadataScanner{e: err}
	}

	return metadataScannerDynamic{
		Rows: rows,
	}
}

// metadataScannerDynamic generated by genieql
type metadataScannerDynamic struct {
	Rows *sql.Rows `json:"rows"`
}

// Scan generated by genieql
func (t metadataScannerDynamic) Scan(i *Metadata) error {
	const (
		cn0  = "archivable"
		cn1  = "auto_description"
		cn2  = "bytes"
		cn3  = "created_at"
		cn4  = "description"
		cn5  = "downloaded"
		cn6  = "encryption_seed"
		cn7  = "hidden_at"
		cn8  = "id"
		cn9  = "infohash"
		cn10 = "initiated_at"
		cn11 = "known_media_id"
		cn12 = "next_announce_at"
		cn13 = "paused_at"
		cn14 = "peers"
		cn15 = "private"
		cn16 = "seeding"
		cn17 = "tracker"
		cn18 = "updated_at"
		cn19 = "uploaded"
		cn20 = "verify_at"
	)
	var (
		ignored sql.RawBytes
		err     error
		columns []string
		dst     []interface{}
		c0      sql.NullBool
		c1      sql.NullString
		c2      ducktype.NullUint64
		c3      sql.NullTime
		c4      sql.NullString
		c5      ducktype.NullUint64
		c6      sql.NullString
		c7      sql.NullTime
		c8      sql.NullString
		c9      []byte
		c10     sql.NullTime
		c11     sql.NullString
		c12     sql.NullTime
		c13     sql.NullTime
		c14     sql.NullInt32
		c15     sql.NullBool
		c16     sql.NullBool
		c17     sql.NullString
		c18     sql.NullTime
		c19     ducktype.NullUint64
		c20     sql.NullTime
	)

	if columns, err = t.Rows.Columns(); err != nil {
		return err
	}

	dst = make([]interface{}, 0, len(columns))

	for _, column := range columns {
		switch column {
		case cn0:
			dst = append(dst, &c0)
		case cn1:
			dst = append(dst, &c1)
		case cn2:
			dst = append(dst, &c2)
		case cn3:
			dst = append(dst, &c3)
		case cn4:
			dst = append(dst, &c4)
		case cn5:
			dst = append(dst, &c5)
		case cn6:
			dst = append(dst, &c6)
		case cn7:
			dst = append(dst, &c7)
		case cn8:
			dst = append(dst, &c8)
		case cn9:
			dst = append(dst, &c9)
		case cn10:
			dst = append(dst, &c10)
		case cn11:
			dst = append(dst, &c11)
		case cn12:
			dst = append(dst, &c12)
		case cn13:
			dst = append(dst, &c13)
		case cn14:
			dst = append(dst, &c14)
		case cn15:
			dst = append(dst, &c15)
		case cn16:
			dst = append(dst, &c16)
		case cn17:
			dst = append(dst, &c17)
		case cn18:
			dst = append(dst, &c18)
		case cn19:
			dst = append(dst, &c19)
		case cn20:
			dst = append(dst, &c20)
		default:
			dst = append(dst, &ignored)
		}
	}

	if err := t.Rows.Scan(dst...); err != nil {
		return err
	}

	for _, column := range columns {
		switch column {
		case cn0:
			if c0.Valid {
				tmp := c0.Bool
				i.Archivable = tmp
			}

		case cn1:
			if c1.Valid {
				tmp := string(c1.String)
				i.AutoDescription = tmp
			}

		case cn2:
			if c2.Valid {
				i.Bytes = c2.V
			}

		case cn3:
			if c3.Valid {
				tmp := c3.Time
				i.CreatedAt = tmp
			}

		case cn4:
			if c4.Valid {
				tmp := string(c4.String)
				i.Description = tmp
			}

		case cn5:
			if c5.Valid {
				i.Downloaded = c5.V
			}

		case cn6:
			if c6.Valid {
				if uid, err := uuid.FromBytes([]byte(c6.String)); err != nil {
					return err
				} else {
					i.EncryptionSeed = uid.String()
				}
			}

		case cn7:
			if c7.Valid {
				tmp := c7.Time
				i.HiddenAt = tmp
			}

		case cn8:
			if c8.Valid {
				if uid, err := uuid.FromBytes([]byte(c8.String)); err != nil {
					return err
				} else {
					i.ID = uid.String()
				}
			}

		case cn9:
			i.Infohash = c9

		case cn10:
			if c10.Valid {
				tmp := c10.Time
				i.InitiatedAt = tmp
			}

		case cn11:
			if c11.Valid {
				if uid, err := uuid.FromBytes([]byte(c11.String)); err != nil {
					return err
				} else {
					i.KnownMediaID = uid.String()
				}
			}

		case cn12:
			if c12.Valid {
				tmp := c12.Time
				i.NextAnnounceAt = tmp
			}

		case cn13:
			if c13.Valid {
				tmp := c13.Time
				i.PausedAt = tmp
			}

		case cn14:
			if c14.Valid {
				tmp := uint16(c14.Int32)
				i.Peers = tmp
			}

		case cn15:
			if c15.Valid {
				tmp := c15.Bool
				i.Private = tmp
			}

		case cn16:
			if c16.Valid {
				tmp := c16.Bool
				i.Seeding = tmp
			}

		case cn17:
			if c17.Valid {
				tmp := string(c17.String)
				i.Tracker = tmp
			}

		case cn18:
			if c18.Valid {
				tmp := c18.Time
				i.UpdatedAt = tmp
			}

		case cn19:
			if c19.Valid {
				i.Uploaded = c19.V
			}

		case cn20:
			if c20.Valid {
				tmp := c20.Time
				i.VerifyAt = tmp
			}

		}
	}

	return t.Rows.Err()
}

// Err generated by genieql
func (t metadataScannerDynamic) Err() error {
	return t.Rows.Err()
}

// Close generated by genieql
func (t metadataScannerDynamic) Close() error {
	if t.Rows == nil {
		return nil
	}
	return t.Rows.Close()
}

// Next generated by genieql
func (t metadataScannerDynamic) Next() bool {
	return t.Rows.Next()
}

// RSSScanner scanner interface.
type RSSScanner interface {
	Scan(i *RSS) error
	Next() bool
	Close() error
	Err() error
}

type errRSSScanner struct {
	e error
}

func (t errRSSScanner) Scan(i *RSS) error {
	return t.e
}

func (t errRSSScanner) Next() bool {
	return false
}

func (t errRSSScanner) Err() error {
	return t.e
}

func (t errRSSScanner) Close() error {
	return nil
}

// RSSScannerStaticColumns generated by genieql
const RSSScannerStaticColumns = `torrents_feed_rss."autoarchive",torrents_feed_rss."autodownload",torrents_feed_rss."contributing",torrents_feed_rss."created_at",torrents_feed_rss."description",torrents_feed_rss."disabled_at",torrents_feed_rss."encryption_seed",torrents_feed_rss."id",torrents_feed_rss."last_built_at",torrents_feed_rss."next_check",torrents_feed_rss."updated_at",torrents_feed_rss."url"`

// NewRSSScannerStatic creates a scanner that operates on a static
// set of columns that are always returned in the same order.
func NewRSSScannerStatic(rows *sql.Rows, err error) RSSScanner {
	if err != nil {
		return errRSSScanner{e: err}
	}

	return rSSScannerStatic{
		Rows: rows,
	}
}

// rSSScannerStatic generated by genieql
type rSSScannerStatic struct {
	Rows *sql.Rows `json:"rows"`
}

// Scan generated by genieql
func (t rSSScannerStatic) Scan(i *RSS) error {
	var (
		c0  sql.NullBool
		c1  sql.NullBool
		c2  sql.NullBool
		c3  sql.NullTime
		c4  sql.NullString
		c5  sql.NullTime
		c6  sql.NullString
		c7  sql.NullString
		c8  sql.NullTime
		c9  sql.NullTime
		c10 sql.NullTime
		c11 sql.NullString
	)

	if err := t.Rows.Scan(&c0, &c1, &c2, &c3, &c4, &c5, &c6, &c7, &c8, &c9, &c10, &c11); err != nil {
		return err
	}

	if c0.Valid {
		tmp := c0.Bool
		i.Autoarchive = tmp
	}

	if c1.Valid {
		tmp := c1.Bool
		i.Autodownload = tmp
	}

	if c2.Valid {
		tmp := c2.Bool
		i.Contributing = tmp
	}

	if c3.Valid {
		tmp := c3.Time
		i.CreatedAt = tmp
	}

	if c4.Valid {
		tmp := string(c4.String)
		i.Description = tmp
	}

	if c5.Valid {
		tmp := c5.Time
		i.DisabledAt = tmp
	}

	if c6.Valid {
		if uid, err := uuid.FromBytes([]byte(c6.String)); err != nil {
			return err
		} else {
			i.EncryptionSeed = uid.String()
		}
	}

	if c7.Valid {
		if uid, err := uuid.FromBytes([]byte(c7.String)); err != nil {
			return err
		} else {
			i.ID = uid.String()
		}
	}

	if c8.Valid {
		tmp := c8.Time
		i.LastBuiltAt = tmp
	}

	if c9.Valid {
		tmp := c9.Time
		i.NextCheck = tmp
	}

	if c10.Valid {
		tmp := c10.Time
		i.UpdatedAt = tmp
	}

	if c11.Valid {
		tmp := string(c11.String)
		i.URL = tmp
	}

	return t.Rows.Err()
}

// Err generated by genieql
func (t rSSScannerStatic) Err() error {
	return t.Rows.Err()
}

// Close generated by genieql
func (t rSSScannerStatic) Close() error {
	if t.Rows == nil {
		return nil
	}
	return t.Rows.Close()
}

// Next generated by genieql
func (t rSSScannerStatic) Next() bool {
	return t.Rows.Next()
}

// NewRSSScannerStaticRow creates a scanner that operates on a static
// set of columns that are always returned in the same order, only scans a single row.
func NewRSSScannerStaticRow(row *sql.Row) RSSScannerStaticRow {
	return RSSScannerStaticRow{
		row: row,
	}
}

// RSSScannerStaticRow generated by genieql
type RSSScannerStaticRow struct {
	err error
	row *sql.Row
}

// Scan generated by genieql
func (t RSSScannerStaticRow) Scan(i *RSS) error {
	var (
		c0  sql.NullBool
		c1  sql.NullBool
		c2  sql.NullBool
		c3  sql.NullTime
		c4  sql.NullString
		c5  sql.NullTime
		c6  sql.NullString
		c7  sql.NullString
		c8  sql.NullTime
		c9  sql.NullTime
		c10 sql.NullTime
		c11 sql.NullString
	)

	if t.err != nil {
		return t.err
	}

	if err := t.row.Scan(&c0, &c1, &c2, &c3, &c4, &c5, &c6, &c7, &c8, &c9, &c10, &c11); err != nil {
		return err
	}

	if c0.Valid {
		tmp := c0.Bool
		i.Autoarchive = tmp
	}

	if c1.Valid {
		tmp := c1.Bool
		i.Autodownload = tmp
	}

	if c2.Valid {
		tmp := c2.Bool
		i.Contributing = tmp
	}

	if c3.Valid {
		tmp := c3.Time
		i.CreatedAt = tmp
	}

	if c4.Valid {
		tmp := string(c4.String)
		i.Description = tmp
	}

	if c5.Valid {
		tmp := c5.Time
		i.DisabledAt = tmp
	}

	if c6.Valid {
		if uid, err := uuid.FromBytes([]byte(c6.String)); err != nil {
			return err
		} else {
			i.EncryptionSeed = uid.String()
		}
	}

	if c7.Valid {
		if uid, err := uuid.FromBytes([]byte(c7.String)); err != nil {
			return err
		} else {
			i.ID = uid.String()
		}
	}

	if c8.Valid {
		tmp := c8.Time
		i.LastBuiltAt = tmp
	}

	if c9.Valid {
		tmp := c9.Time
		i.NextCheck = tmp
	}

	if c10.Valid {
		tmp := c10.Time
		i.UpdatedAt = tmp
	}

	if c11.Valid {
		tmp := string(c11.String)
		i.URL = tmp
	}

	return nil
}

// Err set an error to return by scan
func (t RSSScannerStaticRow) Err(err error) RSSScannerStaticRow {
	t.err = err
	return t
}

// NewRSSScannerDynamic creates a scanner that operates on a dynamic
// set of columns that can be returned in any subset/order.
func NewRSSScannerDynamic(rows *sql.Rows, err error) RSSScanner {
	if err != nil {
		return errRSSScanner{e: err}
	}

	return rSSScannerDynamic{
		Rows: rows,
	}
}

// rSSScannerDynamic generated by genieql
type rSSScannerDynamic struct {
	Rows *sql.Rows `json:"rows"`
}

// Scan generated by genieql
func (t rSSScannerDynamic) Scan(i *RSS) error {
	const (
		cn0  = "autoarchive"
		cn1  = "autodownload"
		cn2  = "contributing"
		cn3  = "created_at"
		cn4  = "description"
		cn5  = "disabled_at"
		cn6  = "encryption_seed"
		cn7  = "id"
		cn8  = "last_built_at"
		cn9  = "next_check"
		cn10 = "updated_at"
		cn11 = "url"
	)
	var (
		ignored sql.RawBytes
		err     error
		columns []string
		dst     []interface{}
		c0      sql.NullBool
		c1      sql.NullBool
		c2      sql.NullBool
		c3      sql.NullTime
		c4      sql.NullString
		c5      sql.NullTime
		c6      sql.NullString
		c7      sql.NullString
		c8      sql.NullTime
		c9      sql.NullTime
		c10     sql.NullTime
		c11     sql.NullString
	)

	if columns, err = t.Rows.Columns(); err != nil {
		return err
	}

	dst = make([]interface{}, 0, len(columns))

	for _, column := range columns {
		switch column {
		case cn0:
			dst = append(dst, &c0)
		case cn1:
			dst = append(dst, &c1)
		case cn2:
			dst = append(dst, &c2)
		case cn3:
			dst = append(dst, &c3)
		case cn4:
			dst = append(dst, &c4)
		case cn5:
			dst = append(dst, &c5)
		case cn6:
			dst = append(dst, &c6)
		case cn7:
			dst = append(dst, &c7)
		case cn8:
			dst = append(dst, &c8)
		case cn9:
			dst = append(dst, &c9)
		case cn10:
			dst = append(dst, &c10)
		case cn11:
			dst = append(dst, &c11)
		default:
			dst = append(dst, &ignored)
		}
	}

	if err := t.Rows.Scan(dst...); err != nil {
		return err
	}

	for _, column := range columns {
		switch column {
		case cn0:
			if c0.Valid {
				tmp := c0.Bool
				i.Autoarchive = tmp
			}

		case cn1:
			if c1.Valid {
				tmp := c1.Bool
				i.Autodownload = tmp
			}

		case cn2:
			if c2.Valid {
				tmp := c2.Bool
				i.Contributing = tmp
			}

		case cn3:
			if c3.Valid {
				tmp := c3.Time
				i.CreatedAt = tmp
			}

		case cn4:
			if c4.Valid {
				tmp := string(c4.String)
				i.Description = tmp
			}

		case cn5:
			if c5.Valid {
				tmp := c5.Time
				i.DisabledAt = tmp
			}

		case cn6:
			if c6.Valid {
				if uid, err := uuid.FromBytes([]byte(c6.String)); err != nil {
					return err
				} else {
					i.EncryptionSeed = uid.String()
				}
			}

		case cn7:
			if c7.Valid {
				if uid, err := uuid.FromBytes([]byte(c7.String)); err != nil {
					return err
				} else {
					i.ID = uid.String()
				}
			}

		case cn8:
			if c8.Valid {
				tmp := c8.Time
				i.LastBuiltAt = tmp
			}

		case cn9:
			if c9.Valid {
				tmp := c9.Time
				i.NextCheck = tmp
			}

		case cn10:
			if c10.Valid {
				tmp := c10.Time
				i.UpdatedAt = tmp
			}

		case cn11:
			if c11.Valid {
				tmp := string(c11.String)
				i.URL = tmp
			}

		}
	}

	return t.Rows.Err()
}

// Err generated by genieql
func (t rSSScannerDynamic) Err() error {
	return t.Rows.Err()
}

// Close generated by genieql
func (t rSSScannerDynamic) Close() error {
	if t.Rows == nil {
		return nil
	}
	return t.Rows.Close()
}

// Next generated by genieql
func (t rSSScannerDynamic) Next() bool {
	return t.Rows.Next()
}

// UnknownHashScanner scanner interface.
type UnknownHashScanner interface {
	Scan(i *UnknownHash) error
	Next() bool
	Close() error
	Err() error
}

type errUnknownHashScanner struct {
	e error
}

func (t errUnknownHashScanner) Scan(i *UnknownHash) error {
	return t.e
}

func (t errUnknownHashScanner) Next() bool {
	return false
}

func (t errUnknownHashScanner) Err() error {
	return t.e
}

func (t errUnknownHashScanner) Close() error {
	return nil
}

// UnknownHashScannerStaticColumns generated by genieql
const UnknownHashScannerStaticColumns = `torrents_unknown_infohashes."attempts",torrents_unknown_infohashes."created_at",torrents_unknown_infohashes."id",torrents_unknown_infohashes."infohash",torrents_unknown_infohashes."next_check",torrents_unknown_infohashes."updated_at"`

// NewUnknownHashScannerStatic creates a scanner that operates on a static
// set of columns that are always returned in the same order.
func NewUnknownHashScannerStatic(rows *sql.Rows, err error) UnknownHashScanner {
	if err != nil {
		return errUnknownHashScanner{e: err}
	}

	return unknownHashScannerStatic{
		Rows: rows,
	}
}

// unknownHashScannerStatic generated by genieql
type unknownHashScannerStatic struct {
	Rows *sql.Rows `json:"rows"`
}

// Scan generated by genieql
func (t unknownHashScannerStatic) Scan(i *UnknownHash) error {
	var (
		c0 ducktype.NullUint64
		c1 sql.NullTime
		c2 sql.NullString
		c3 []byte
		c4 sql.NullTime
		c5 sql.NullTime
	)

	if err := t.Rows.Scan(&c0, &c1, &c2, &c3, &c4, &c5); err != nil {
		return err
	}

	if c0.Valid {
		i.Attempts = c0.V
	}

	if c1.Valid {
		tmp := c1.Time
		i.CreatedAt = tmp
	}

	if c2.Valid {
		if uid, err := uuid.FromBytes([]byte(c2.String)); err != nil {
			return err
		} else {
			i.ID = uid.String()
		}
	}

	i.Infohash = c3

	if c4.Valid {
		tmp := c4.Time
		i.NextCheck = tmp
	}

	if c5.Valid {
		tmp := c5.Time
		i.UpdatedAt = tmp
	}

	return t.Rows.Err()
}

// Err generated by genieql
func (t unknownHashScannerStatic) Err() error {
	return t.Rows.Err()
}

// Close generated by genieql
func (t unknownHashScannerStatic) Close() error {
	if t.Rows == nil {
		return nil
	}
	return t.Rows.Close()
}

// Next generated by genieql
func (t unknownHashScannerStatic) Next() bool {
	return t.Rows.Next()
}

// NewUnknownHashScannerStaticRow creates a scanner that operates on a static
// set of columns that are always returned in the same order, only scans a single row.
func NewUnknownHashScannerStaticRow(row *sql.Row) UnknownHashScannerStaticRow {
	return UnknownHashScannerStaticRow{
		row: row,
	}
}

// UnknownHashScannerStaticRow generated by genieql
type UnknownHashScannerStaticRow struct {
	err error
	row *sql.Row
}

// Scan generated by genieql
func (t UnknownHashScannerStaticRow) Scan(i *UnknownHash) error {
	var (
		c0 ducktype.NullUint64
		c1 sql.NullTime
		c2 sql.NullString
		c3 []byte
		c4 sql.NullTime
		c5 sql.NullTime
	)

	if t.err != nil {
		return t.err
	}

	if err := t.row.Scan(&c0, &c1, &c2, &c3, &c4, &c5); err != nil {
		return err
	}

	if c0.Valid {
		i.Attempts = c0.V
	}

	if c1.Valid {
		tmp := c1.Time
		i.CreatedAt = tmp
	}

	if c2.Valid {
		if uid, err := uuid.FromBytes([]byte(c2.String)); err != nil {
			return err
		} else {
			i.ID = uid.String()
		}
	}

	i.Infohash = c3

	if c4.Valid {
		tmp := c4.Time
		i.NextCheck = tmp
	}

	if c5.Valid {
		tmp := c5.Time
		i.UpdatedAt = tmp
	}

	return nil
}

// Err set an error to return by scan
func (t UnknownHashScannerStaticRow) Err(err error) UnknownHashScannerStaticRow {
	t.err = err
	return t
}

// NewUnknownHashScannerDynamic creates a scanner that operates on a dynamic
// set of columns that can be returned in any subset/order.
func NewUnknownHashScannerDynamic(rows *sql.Rows, err error) UnknownHashScanner {
	if err != nil {
		return errUnknownHashScanner{e: err}
	}

	return unknownHashScannerDynamic{
		Rows: rows,
	}
}

// unknownHashScannerDynamic generated by genieql
type unknownHashScannerDynamic struct {
	Rows *sql.Rows `json:"rows"`
}

// Scan generated by genieql
func (t unknownHashScannerDynamic) Scan(i *UnknownHash) error {
	const (
		cn0 = "attempts"
		cn1 = "created_at"
		cn2 = "id"
		cn3 = "infohash"
		cn4 = "next_check"
		cn5 = "updated_at"
	)
	var (
		ignored sql.RawBytes
		err     error
		columns []string
		dst     []interface{}
		c0      ducktype.NullUint64
		c1      sql.NullTime
		c2      sql.NullString
		c3      []byte
		c4      sql.NullTime
		c5      sql.NullTime
	)

	if columns, err = t.Rows.Columns(); err != nil {
		return err
	}

	dst = make([]interface{}, 0, len(columns))

	for _, column := range columns {
		switch column {
		case cn0:
			dst = append(dst, &c0)
		case cn1:
			dst = append(dst, &c1)
		case cn2:
			dst = append(dst, &c2)
		case cn3:
			dst = append(dst, &c3)
		case cn4:
			dst = append(dst, &c4)
		case cn5:
			dst = append(dst, &c5)
		default:
			dst = append(dst, &ignored)
		}
	}

	if err := t.Rows.Scan(dst...); err != nil {
		return err
	}

	for _, column := range columns {
		switch column {
		case cn0:
			if c0.Valid {
				i.Attempts = c0.V
			}

		case cn1:
			if c1.Valid {
				tmp := c1.Time
				i.CreatedAt = tmp
			}

		case cn2:
			if c2.Valid {
				if uid, err := uuid.FromBytes([]byte(c2.String)); err != nil {
					return err
				} else {
					i.ID = uid.String()
				}
			}

		case cn3:
			i.Infohash = c3

		case cn4:
			if c4.Valid {
				tmp := c4.Time
				i.NextCheck = tmp
			}

		case cn5:
			if c5.Valid {
				tmp := c5.Time
				i.UpdatedAt = tmp
			}

		}
	}

	return t.Rows.Err()
}

// Err generated by genieql
func (t unknownHashScannerDynamic) Err() error {
	return t.Rows.Err()
}

// Close generated by genieql
func (t unknownHashScannerDynamic) Close() error {
	if t.Rows == nil {
		return nil
	}
	return t.Rows.Close()
}

// Next generated by genieql
func (t unknownHashScannerDynamic) Next() bool {
	return t.Rows.Next()
}

// PeerScanner scanner interface.
type PeerScanner interface {
	Scan(i *Peer) error
	Next() bool
	Close() error
	Err() error
}

type errPeerScanner struct {
	e error
}

func (t errPeerScanner) Scan(i *Peer) error {
	return t.e
}

func (t errPeerScanner) Next() bool {
	return false
}

func (t errPeerScanner) Err() error {
	return t.e
}

func (t errPeerScanner) Close() error {
	return nil
}

// PeerScannerStaticColumns generated by genieql
const PeerScannerStaticColumns = `torrents_peers."bep51",torrents_peers."bep51_available",torrents_peers."bep51_ttl",torrents_peers."created_at",torrents_peers."id",torrents_peers."ip",torrents_peers."network",torrents_peers."next_check",torrents_peers."peer",torrents_peers."port",torrents_peers."updated_at"`

// NewPeerScannerStatic creates a scanner that operates on a static
// set of columns that are always returned in the same order.
func NewPeerScannerStatic(rows *sql.Rows, err error) PeerScanner {
	if err != nil {
		return errPeerScanner{e: err}
	}

	return peerScannerStatic{
		Rows: rows,
	}
}

// peerScannerStatic generated by genieql
type peerScannerStatic struct {
	Rows *sql.Rows `json:"rows"`
}

// Scan generated by genieql
func (t peerScannerStatic) Scan(i *Peer) error {
	var (
		c0  sql.NullBool
		c1  ducktype.NullUint64
		c2  sql.NullInt32
		c3  sql.NullTime
		c4  sql.NullString
		c5  sql.NullString
		c6  sql.NullString
		c7  sql.NullTime
		c8  []byte
		c9  sql.NullInt32
		c10 sql.NullTime
	)

	if err := t.Rows.Scan(&c0, &c1, &c2, &c3, &c4, &c5, &c6, &c7, &c8, &c9, &c10); err != nil {
		return err
	}

	if c0.Valid {
		tmp := c0.Bool
		i.Bep51 = tmp
	}

	if c1.Valid {
		i.Bep51Available = c1.V
	}

	if c2.Valid {
		tmp := uint16(c2.Int32)
		i.Bep51TTL = tmp
	}

	if c3.Valid {
		tmp := c3.Time
		i.CreatedAt = tmp
	}

	if c4.Valid {
		if uid, err := uuid.FromBytes([]byte(c4.String)); err != nil {
			return err
		} else {
			i.ID = uid.String()
		}
	}

	if c5.Valid {
		tmp := string(c5.String)
		i.IP = tmp
	}

	if c6.Valid {
		tmp := string(c6.String)
		i.Network = tmp
	}

	if c7.Valid {
		tmp := c7.Time
		i.NextCheck = tmp
	}

	i.Peer = c8

	if c9.Valid {
		tmp := uint16(c9.Int32)
		i.Port = tmp
	}

	if c10.Valid {
		tmp := c10.Time
		i.UpdatedAt = tmp
	}

	return t.Rows.Err()
}

// Err generated by genieql
func (t peerScannerStatic) Err() error {
	return t.Rows.Err()
}

// Close generated by genieql
func (t peerScannerStatic) Close() error {
	if t.Rows == nil {
		return nil
	}
	return t.Rows.Close()
}

// Next generated by genieql
func (t peerScannerStatic) Next() bool {
	return t.Rows.Next()
}

// NewPeerScannerStaticRow creates a scanner that operates on a static
// set of columns that are always returned in the same order, only scans a single row.
func NewPeerScannerStaticRow(row *sql.Row) PeerScannerStaticRow {
	return PeerScannerStaticRow{
		row: row,
	}
}

// PeerScannerStaticRow generated by genieql
type PeerScannerStaticRow struct {
	err error
	row *sql.Row
}

// Scan generated by genieql
func (t PeerScannerStaticRow) Scan(i *Peer) error {
	var (
		c0  sql.NullBool
		c1  ducktype.NullUint64
		c2  sql.NullInt32
		c3  sql.NullTime
		c4  sql.NullString
		c5  sql.NullString
		c6  sql.NullString
		c7  sql.NullTime
		c8  []byte
		c9  sql.NullInt32
		c10 sql.NullTime
	)

	if t.err != nil {
		return t.err
	}

	if err := t.row.Scan(&c0, &c1, &c2, &c3, &c4, &c5, &c6, &c7, &c8, &c9, &c10); err != nil {
		return err
	}

	if c0.Valid {
		tmp := c0.Bool
		i.Bep51 = tmp
	}

	if c1.Valid {
		i.Bep51Available = c1.V
	}

	if c2.Valid {
		tmp := uint16(c2.Int32)
		i.Bep51TTL = tmp
	}

	if c3.Valid {
		tmp := c3.Time
		i.CreatedAt = tmp
	}

	if c4.Valid {
		if uid, err := uuid.FromBytes([]byte(c4.String)); err != nil {
			return err
		} else {
			i.ID = uid.String()
		}
	}

	if c5.Valid {
		tmp := string(c5.String)
		i.IP = tmp
	}

	if c6.Valid {
		tmp := string(c6.String)
		i.Network = tmp
	}

	if c7.Valid {
		tmp := c7.Time
		i.NextCheck = tmp
	}

	i.Peer = c8

	if c9.Valid {
		tmp := uint16(c9.Int32)
		i.Port = tmp
	}

	if c10.Valid {
		tmp := c10.Time
		i.UpdatedAt = tmp
	}

	return nil
}

// Err set an error to return by scan
func (t PeerScannerStaticRow) Err(err error) PeerScannerStaticRow {
	t.err = err
	return t
}

// NewPeerScannerDynamic creates a scanner that operates on a dynamic
// set of columns that can be returned in any subset/order.
func NewPeerScannerDynamic(rows *sql.Rows, err error) PeerScanner {
	if err != nil {
		return errPeerScanner{e: err}
	}

	return peerScannerDynamic{
		Rows: rows,
	}
}

// peerScannerDynamic generated by genieql
type peerScannerDynamic struct {
	Rows *sql.Rows `json:"rows"`
}

// Scan generated by genieql
func (t peerScannerDynamic) Scan(i *Peer) error {
	const (
		cn0  = "bep51"
		cn1  = "bep51_available"
		cn2  = "bep51_ttl"
		cn3  = "created_at"
		cn4  = "id"
		cn5  = "ip"
		cn6  = "network"
		cn7  = "next_check"
		cn8  = "peer"
		cn9  = "port"
		cn10 = "updated_at"
	)
	var (
		ignored sql.RawBytes
		err     error
		columns []string
		dst     []interface{}
		c0      sql.NullBool
		c1      ducktype.NullUint64
		c2      sql.NullInt32
		c3      sql.NullTime
		c4      sql.NullString
		c5      sql.NullString
		c6      sql.NullString
		c7      sql.NullTime
		c8      []byte
		c9      sql.NullInt32
		c10     sql.NullTime
	)

	if columns, err = t.Rows.Columns(); err != nil {
		return err
	}

	dst = make([]interface{}, 0, len(columns))

	for _, column := range columns {
		switch column {
		case cn0:
			dst = append(dst, &c0)
		case cn1:
			dst = append(dst, &c1)
		case cn2:
			dst = append(dst, &c2)
		case cn3:
			dst = append(dst, &c3)
		case cn4:
			dst = append(dst, &c4)
		case cn5:
			dst = append(dst, &c5)
		case cn6:
			dst = append(dst, &c6)
		case cn7:
			dst = append(dst, &c7)
		case cn8:
			dst = append(dst, &c8)
		case cn9:
			dst = append(dst, &c9)
		case cn10:
			dst = append(dst, &c10)
		default:
			dst = append(dst, &ignored)
		}
	}

	if err := t.Rows.Scan(dst...); err != nil {
		return err
	}

	for _, column := range columns {
		switch column {
		case cn0:
			if c0.Valid {
				tmp := c0.Bool
				i.Bep51 = tmp
			}

		case cn1:
			if c1.Valid {
				i.Bep51Available = c1.V
			}

		case cn2:
			if c2.Valid {
				tmp := uint16(c2.Int32)
				i.Bep51TTL = tmp
			}

		case cn3:
			if c3.Valid {
				tmp := c3.Time
				i.CreatedAt = tmp
			}

		case cn4:
			if c4.Valid {
				if uid, err := uuid.FromBytes([]byte(c4.String)); err != nil {
					return err
				} else {
					i.ID = uid.String()
				}
			}

		case cn5:
			if c5.Valid {
				tmp := string(c5.String)
				i.IP = tmp
			}

		case cn6:
			if c6.Valid {
				tmp := string(c6.String)
				i.Network = tmp
			}

		case cn7:
			if c7.Valid {
				tmp := c7.Time
				i.NextCheck = tmp
			}

		case cn8:
			i.Peer = c8

		case cn9:
			if c9.Valid {
				tmp := uint16(c9.Int32)
				i.Port = tmp
			}

		case cn10:
			if c10.Valid {
				tmp := c10.Time
				i.UpdatedAt = tmp
			}

		}
	}

	return t.Rows.Err()
}

// Err generated by genieql
func (t peerScannerDynamic) Err() error {
	return t.Rows.Err()
}

// Close generated by genieql
func (t peerScannerDynamic) Close() error {
	if t.Rows == nil {
		return nil
	}
	return t.Rows.Close()
}

// Next generated by genieql
func (t peerScannerDynamic) Next() bool {
	return t.Rows.Next()
}

// MetadataAssignKnownMediaID generated by genieql
func MetadataAssignKnownMediaID(ctx context.Context, q sqlx.Queryer, id string, kid string) MetadataScannerStaticRow {
	const query = `UPDATE torrents_metadata SET updated_at = NOW(), known_media_id = $2 WHERE "id" = $1 RETURNING torrents_metadata."archivable",torrents_metadata."auto_description",torrents_metadata."bytes",torrents_metadata."created_at",torrents_metadata."description",torrents_metadata."downloaded",torrents_metadata."encryption_seed",torrents_metadata."hidden_at",torrents_metadata."id",torrents_metadata."infohash",torrents_metadata."initiated_at",torrents_metadata."known_media_id",torrents_metadata."next_announce_at",torrents_metadata."paused_at",torrents_metadata."peers",torrents_metadata."private",torrents_metadata."seeding",torrents_metadata."tracker",torrents_metadata."updated_at",torrents_metadata."uploaded",torrents_metadata."verify_at"`
	var (
		c0 sql.NullString // id
		c1 sql.NullString // kid
	)
	c0.Valid = true
	c0.String = id
	c1.Valid = true
	c1.String = kid
	return NewMetadataScannerStaticRow(q.QueryRowContext(ctx, query, c0, c1))
}

// MetadataFindByID generated by genieql
func MetadataFindByID(ctx context.Context, q sqlx.Queryer, id string) MetadataScannerStaticRow {
	const query = `SELECT torrents_metadata."archivable",torrents_metadata."auto_description",torrents_metadata."bytes",torrents_metadata."created_at",torrents_metadata."description",torrents_metadata."downloaded",torrents_metadata."encryption_seed",torrents_metadata."hidden_at",torrents_metadata."id",torrents_metadata."infohash",torrents_metadata."initiated_at",torrents_metadata."known_media_id",torrents_metadata."next_announce_at",torrents_metadata."paused_at",torrents_metadata."peers",torrents_metadata."private",torrents_metadata."seeding",torrents_metadata."tracker",torrents_metadata."updated_at",torrents_metadata."uploaded",torrents_metadata."verify_at" FROM torrents_metadata WHERE "id" = $1`
	var c0 sql.NullString // id
	c0.Valid = true
	c0.String = id
	return NewMetadataScannerStaticRow(q.QueryRowContext(ctx, query, c0))
}

// MetadataCompleteByID generated by genieql
func MetadataCompleteByID(ctx context.Context, q sqlx.Queryer, id string, peers uint16, downloaded uint64, uploaded uint64) MetadataScannerStaticRow {
	const query = `UPDATE torrents_metadata SET updated_at = NOW(), verify_at = NOW(), downloaded = $3, uploaded = $4, peers = $2, seeding = (bytes == $3) WHERE "id" = $1 RETURNING torrents_metadata."archivable",torrents_metadata."auto_description",torrents_metadata."bytes",torrents_metadata."created_at",torrents_metadata."description",torrents_metadata."downloaded",torrents_metadata."encryption_seed",torrents_metadata."hidden_at",torrents_metadata."id",torrents_metadata."infohash",torrents_metadata."initiated_at",torrents_metadata."known_media_id",torrents_metadata."next_announce_at",torrents_metadata."paused_at",torrents_metadata."peers",torrents_metadata."private",torrents_metadata."seeding",torrents_metadata."tracker",torrents_metadata."updated_at",torrents_metadata."uploaded",torrents_metadata."verify_at"`
	var (
		c0 sql.NullString   // id
		c1 sql.Null[uint16] // peers
	)
	c0.Valid = true
	c0.String = id
	c1.Valid = true
	c1.V = peers
	return NewMetadataScannerStaticRow(q.QueryRowContext(ctx, query, c0, c1, downloaded, uploaded))
}

// MetadataUploadedByID generated by genieql
func MetadataUploadedByID(ctx context.Context, q sqlx.Queryer, id []byte, uploaded uint64) MetadataScannerStaticRow {
	const query = `UPDATE torrents_metadata SET updated_at = NOW(), uploaded = (uploaded + $2) WHERE "infohash" = $1 RETURNING torrents_metadata."archivable",torrents_metadata."auto_description",torrents_metadata."bytes",torrents_metadata."created_at",torrents_metadata."description",torrents_metadata."downloaded",torrents_metadata."encryption_seed",torrents_metadata."hidden_at",torrents_metadata."id",torrents_metadata."infohash",torrents_metadata."initiated_at",torrents_metadata."known_media_id",torrents_metadata."next_announce_at",torrents_metadata."paused_at",torrents_metadata."peers",torrents_metadata."private",torrents_metadata."seeding",torrents_metadata."tracker",torrents_metadata."updated_at",torrents_metadata."uploaded",torrents_metadata."verify_at"`
	return NewMetadataScannerStaticRow(q.QueryRowContext(ctx, query, id, uploaded))
}

// MetadataAnnounced generated by genieql
func MetadataAnnounced(ctx context.Context, q sqlx.Queryer, id string, nextts time.Time) MetadataScannerStaticRow {
	const query = `UPDATE torrents_metadata SET updated_at = NOW(), next_announce_at = $2 WHERE "id" = $1 RETURNING torrents_metadata."archivable",torrents_metadata."auto_description",torrents_metadata."bytes",torrents_metadata."created_at",torrents_metadata."description",torrents_metadata."downloaded",torrents_metadata."encryption_seed",torrents_metadata."hidden_at",torrents_metadata."id",torrents_metadata."infohash",torrents_metadata."initiated_at",torrents_metadata."known_media_id",torrents_metadata."next_announce_at",torrents_metadata."paused_at",torrents_metadata."peers",torrents_metadata."private",torrents_metadata."seeding",torrents_metadata."tracker",torrents_metadata."updated_at",torrents_metadata."uploaded",torrents_metadata."verify_at"`
	var (
		c0 sql.NullString // id
		c1 sql.NullTime   // nextts
	)
	c0.Valid = true
	c0.String = id
	c1.Valid = true
	c1.Time = nextts
	return NewMetadataScannerStaticRow(q.QueryRowContext(ctx, query, c0, c1))
}

// MetadataDisableAnnounced generated by genieql
func MetadataDisableAnnounced(ctx context.Context, q sqlx.Queryer, id string) MetadataScannerStaticRow {
	const query = `UPDATE torrents_metadata SET updated_at = NOW(), next_announce_at = 'infinity' WHERE "id" = $1 RETURNING torrents_metadata."archivable",torrents_metadata."auto_description",torrents_metadata."bytes",torrents_metadata."created_at",torrents_metadata."description",torrents_metadata."downloaded",torrents_metadata."encryption_seed",torrents_metadata."hidden_at",torrents_metadata."id",torrents_metadata."infohash",torrents_metadata."initiated_at",torrents_metadata."known_media_id",torrents_metadata."next_announce_at",torrents_metadata."paused_at",torrents_metadata."peers",torrents_metadata."private",torrents_metadata."seeding",torrents_metadata."tracker",torrents_metadata."updated_at",torrents_metadata."uploaded",torrents_metadata."verify_at"`
	var c0 sql.NullString // id
	c0.Valid = true
	c0.String = id
	return NewMetadataScannerStaticRow(q.QueryRowContext(ctx, query, c0))
}

// MetadataProgressByID generated by genieql
func MetadataProgressByID(ctx context.Context, q sqlx.Queryer, id string, peers uint16, downloaded uint64) MetadataScannerStaticRow {
	const query = `UPDATE torrents_metadata SET updated_at = NOW(), downloaded = $3, peers = $2, seeding = (bytes == $3) WHERE "id" = $1 RETURNING torrents_metadata."archivable",torrents_metadata."auto_description",torrents_metadata."bytes",torrents_metadata."created_at",torrents_metadata."description",torrents_metadata."downloaded",torrents_metadata."encryption_seed",torrents_metadata."hidden_at",torrents_metadata."id",torrents_metadata."infohash",torrents_metadata."initiated_at",torrents_metadata."known_media_id",torrents_metadata."next_announce_at",torrents_metadata."paused_at",torrents_metadata."peers",torrents_metadata."private",torrents_metadata."seeding",torrents_metadata."tracker",torrents_metadata."updated_at",torrents_metadata."uploaded",torrents_metadata."verify_at"`
	var (
		c0 sql.NullString   // id
		c1 sql.Null[uint16] // peers
	)
	c0.Valid = true
	c0.String = id
	c1.Valid = true
	c1.V = peers
	return NewMetadataScannerStaticRow(q.QueryRowContext(ctx, query, c0, c1, downloaded))
}

// MetadataDownloadByID generated by genieql
func MetadataDownloadByID(ctx context.Context, q sqlx.Queryer, id string) MetadataScannerStaticRow {
	const query = `UPDATE torrents_metadata SET paused_at = 'infinity', initiated_at = NOW() WHERE "id" = $1 RETURNING torrents_metadata."archivable",torrents_metadata."auto_description",torrents_metadata."bytes",torrents_metadata."created_at",torrents_metadata."description",torrents_metadata."downloaded",torrents_metadata."encryption_seed",torrents_metadata."hidden_at",torrents_metadata."id",torrents_metadata."infohash",torrents_metadata."initiated_at",torrents_metadata."known_media_id",torrents_metadata."next_announce_at",torrents_metadata."paused_at",torrents_metadata."peers",torrents_metadata."private",torrents_metadata."seeding",torrents_metadata."tracker",torrents_metadata."updated_at",torrents_metadata."uploaded",torrents_metadata."verify_at"`
	var c0 sql.NullString // id
	c0.Valid = true
	c0.String = id
	return NewMetadataScannerStaticRow(q.QueryRowContext(ctx, query, c0))
}

// MetadataPausedByID generated by genieql
func MetadataPausedByID(ctx context.Context, q sqlx.Queryer, id string) MetadataScannerStaticRow {
	const query = `UPDATE torrents_metadata SET paused_at = NOW(), initiated_at = 'infinity' WHERE "id" = $1 RETURNING torrents_metadata."archivable",torrents_metadata."auto_description",torrents_metadata."bytes",torrents_metadata."created_at",torrents_metadata."description",torrents_metadata."downloaded",torrents_metadata."encryption_seed",torrents_metadata."hidden_at",torrents_metadata."id",torrents_metadata."infohash",torrents_metadata."initiated_at",torrents_metadata."known_media_id",torrents_metadata."next_announce_at",torrents_metadata."paused_at",torrents_metadata."peers",torrents_metadata."private",torrents_metadata."seeding",torrents_metadata."tracker",torrents_metadata."updated_at",torrents_metadata."uploaded",torrents_metadata."verify_at"`
	var c0 sql.NullString // id
	c0.Valid = true
	c0.String = id
	return NewMetadataScannerStaticRow(q.QueryRowContext(ctx, query, c0))
}

// PeerInsertWithDefaultsStaticColumns generated by genieql
const PeerInsertWithDefaultsStaticColumns = `$1,$2,$3,DEFAULT,$4,$5,$6,DEFAULT,$7,$8,DEFAULT`

// PeerInsertWithDefaultsExplode generated by genieql
func PeerInsertWithDefaultsExplode(a *Peer) ([]interface{}, error) {
	var (
		c0 sql.NullBool        // bep51
		c1 ducktype.NullUint64 // bep51_available
		c2 sql.NullInt32       // bep51_ttl
		c3 sql.NullString      // id
		c4 sql.NullString      // ip
		c5 sql.NullString      // network
		c6 []byte              // peer
		c7 sql.NullInt32       // port
	)

	c0.Valid = true
	c0.Bool = a.Bep51

	c1.Valid = true
	c1.V = a.Bep51Available

	c2.Valid = true
	c2.Int32 = int32(a.Bep51TTL)

	c3.Valid = true
	c3.String = a.ID

	c4.Valid = true
	c4.String = a.IP

	c5.Valid = true
	c5.String = a.Network

	c6 = a.Peer

	c7.Valid = true
	c7.Int32 = int32(a.Port)

	return []interface{}{c0, c1, c2, c3, c4, c5, c6, c7}, nil
}

// PeerInsertWithDefaults generated by genieql
func PeerInsertWithDefaults(ctx context.Context, q sqlx.Queryer, a Peer) PeerScannerStaticRow {
	const query = `INSERT INTO "torrents_peers" ("bep51","bep51_available","bep51_ttl","created_at","id","ip","network","next_check","peer","port","updated_at") VALUES ($1,$2,$3,DEFAULT,$4,$5,$6,DEFAULT,$7,$8,DEFAULT) ON CONFLICT (id) DO UPDATE SET updated_at = DEFAULT, ip = EXCLUDED.ip, port = EXCLUDED.port, bep51_available = EXCLUDED.bep51_available RETURNING "bep51","bep51_available","bep51_ttl","created_at","id","ip","network","next_check","peer","port","updated_at"`
	var (
		c0 sql.NullBool        // bep51
		c1 ducktype.NullUint64 // bep51_available
		c2 sql.NullInt32       // bep51_ttl
		c3 sql.NullString      // id
		c4 sql.NullString      // ip
		c5 sql.NullString      // network
		c6 []byte              // peer
		c7 sql.NullInt32
	)
	c0.Valid = true
	c0.Bool = a.Bep51
	c1.Valid = true
	c1.V = a.Bep51Available
	c2.Valid = true
	c2.Int32 = int32(a.Bep51TTL)
	c3.Valid = true
	c3.String = a.ID
	c4.Valid = true
	c4.String = a.IP
	c5.Valid = true
	c5.String = a.Network
	c6 = a.Peer
	c7.Valid = true
	c7.Int32 = int32(a.Port) // port
	return NewPeerScannerStaticRow(q.QueryRowContext(ctx, query, c0, c1, c2, c3, c4, c5, c6, c7))
}

// PeerMarkNextCheckStaticColumns generated by genieql
const PeerMarkNextCheckStaticColumns = `$1,$2,$3,DEFAULT,$4,$5,$6,DEFAULT,$7,$8,DEFAULT`

// PeerMarkNextCheckExplode generated by genieql
func PeerMarkNextCheckExplode(a *Peer) ([]interface{}, error) {
	var (
		c0 sql.NullBool        // bep51
		c1 ducktype.NullUint64 // bep51_available
		c2 sql.NullInt32       // bep51_ttl
		c3 sql.NullString      // id
		c4 sql.NullString      // ip
		c5 sql.NullString      // network
		c6 []byte              // peer
		c7 sql.NullInt32       // port
	)

	c0.Valid = true
	c0.Bool = a.Bep51

	c1.Valid = true
	c1.V = a.Bep51Available

	c2.Valid = true
	c2.Int32 = int32(a.Bep51TTL)

	c3.Valid = true
	c3.String = a.ID

	c4.Valid = true
	c4.String = a.IP

	c5.Valid = true
	c5.String = a.Network

	c6 = a.Peer

	c7.Valid = true
	c7.Int32 = int32(a.Port)

	return []interface{}{c0, c1, c2, c3, c4, c5, c6, c7}, nil
}

// PeerMarkNextCheck generated by genieql
func PeerMarkNextCheck(ctx context.Context, q sqlx.Queryer, a Peer) PeerScannerStaticRow {
	const query = `INSERT INTO "torrents_peers" ("bep51","bep51_available","bep51_ttl","created_at","id","ip","network","next_check","peer","port","updated_at") VALUES ($1,$2,$3,DEFAULT,$4,$5,$6,DEFAULT,$7,$8,DEFAULT) ON CONFLICT (id) DO UPDATE SET updated_at = NOW(), next_check = NOW() + to_seconds(EXCLUDED.bep51_ttl) RETURNING "bep51","bep51_available","bep51_ttl","created_at","id","ip","network","next_check","peer","port","updated_at"`
	var (
		c0 sql.NullBool        // bep51
		c1 ducktype.NullUint64 // bep51_available
		c2 sql.NullInt32       // bep51_ttl
		c3 sql.NullString      // id
		c4 sql.NullString      // ip
		c5 sql.NullString      // network
		c6 []byte              // peer
		c7 sql.NullInt32
	)
	c0.Valid = true
	c0.Bool = a.Bep51
	c1.Valid = true
	c1.V = a.Bep51Available
	c2.Valid = true
	c2.Int32 = int32(a.Bep51TTL)
	c3.Valid = true
	c3.String = a.ID
	c4.Valid = true
	c4.String = a.IP
	c5.Valid = true
	c5.String = a.Network
	c6 = a.Peer
	c7.Valid = true
	c7.Int32 = int32(a.Port) // port
	return NewPeerScannerStaticRow(q.QueryRowContext(ctx, query, c0, c1, c2, c3, c4, c5, c6, c7))
}

// MetadataVerifyByID generated by genieql
func MetadataVerifyByID(ctx context.Context, q sqlx.Queryer, id string, peers uint16, downloaded uint64) MetadataScannerStaticRow {
	const query = `UPDATE torrents_metadata SET updated_at = NOW(), downloaded = $3, peers = $2, seeding = (bytes == $3), verify_at = 'infinity' WHERE "id" = $1 RETURNING torrents_metadata."archivable",torrents_metadata."auto_description",torrents_metadata."bytes",torrents_metadata."created_at",torrents_metadata."description",torrents_metadata."downloaded",torrents_metadata."encryption_seed",torrents_metadata."hidden_at",torrents_metadata."id",torrents_metadata."infohash",torrents_metadata."initiated_at",torrents_metadata."known_media_id",torrents_metadata."next_announce_at",torrents_metadata."paused_at",torrents_metadata."peers",torrents_metadata."private",torrents_metadata."seeding",torrents_metadata."tracker",torrents_metadata."updated_at",torrents_metadata."uploaded",torrents_metadata."verify_at"`
	var (
		c0 sql.NullString   // id
		c1 sql.Null[uint16] // peers
	)
	c0.Valid = true
	c0.String = id
	c1.Valid = true
	c1.V = peers
	return NewMetadataScannerStaticRow(q.QueryRowContext(ctx, query, c0, c1, downloaded))
}

// MetadataDeleteByID generated by genieql
func MetadataDeleteByID(ctx context.Context, q sqlx.Queryer, id string) MetadataScannerStaticRow {
	const query = `DELETE FROM torrents_metadata WHERE "id" = $1 RETURNING torrents_metadata."archivable",torrents_metadata."auto_description",torrents_metadata."bytes",torrents_metadata."created_at",torrents_metadata."description",torrents_metadata."downloaded",torrents_metadata."encryption_seed",torrents_metadata."hidden_at",torrents_metadata."id",torrents_metadata."infohash",torrents_metadata."initiated_at",torrents_metadata."known_media_id",torrents_metadata."next_announce_at",torrents_metadata."paused_at",torrents_metadata."peers",torrents_metadata."private",torrents_metadata."seeding",torrents_metadata."tracker",torrents_metadata."updated_at",torrents_metadata."uploaded",torrents_metadata."verify_at"`
	var c0 sql.NullString // id
	c0.Valid = true
	c0.String = id
	return NewMetadataScannerStaticRow(q.QueryRowContext(ctx, query, c0))
}

// UnknownHashInsertWithDefaultsStaticColumns generated by genieql
const UnknownHashInsertWithDefaultsStaticColumns = `$1,DEFAULT,$2,$3,$4,DEFAULT`

// UnknownHashInsertWithDefaultsExplode generated by genieql
func UnknownHashInsertWithDefaultsExplode(a *UnknownHash) ([]interface{}, error) {
	var (
		c0 ducktype.NullUint64 // attempts
		c1 sql.NullString      // id
		c2 []byte              // infohash
		c3 sql.NullTime        // next_check
	)

	c0.Valid = true
	c0.V = a.Attempts

	c1.Valid = true
	c1.String = a.ID

	c2 = a.Infohash

	c3.Valid = true
	c3.Time = a.NextCheck

	return []interface{}{c0, c1, c2, c3}, nil
}

// UnknownHashInsertWithDefaults generated by genieql
func UnknownHashInsertWithDefaults(ctx context.Context, q sqlx.Queryer, a UnknownHash) UnknownHashScannerStaticRow {
	const query = `INSERT INTO "torrents_unknown_infohashes" ("attempts","created_at","id","infohash","next_check","updated_at") VALUES ($1,DEFAULT,$2,$3,$4,DEFAULT) ON CONFLICT (id) DO UPDATE SET updated_at = DEFAULT RETURNING "attempts","created_at","id","infohash","next_check","updated_at"`
	var (
		c0 ducktype.NullUint64 // attempts
		c1 sql.NullString      // id
		c2 []byte              // infohash
		c3 sql.NullTime
	)
	c0.Valid = true
	c0.V = a.Attempts
	c1.Valid = true
	c1.String = a.ID
	c2 = a.Infohash
	c3.Valid = true
	c3.Time = a.NextCheck // next_check
	return NewUnknownHashScannerStaticRow(q.QueryRowContext(ctx, query, c0, c1, c2, c3))
}

// UnknownHashDeleteByID generated by genieql
func UnknownHashDeleteByID(ctx context.Context, q sqlx.Queryer, id string) UnknownHashScannerStaticRow {
	const query = `DELETE FROM torrents_unknown_infohashes WHERE "id" = $1 RETURNING torrents_unknown_infohashes."attempts",torrents_unknown_infohashes."created_at",torrents_unknown_infohashes."id",torrents_unknown_infohashes."infohash",torrents_unknown_infohashes."next_check",torrents_unknown_infohashes."updated_at"`
	var c0 sql.NullString // id
	c0.Valid = true
	c0.String = id
	return NewUnknownHashScannerStaticRow(q.QueryRowContext(ctx, query, c0))
}

// UnknownHashCooldownStaticColumns generated by genieql
const UnknownHashCooldownStaticColumns = `$1,DEFAULT,$2,$3,$4,DEFAULT`

// UnknownHashCooldownExplode generated by genieql
func UnknownHashCooldownExplode(a *UnknownHash) ([]interface{}, error) {
	var (
		c0 ducktype.NullUint64 // attempts
		c1 sql.NullString      // id
		c2 []byte              // infohash
		c3 sql.NullTime        // next_check
	)

	c0.Valid = true
	c0.V = a.Attempts

	c1.Valid = true
	c1.String = a.ID

	c2 = a.Infohash

	c3.Valid = true
	c3.Time = a.NextCheck

	return []interface{}{c0, c1, c2, c3}, nil
}

// UnknownHashCooldown generated by genieql
func UnknownHashCooldown(ctx context.Context, q sqlx.Queryer, a UnknownHash) UnknownHashScannerStaticRow {
	const query = `INSERT INTO "torrents_unknown_infohashes" ("attempts","created_at","id","infohash","next_check","updated_at") VALUES ($1,DEFAULT,$2,$3,$4,DEFAULT) ON CONFLICT (id) DO UPDATE SET updated_at = DEFAULT, attempts = EXCLUDED.attempts + 1, next_check = NOW() + least(to_minutes(CAST(EXCLUDED.attempts AS INT)*2), to_hours(24)) RETURNING "attempts","created_at","id","infohash","next_check","updated_at"`
	var (
		c0 ducktype.NullUint64 // attempts
		c1 sql.NullString      // id
		c2 []byte              // infohash
		c3 sql.NullTime
	)
	c0.Valid = true
	c0.V = a.Attempts
	c1.Valid = true
	c1.String = a.ID
	c2 = a.Infohash
	c3.Valid = true
	c3.Time = a.NextCheck // next_check
	return NewUnknownHashScannerStaticRow(q.QueryRowContext(ctx, query, c0, c1, c2, c3))
}

// MetadataBatchInsertWithDefaults generated by genieql
func NewMetadataBatchInsertWithDefaults(ctx context.Context, q sqlx.Queryer, p ...Metadata) MetadataScanner {
	return &metadataBatchInsertWithDefaults{ctx: ctx, q: q, remaining: p}
}

type metadataBatchInsertWithDefaults struct {
	ctx       context.Context
	q         sqlx.Queryer
	remaining []Metadata
	scanner   MetadataScanner
}

func (t *metadataBatchInsertWithDefaults) Scan(p *Metadata) error {
	return t.scanner.Scan(p)
}

func (t *metadataBatchInsertWithDefaults) Err() error {
	if t.scanner == nil {
		return nil
	}
	return t.scanner.Err()
}

func (t *metadataBatchInsertWithDefaults) Close() error {
	if t.scanner == nil {
		return nil
	}
	return t.scanner.Close()
}

func (t *metadataBatchInsertWithDefaults) Next() bool {
	var advanced bool
	if t.scanner != nil && t.scanner.Next() {
		return true
	}
	if len(t.remaining) > 0 && t.Close() == nil {
		t.scanner, t.remaining, advanced = t.advance(t.remaining...)
		return advanced && t.scanner.Next()
	}
	return false
}

func (t *metadataBatchInsertWithDefaults) advance(p ...Metadata) (MetadataScanner, []Metadata, bool) {
	transform := func(p Metadata) (c0 sql.NullBool, c1 sql.NullString, c2 ducktype.NullUint64, c3 sql.NullString, c4 sql.NullString, c5 sql.NullString, c6 []byte, c7 sql.NullString, c8 sql.NullInt32, c9 sql.NullBool, c10 sql.NullBool, c11 sql.NullString, c12 ducktype.NullUint64, c13 sql.NullTime, err error) {
		c0.Valid = true
		c0.Bool = p.Archivable
		c1.Valid = true
		c1.String = p.AutoDescription
		c2.Valid = true
		c2.V = p.Bytes
		c3.Valid = true
		c3.String = p.Description
		c4.Valid = true
		c4.String = p.EncryptionSeed
		c5.Valid = true
		c5.String = p.ID
		c6 = p.Infohash
		c7.Valid = true
		c7.String = p.KnownMediaID
		c8.Valid = true
		c8.Int32 = int32(p.Peers)
		c9.Valid = true
		c9.Bool = p.Private
		c10.Valid = true
		c10.Bool = p.Seeding
		c11.Valid = true
		c11.String = p.Tracker
		c12.Valid = true
		c12.V = p.Uploaded
		c13.Valid = true
		c13.Time = p.VerifyAt
		return c0, c1, c2, c3, c4, c5, c6, c7, c8, c9, c10, c11, c12, c13, nil
	}
	switch len(p) {
	case 0:
		return nil, []Metadata(nil), false
	case 1:
		const query = `INSERT INTO "torrents_metadata" ("archivable","auto_description","bytes","created_at","description","downloaded","encryption_seed","hidden_at","id","infohash","initiated_at","known_media_id","next_announce_at","paused_at","peers","private","seeding","tracker","updated_at","uploaded","verify_at") VALUES ($1,$2,$3,DEFAULT,$4,DEFAULT,$5,DEFAULT,$6,$7,DEFAULT,$8,DEFAULT,DEFAULT,$9,$10,$11,$12,DEFAULT,$13,$14) RETURNING "archivable","auto_description","bytes","created_at","description","downloaded","encryption_seed","hidden_at","id","infohash","initiated_at","known_media_id","next_announce_at","paused_at","peers","private","seeding","tracker","updated_at","uploaded","verify_at"`
		var (
			r0c0  sql.NullBool
			r0c1  sql.NullString
			r0c2  ducktype.NullUint64
			r0c3  sql.NullString
			r0c4  sql.NullString
			r0c5  sql.NullString
			r0c6  []byte
			r0c7  sql.NullString
			r0c8  sql.NullInt32
			r0c9  sql.NullBool
			r0c10 sql.NullBool
			r0c11 sql.NullString
			r0c12 ducktype.NullUint64
			r0c13 sql.NullTime
			err   error
		)
		if r0c0, r0c1, r0c2, r0c3, r0c4, r0c5, r0c6, r0c7, r0c8, r0c9, r0c10, r0c11, r0c12, r0c13, err = transform(p[0]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		return NewMetadataScannerStatic(t.q.QueryContext(t.ctx, query, r0c0, r0c1, r0c2, r0c3, r0c4, r0c5, r0c6, r0c7, r0c8, r0c9, r0c10, r0c11, r0c12, r0c13)), p[1:], true
	case 2:
		const query = `INSERT INTO "torrents_metadata" ("archivable","auto_description","bytes","created_at","description","downloaded","encryption_seed","hidden_at","id","infohash","initiated_at","known_media_id","next_announce_at","paused_at","peers","private","seeding","tracker","updated_at","uploaded","verify_at") VALUES ($1,$2,$3,DEFAULT,$4,DEFAULT,$5,DEFAULT,$6,$7,DEFAULT,$8,DEFAULT,DEFAULT,$9,$10,$11,$12,DEFAULT,$13,$14),($15,$16,$17,DEFAULT,$18,DEFAULT,$19,DEFAULT,$20,$21,DEFAULT,$22,DEFAULT,DEFAULT,$23,$24,$25,$26,DEFAULT,$27,$28) RETURNING "archivable","auto_description","bytes","created_at","description","downloaded","encryption_seed","hidden_at","id","infohash","initiated_at","known_media_id","next_announce_at","paused_at","peers","private","seeding","tracker","updated_at","uploaded","verify_at"`
		var (
			r0c0  sql.NullBool
			r0c1  sql.NullString
			r0c2  ducktype.NullUint64
			r0c3  sql.NullString
			r0c4  sql.NullString
			r0c5  sql.NullString
			r0c6  []byte
			r0c7  sql.NullString
			r0c8  sql.NullInt32
			r0c9  sql.NullBool
			r0c10 sql.NullBool
			r0c11 sql.NullString
			r0c12 ducktype.NullUint64
			r0c13 sql.NullTime
			r1c0  sql.NullBool
			r1c1  sql.NullString
			r1c2  ducktype.NullUint64
			r1c3  sql.NullString
			r1c4  sql.NullString
			r1c5  sql.NullString
			r1c6  []byte
			r1c7  sql.NullString
			r1c8  sql.NullInt32
			r1c9  sql.NullBool
			r1c10 sql.NullBool
			r1c11 sql.NullString
			r1c12 ducktype.NullUint64
			r1c13 sql.NullTime
			err   error
		)
		if r0c0, r0c1, r0c2, r0c3, r0c4, r0c5, r0c6, r0c7, r0c8, r0c9, r0c10, r0c11, r0c12, r0c13, err = transform(p[0]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r1c0, r1c1, r1c2, r1c3, r1c4, r1c5, r1c6, r1c7, r1c8, r1c9, r1c10, r1c11, r1c12, r1c13, err = transform(p[1]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		return NewMetadataScannerStatic(t.q.QueryContext(t.ctx, query, r0c0, r0c1, r0c2, r0c3, r0c4, r0c5, r0c6, r0c7, r0c8, r0c9, r0c10, r0c11, r0c12, r0c13, r1c0, r1c1, r1c2, r1c3, r1c4, r1c5, r1c6, r1c7, r1c8, r1c9, r1c10, r1c11, r1c12, r1c13)), p[2:], true
	case 3:
		const query = `INSERT INTO "torrents_metadata" ("archivable","auto_description","bytes","created_at","description","downloaded","encryption_seed","hidden_at","id","infohash","initiated_at","known_media_id","next_announce_at","paused_at","peers","private","seeding","tracker","updated_at","uploaded","verify_at") VALUES ($1,$2,$3,DEFAULT,$4,DEFAULT,$5,DEFAULT,$6,$7,DEFAULT,$8,DEFAULT,DEFAULT,$9,$10,$11,$12,DEFAULT,$13,$14),($15,$16,$17,DEFAULT,$18,DEFAULT,$19,DEFAULT,$20,$21,DEFAULT,$22,DEFAULT,DEFAULT,$23,$24,$25,$26,DEFAULT,$27,$28),($29,$30,$31,DEFAULT,$32,DEFAULT,$33,DEFAULT,$34,$35,DEFAULT,$36,DEFAULT,DEFAULT,$37,$38,$39,$40,DEFAULT,$41,$42) RETURNING "archivable","auto_description","bytes","created_at","description","downloaded","encryption_seed","hidden_at","id","infohash","initiated_at","known_media_id","next_announce_at","paused_at","peers","private","seeding","tracker","updated_at","uploaded","verify_at"`
		var (
			r0c0  sql.NullBool
			r0c1  sql.NullString
			r0c2  ducktype.NullUint64
			r0c3  sql.NullString
			r0c4  sql.NullString
			r0c5  sql.NullString
			r0c6  []byte
			r0c7  sql.NullString
			r0c8  sql.NullInt32
			r0c9  sql.NullBool
			r0c10 sql.NullBool
			r0c11 sql.NullString
			r0c12 ducktype.NullUint64
			r0c13 sql.NullTime
			r1c0  sql.NullBool
			r1c1  sql.NullString
			r1c2  ducktype.NullUint64
			r1c3  sql.NullString
			r1c4  sql.NullString
			r1c5  sql.NullString
			r1c6  []byte
			r1c7  sql.NullString
			r1c8  sql.NullInt32
			r1c9  sql.NullBool
			r1c10 sql.NullBool
			r1c11 sql.NullString
			r1c12 ducktype.NullUint64
			r1c13 sql.NullTime
			r2c0  sql.NullBool
			r2c1  sql.NullString
			r2c2  ducktype.NullUint64
			r2c3  sql.NullString
			r2c4  sql.NullString
			r2c5  sql.NullString
			r2c6  []byte
			r2c7  sql.NullString
			r2c8  sql.NullInt32
			r2c9  sql.NullBool
			r2c10 sql.NullBool
			r2c11 sql.NullString
			r2c12 ducktype.NullUint64
			r2c13 sql.NullTime
			err   error
		)
		if r0c0, r0c1, r0c2, r0c3, r0c4, r0c5, r0c6, r0c7, r0c8, r0c9, r0c10, r0c11, r0c12, r0c13, err = transform(p[0]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r1c0, r1c1, r1c2, r1c3, r1c4, r1c5, r1c6, r1c7, r1c8, r1c9, r1c10, r1c11, r1c12, r1c13, err = transform(p[1]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r2c0, r2c1, r2c2, r2c3, r2c4, r2c5, r2c6, r2c7, r2c8, r2c9, r2c10, r2c11, r2c12, r2c13, err = transform(p[2]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		return NewMetadataScannerStatic(t.q.QueryContext(t.ctx, query, r0c0, r0c1, r0c2, r0c3, r0c4, r0c5, r0c6, r0c7, r0c8, r0c9, r0c10, r0c11, r0c12, r0c13, r1c0, r1c1, r1c2, r1c3, r1c4, r1c5, r1c6, r1c7, r1c8, r1c9, r1c10, r1c11, r1c12, r1c13, r2c0, r2c1, r2c2, r2c3, r2c4, r2c5, r2c6, r2c7, r2c8, r2c9, r2c10, r2c11, r2c12, r2c13)), p[3:], true
	case 4:
		const query = `INSERT INTO "torrents_metadata" ("archivable","auto_description","bytes","created_at","description","downloaded","encryption_seed","hidden_at","id","infohash","initiated_at","known_media_id","next_announce_at","paused_at","peers","private","seeding","tracker","updated_at","uploaded","verify_at") VALUES ($1,$2,$3,DEFAULT,$4,DEFAULT,$5,DEFAULT,$6,$7,DEFAULT,$8,DEFAULT,DEFAULT,$9,$10,$11,$12,DEFAULT,$13,$14),($15,$16,$17,DEFAULT,$18,DEFAULT,$19,DEFAULT,$20,$21,DEFAULT,$22,DEFAULT,DEFAULT,$23,$24,$25,$26,DEFAULT,$27,$28),($29,$30,$31,DEFAULT,$32,DEFAULT,$33,DEFAULT,$34,$35,DEFAULT,$36,DEFAULT,DEFAULT,$37,$38,$39,$40,DEFAULT,$41,$42),($43,$44,$45,DEFAULT,$46,DEFAULT,$47,DEFAULT,$48,$49,DEFAULT,$50,DEFAULT,DEFAULT,$51,$52,$53,$54,DEFAULT,$55,$56) RETURNING "archivable","auto_description","bytes","created_at","description","downloaded","encryption_seed","hidden_at","id","infohash","initiated_at","known_media_id","next_announce_at","paused_at","peers","private","seeding","tracker","updated_at","uploaded","verify_at"`
		var (
			r0c0  sql.NullBool
			r0c1  sql.NullString
			r0c2  ducktype.NullUint64
			r0c3  sql.NullString
			r0c4  sql.NullString
			r0c5  sql.NullString
			r0c6  []byte
			r0c7  sql.NullString
			r0c8  sql.NullInt32
			r0c9  sql.NullBool
			r0c10 sql.NullBool
			r0c11 sql.NullString
			r0c12 ducktype.NullUint64
			r0c13 sql.NullTime
			r1c0  sql.NullBool
			r1c1  sql.NullString
			r1c2  ducktype.NullUint64
			r1c3  sql.NullString
			r1c4  sql.NullString
			r1c5  sql.NullString
			r1c6  []byte
			r1c7  sql.NullString
			r1c8  sql.NullInt32
			r1c9  sql.NullBool
			r1c10 sql.NullBool
			r1c11 sql.NullString
			r1c12 ducktype.NullUint64
			r1c13 sql.NullTime
			r2c0  sql.NullBool
			r2c1  sql.NullString
			r2c2  ducktype.NullUint64
			r2c3  sql.NullString
			r2c4  sql.NullString
			r2c5  sql.NullString
			r2c6  []byte
			r2c7  sql.NullString
			r2c8  sql.NullInt32
			r2c9  sql.NullBool
			r2c10 sql.NullBool
			r2c11 sql.NullString
			r2c12 ducktype.NullUint64
			r2c13 sql.NullTime
			r3c0  sql.NullBool
			r3c1  sql.NullString
			r3c2  ducktype.NullUint64
			r3c3  sql.NullString
			r3c4  sql.NullString
			r3c5  sql.NullString
			r3c6  []byte
			r3c7  sql.NullString
			r3c8  sql.NullInt32
			r3c9  sql.NullBool
			r3c10 sql.NullBool
			r3c11 sql.NullString
			r3c12 ducktype.NullUint64
			r3c13 sql.NullTime
			err   error
		)
		if r0c0, r0c1, r0c2, r0c3, r0c4, r0c5, r0c6, r0c7, r0c8, r0c9, r0c10, r0c11, r0c12, r0c13, err = transform(p[0]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r1c0, r1c1, r1c2, r1c3, r1c4, r1c5, r1c6, r1c7, r1c8, r1c9, r1c10, r1c11, r1c12, r1c13, err = transform(p[1]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r2c0, r2c1, r2c2, r2c3, r2c4, r2c5, r2c6, r2c7, r2c8, r2c9, r2c10, r2c11, r2c12, r2c13, err = transform(p[2]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r3c0, r3c1, r3c2, r3c3, r3c4, r3c5, r3c6, r3c7, r3c8, r3c9, r3c10, r3c11, r3c12, r3c13, err = transform(p[3]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		return NewMetadataScannerStatic(t.q.QueryContext(t.ctx, query, r0c0, r0c1, r0c2, r0c3, r0c4, r0c5, r0c6, r0c7, r0c8, r0c9, r0c10, r0c11, r0c12, r0c13, r1c0, r1c1, r1c2, r1c3, r1c4, r1c5, r1c6, r1c7, r1c8, r1c9, r1c10, r1c11, r1c12, r1c13, r2c0, r2c1, r2c2, r2c3, r2c4, r2c5, r2c6, r2c7, r2c8, r2c9, r2c10, r2c11, r2c12, r2c13, r3c0, r3c1, r3c2, r3c3, r3c4, r3c5, r3c6, r3c7, r3c8, r3c9, r3c10, r3c11, r3c12, r3c13)), p[4:], true
	case 5:
		const query = `INSERT INTO "torrents_metadata" ("archivable","auto_description","bytes","created_at","description","downloaded","encryption_seed","hidden_at","id","infohash","initiated_at","known_media_id","next_announce_at","paused_at","peers","private","seeding","tracker","updated_at","uploaded","verify_at") VALUES ($1,$2,$3,DEFAULT,$4,DEFAULT,$5,DEFAULT,$6,$7,DEFAULT,$8,DEFAULT,DEFAULT,$9,$10,$11,$12,DEFAULT,$13,$14),($15,$16,$17,DEFAULT,$18,DEFAULT,$19,DEFAULT,$20,$21,DEFAULT,$22,DEFAULT,DEFAULT,$23,$24,$25,$26,DEFAULT,$27,$28),($29,$30,$31,DEFAULT,$32,DEFAULT,$33,DEFAULT,$34,$35,DEFAULT,$36,DEFAULT,DEFAULT,$37,$38,$39,$40,DEFAULT,$41,$42),($43,$44,$45,DEFAULT,$46,DEFAULT,$47,DEFAULT,$48,$49,DEFAULT,$50,DEFAULT,DEFAULT,$51,$52,$53,$54,DEFAULT,$55,$56),($57,$58,$59,DEFAULT,$60,DEFAULT,$61,DEFAULT,$62,$63,DEFAULT,$64,DEFAULT,DEFAULT,$65,$66,$67,$68,DEFAULT,$69,$70) RETURNING "archivable","auto_description","bytes","created_at","description","downloaded","encryption_seed","hidden_at","id","infohash","initiated_at","known_media_id","next_announce_at","paused_at","peers","private","seeding","tracker","updated_at","uploaded","verify_at"`
		var (
			r0c0  sql.NullBool
			r0c1  sql.NullString
			r0c2  ducktype.NullUint64
			r0c3  sql.NullString
			r0c4  sql.NullString
			r0c5  sql.NullString
			r0c6  []byte
			r0c7  sql.NullString
			r0c8  sql.NullInt32
			r0c9  sql.NullBool
			r0c10 sql.NullBool
			r0c11 sql.NullString
			r0c12 ducktype.NullUint64
			r0c13 sql.NullTime
			r1c0  sql.NullBool
			r1c1  sql.NullString
			r1c2  ducktype.NullUint64
			r1c3  sql.NullString
			r1c4  sql.NullString
			r1c5  sql.NullString
			r1c6  []byte
			r1c7  sql.NullString
			r1c8  sql.NullInt32
			r1c9  sql.NullBool
			r1c10 sql.NullBool
			r1c11 sql.NullString
			r1c12 ducktype.NullUint64
			r1c13 sql.NullTime
			r2c0  sql.NullBool
			r2c1  sql.NullString
			r2c2  ducktype.NullUint64
			r2c3  sql.NullString
			r2c4  sql.NullString
			r2c5  sql.NullString
			r2c6  []byte
			r2c7  sql.NullString
			r2c8  sql.NullInt32
			r2c9  sql.NullBool
			r2c10 sql.NullBool
			r2c11 sql.NullString
			r2c12 ducktype.NullUint64
			r2c13 sql.NullTime
			r3c0  sql.NullBool
			r3c1  sql.NullString
			r3c2  ducktype.NullUint64
			r3c3  sql.NullString
			r3c4  sql.NullString
			r3c5  sql.NullString
			r3c6  []byte
			r3c7  sql.NullString
			r3c8  sql.NullInt32
			r3c9  sql.NullBool
			r3c10 sql.NullBool
			r3c11 sql.NullString
			r3c12 ducktype.NullUint64
			r3c13 sql.NullTime
			r4c0  sql.NullBool
			r4c1  sql.NullString
			r4c2  ducktype.NullUint64
			r4c3  sql.NullString
			r4c4  sql.NullString
			r4c5  sql.NullString
			r4c6  []byte
			r4c7  sql.NullString
			r4c8  sql.NullInt32
			r4c9  sql.NullBool
			r4c10 sql.NullBool
			r4c11 sql.NullString
			r4c12 ducktype.NullUint64
			r4c13 sql.NullTime
			err   error
		)
		if r0c0, r0c1, r0c2, r0c3, r0c4, r0c5, r0c6, r0c7, r0c8, r0c9, r0c10, r0c11, r0c12, r0c13, err = transform(p[0]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r1c0, r1c1, r1c2, r1c3, r1c4, r1c5, r1c6, r1c7, r1c8, r1c9, r1c10, r1c11, r1c12, r1c13, err = transform(p[1]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r2c0, r2c1, r2c2, r2c3, r2c4, r2c5, r2c6, r2c7, r2c8, r2c9, r2c10, r2c11, r2c12, r2c13, err = transform(p[2]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r3c0, r3c1, r3c2, r3c3, r3c4, r3c5, r3c6, r3c7, r3c8, r3c9, r3c10, r3c11, r3c12, r3c13, err = transform(p[3]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r4c0, r4c1, r4c2, r4c3, r4c4, r4c5, r4c6, r4c7, r4c8, r4c9, r4c10, r4c11, r4c12, r4c13, err = transform(p[4]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		return NewMetadataScannerStatic(t.q.QueryContext(t.ctx, query, r0c0, r0c1, r0c2, r0c3, r0c4, r0c5, r0c6, r0c7, r0c8, r0c9, r0c10, r0c11, r0c12, r0c13, r1c0, r1c1, r1c2, r1c3, r1c4, r1c5, r1c6, r1c7, r1c8, r1c9, r1c10, r1c11, r1c12, r1c13, r2c0, r2c1, r2c2, r2c3, r2c4, r2c5, r2c6, r2c7, r2c8, r2c9, r2c10, r2c11, r2c12, r2c13, r3c0, r3c1, r3c2, r3c3, r3c4, r3c5, r3c6, r3c7, r3c8, r3c9, r3c10, r3c11, r3c12, r3c13, r4c0, r4c1, r4c2, r4c3, r4c4, r4c5, r4c6, r4c7, r4c8, r4c9, r4c10, r4c11, r4c12, r4c13)), p[5:], true
	case 6:
		const query = `INSERT INTO "torrents_metadata" ("archivable","auto_description","bytes","created_at","description","downloaded","encryption_seed","hidden_at","id","infohash","initiated_at","known_media_id","next_announce_at","paused_at","peers","private","seeding","tracker","updated_at","uploaded","verify_at") VALUES ($1,$2,$3,DEFAULT,$4,DEFAULT,$5,DEFAULT,$6,$7,DEFAULT,$8,DEFAULT,DEFAULT,$9,$10,$11,$12,DEFAULT,$13,$14),($15,$16,$17,DEFAULT,$18,DEFAULT,$19,DEFAULT,$20,$21,DEFAULT,$22,DEFAULT,DEFAULT,$23,$24,$25,$26,DEFAULT,$27,$28),($29,$30,$31,DEFAULT,$32,DEFAULT,$33,DEFAULT,$34,$35,DEFAULT,$36,DEFAULT,DEFAULT,$37,$38,$39,$40,DEFAULT,$41,$42),($43,$44,$45,DEFAULT,$46,DEFAULT,$47,DEFAULT,$48,$49,DEFAULT,$50,DEFAULT,DEFAULT,$51,$52,$53,$54,DEFAULT,$55,$56),($57,$58,$59,DEFAULT,$60,DEFAULT,$61,DEFAULT,$62,$63,DEFAULT,$64,DEFAULT,DEFAULT,$65,$66,$67,$68,DEFAULT,$69,$70),($71,$72,$73,DEFAULT,$74,DEFAULT,$75,DEFAULT,$76,$77,DEFAULT,$78,DEFAULT,DEFAULT,$79,$80,$81,$82,DEFAULT,$83,$84) RETURNING "archivable","auto_description","bytes","created_at","description","downloaded","encryption_seed","hidden_at","id","infohash","initiated_at","known_media_id","next_announce_at","paused_at","peers","private","seeding","tracker","updated_at","uploaded","verify_at"`
		var (
			r0c0  sql.NullBool
			r0c1  sql.NullString
			r0c2  ducktype.NullUint64
			r0c3  sql.NullString
			r0c4  sql.NullString
			r0c5  sql.NullString
			r0c6  []byte
			r0c7  sql.NullString
			r0c8  sql.NullInt32
			r0c9  sql.NullBool
			r0c10 sql.NullBool
			r0c11 sql.NullString
			r0c12 ducktype.NullUint64
			r0c13 sql.NullTime
			r1c0  sql.NullBool
			r1c1  sql.NullString
			r1c2  ducktype.NullUint64
			r1c3  sql.NullString
			r1c4  sql.NullString
			r1c5  sql.NullString
			r1c6  []byte
			r1c7  sql.NullString
			r1c8  sql.NullInt32
			r1c9  sql.NullBool
			r1c10 sql.NullBool
			r1c11 sql.NullString
			r1c12 ducktype.NullUint64
			r1c13 sql.NullTime
			r2c0  sql.NullBool
			r2c1  sql.NullString
			r2c2  ducktype.NullUint64
			r2c3  sql.NullString
			r2c4  sql.NullString
			r2c5  sql.NullString
			r2c6  []byte
			r2c7  sql.NullString
			r2c8  sql.NullInt32
			r2c9  sql.NullBool
			r2c10 sql.NullBool
			r2c11 sql.NullString
			r2c12 ducktype.NullUint64
			r2c13 sql.NullTime
			r3c0  sql.NullBool
			r3c1  sql.NullString
			r3c2  ducktype.NullUint64
			r3c3  sql.NullString
			r3c4  sql.NullString
			r3c5  sql.NullString
			r3c6  []byte
			r3c7  sql.NullString
			r3c8  sql.NullInt32
			r3c9  sql.NullBool
			r3c10 sql.NullBool
			r3c11 sql.NullString
			r3c12 ducktype.NullUint64
			r3c13 sql.NullTime
			r4c0  sql.NullBool
			r4c1  sql.NullString
			r4c2  ducktype.NullUint64
			r4c3  sql.NullString
			r4c4  sql.NullString
			r4c5  sql.NullString
			r4c6  []byte
			r4c7  sql.NullString
			r4c8  sql.NullInt32
			r4c9  sql.NullBool
			r4c10 sql.NullBool
			r4c11 sql.NullString
			r4c12 ducktype.NullUint64
			r4c13 sql.NullTime
			r5c0  sql.NullBool
			r5c1  sql.NullString
			r5c2  ducktype.NullUint64
			r5c3  sql.NullString
			r5c4  sql.NullString
			r5c5  sql.NullString
			r5c6  []byte
			r5c7  sql.NullString
			r5c8  sql.NullInt32
			r5c9  sql.NullBool
			r5c10 sql.NullBool
			r5c11 sql.NullString
			r5c12 ducktype.NullUint64
			r5c13 sql.NullTime
			err   error
		)
		if r0c0, r0c1, r0c2, r0c3, r0c4, r0c5, r0c6, r0c7, r0c8, r0c9, r0c10, r0c11, r0c12, r0c13, err = transform(p[0]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r1c0, r1c1, r1c2, r1c3, r1c4, r1c5, r1c6, r1c7, r1c8, r1c9, r1c10, r1c11, r1c12, r1c13, err = transform(p[1]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r2c0, r2c1, r2c2, r2c3, r2c4, r2c5, r2c6, r2c7, r2c8, r2c9, r2c10, r2c11, r2c12, r2c13, err = transform(p[2]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r3c0, r3c1, r3c2, r3c3, r3c4, r3c5, r3c6, r3c7, r3c8, r3c9, r3c10, r3c11, r3c12, r3c13, err = transform(p[3]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r4c0, r4c1, r4c2, r4c3, r4c4, r4c5, r4c6, r4c7, r4c8, r4c9, r4c10, r4c11, r4c12, r4c13, err = transform(p[4]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r5c0, r5c1, r5c2, r5c3, r5c4, r5c5, r5c6, r5c7, r5c8, r5c9, r5c10, r5c11, r5c12, r5c13, err = transform(p[5]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		return NewMetadataScannerStatic(t.q.QueryContext(t.ctx, query, r0c0, r0c1, r0c2, r0c3, r0c4, r0c5, r0c6, r0c7, r0c8, r0c9, r0c10, r0c11, r0c12, r0c13, r1c0, r1c1, r1c2, r1c3, r1c4, r1c5, r1c6, r1c7, r1c8, r1c9, r1c10, r1c11, r1c12, r1c13, r2c0, r2c1, r2c2, r2c3, r2c4, r2c5, r2c6, r2c7, r2c8, r2c9, r2c10, r2c11, r2c12, r2c13, r3c0, r3c1, r3c2, r3c3, r3c4, r3c5, r3c6, r3c7, r3c8, r3c9, r3c10, r3c11, r3c12, r3c13, r4c0, r4c1, r4c2, r4c3, r4c4, r4c5, r4c6, r4c7, r4c8, r4c9, r4c10, r4c11, r4c12, r4c13, r5c0, r5c1, r5c2, r5c3, r5c4, r5c5, r5c6, r5c7, r5c8, r5c9, r5c10, r5c11, r5c12, r5c13)), p[6:], true
	case 7:
		const query = `INSERT INTO "torrents_metadata" ("archivable","auto_description","bytes","created_at","description","downloaded","encryption_seed","hidden_at","id","infohash","initiated_at","known_media_id","next_announce_at","paused_at","peers","private","seeding","tracker","updated_at","uploaded","verify_at") VALUES ($1,$2,$3,DEFAULT,$4,DEFAULT,$5,DEFAULT,$6,$7,DEFAULT,$8,DEFAULT,DEFAULT,$9,$10,$11,$12,DEFAULT,$13,$14),($15,$16,$17,DEFAULT,$18,DEFAULT,$19,DEFAULT,$20,$21,DEFAULT,$22,DEFAULT,DEFAULT,$23,$24,$25,$26,DEFAULT,$27,$28),($29,$30,$31,DEFAULT,$32,DEFAULT,$33,DEFAULT,$34,$35,DEFAULT,$36,DEFAULT,DEFAULT,$37,$38,$39,$40,DEFAULT,$41,$42),($43,$44,$45,DEFAULT,$46,DEFAULT,$47,DEFAULT,$48,$49,DEFAULT,$50,DEFAULT,DEFAULT,$51,$52,$53,$54,DEFAULT,$55,$56),($57,$58,$59,DEFAULT,$60,DEFAULT,$61,DEFAULT,$62,$63,DEFAULT,$64,DEFAULT,DEFAULT,$65,$66,$67,$68,DEFAULT,$69,$70),($71,$72,$73,DEFAULT,$74,DEFAULT,$75,DEFAULT,$76,$77,DEFAULT,$78,DEFAULT,DEFAULT,$79,$80,$81,$82,DEFAULT,$83,$84),($85,$86,$87,DEFAULT,$88,DEFAULT,$89,DEFAULT,$90,$91,DEFAULT,$92,DEFAULT,DEFAULT,$93,$94,$95,$96,DEFAULT,$97,$98) RETURNING "archivable","auto_description","bytes","created_at","description","downloaded","encryption_seed","hidden_at","id","infohash","initiated_at","known_media_id","next_announce_at","paused_at","peers","private","seeding","tracker","updated_at","uploaded","verify_at"`
		var (
			r0c0  sql.NullBool
			r0c1  sql.NullString
			r0c2  ducktype.NullUint64
			r0c3  sql.NullString
			r0c4  sql.NullString
			r0c5  sql.NullString
			r0c6  []byte
			r0c7  sql.NullString
			r0c8  sql.NullInt32
			r0c9  sql.NullBool
			r0c10 sql.NullBool
			r0c11 sql.NullString
			r0c12 ducktype.NullUint64
			r0c13 sql.NullTime
			r1c0  sql.NullBool
			r1c1  sql.NullString
			r1c2  ducktype.NullUint64
			r1c3  sql.NullString
			r1c4  sql.NullString
			r1c5  sql.NullString
			r1c6  []byte
			r1c7  sql.NullString
			r1c8  sql.NullInt32
			r1c9  sql.NullBool
			r1c10 sql.NullBool
			r1c11 sql.NullString
			r1c12 ducktype.NullUint64
			r1c13 sql.NullTime
			r2c0  sql.NullBool
			r2c1  sql.NullString
			r2c2  ducktype.NullUint64
			r2c3  sql.NullString
			r2c4  sql.NullString
			r2c5  sql.NullString
			r2c6  []byte
			r2c7  sql.NullString
			r2c8  sql.NullInt32
			r2c9  sql.NullBool
			r2c10 sql.NullBool
			r2c11 sql.NullString
			r2c12 ducktype.NullUint64
			r2c13 sql.NullTime
			r3c0  sql.NullBool
			r3c1  sql.NullString
			r3c2  ducktype.NullUint64
			r3c3  sql.NullString
			r3c4  sql.NullString
			r3c5  sql.NullString
			r3c6  []byte
			r3c7  sql.NullString
			r3c8  sql.NullInt32
			r3c9  sql.NullBool
			r3c10 sql.NullBool
			r3c11 sql.NullString
			r3c12 ducktype.NullUint64
			r3c13 sql.NullTime
			r4c0  sql.NullBool
			r4c1  sql.NullString
			r4c2  ducktype.NullUint64
			r4c3  sql.NullString
			r4c4  sql.NullString
			r4c5  sql.NullString
			r4c6  []byte
			r4c7  sql.NullString
			r4c8  sql.NullInt32
			r4c9  sql.NullBool
			r4c10 sql.NullBool
			r4c11 sql.NullString
			r4c12 ducktype.NullUint64
			r4c13 sql.NullTime
			r5c0  sql.NullBool
			r5c1  sql.NullString
			r5c2  ducktype.NullUint64
			r5c3  sql.NullString
			r5c4  sql.NullString
			r5c5  sql.NullString
			r5c6  []byte
			r5c7  sql.NullString
			r5c8  sql.NullInt32
			r5c9  sql.NullBool
			r5c10 sql.NullBool
			r5c11 sql.NullString
			r5c12 ducktype.NullUint64
			r5c13 sql.NullTime
			r6c0  sql.NullBool
			r6c1  sql.NullString
			r6c2  ducktype.NullUint64
			r6c3  sql.NullString
			r6c4  sql.NullString
			r6c5  sql.NullString
			r6c6  []byte
			r6c7  sql.NullString
			r6c8  sql.NullInt32
			r6c9  sql.NullBool
			r6c10 sql.NullBool
			r6c11 sql.NullString
			r6c12 ducktype.NullUint64
			r6c13 sql.NullTime
			err   error
		)
		if r0c0, r0c1, r0c2, r0c3, r0c4, r0c5, r0c6, r0c7, r0c8, r0c9, r0c10, r0c11, r0c12, r0c13, err = transform(p[0]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r1c0, r1c1, r1c2, r1c3, r1c4, r1c5, r1c6, r1c7, r1c8, r1c9, r1c10, r1c11, r1c12, r1c13, err = transform(p[1]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r2c0, r2c1, r2c2, r2c3, r2c4, r2c5, r2c6, r2c7, r2c8, r2c9, r2c10, r2c11, r2c12, r2c13, err = transform(p[2]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r3c0, r3c1, r3c2, r3c3, r3c4, r3c5, r3c6, r3c7, r3c8, r3c9, r3c10, r3c11, r3c12, r3c13, err = transform(p[3]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r4c0, r4c1, r4c2, r4c3, r4c4, r4c5, r4c6, r4c7, r4c8, r4c9, r4c10, r4c11, r4c12, r4c13, err = transform(p[4]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r5c0, r5c1, r5c2, r5c3, r5c4, r5c5, r5c6, r5c7, r5c8, r5c9, r5c10, r5c11, r5c12, r5c13, err = transform(p[5]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r6c0, r6c1, r6c2, r6c3, r6c4, r6c5, r6c6, r6c7, r6c8, r6c9, r6c10, r6c11, r6c12, r6c13, err = transform(p[6]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		return NewMetadataScannerStatic(t.q.QueryContext(t.ctx, query, r0c0, r0c1, r0c2, r0c3, r0c4, r0c5, r0c6, r0c7, r0c8, r0c9, r0c10, r0c11, r0c12, r0c13, r1c0, r1c1, r1c2, r1c3, r1c4, r1c5, r1c6, r1c7, r1c8, r1c9, r1c10, r1c11, r1c12, r1c13, r2c0, r2c1, r2c2, r2c3, r2c4, r2c5, r2c6, r2c7, r2c8, r2c9, r2c10, r2c11, r2c12, r2c13, r3c0, r3c1, r3c2, r3c3, r3c4, r3c5, r3c6, r3c7, r3c8, r3c9, r3c10, r3c11, r3c12, r3c13, r4c0, r4c1, r4c2, r4c3, r4c4, r4c5, r4c6, r4c7, r4c8, r4c9, r4c10, r4c11, r4c12, r4c13, r5c0, r5c1, r5c2, r5c3, r5c4, r5c5, r5c6, r5c7, r5c8, r5c9, r5c10, r5c11, r5c12, r5c13, r6c0, r6c1, r6c2, r6c3, r6c4, r6c5, r6c6, r6c7, r6c8, r6c9, r6c10, r6c11, r6c12, r6c13)), p[7:], true
	case 8:
		const query = `INSERT INTO "torrents_metadata" ("archivable","auto_description","bytes","created_at","description","downloaded","encryption_seed","hidden_at","id","infohash","initiated_at","known_media_id","next_announce_at","paused_at","peers","private","seeding","tracker","updated_at","uploaded","verify_at") VALUES ($1,$2,$3,DEFAULT,$4,DEFAULT,$5,DEFAULT,$6,$7,DEFAULT,$8,DEFAULT,DEFAULT,$9,$10,$11,$12,DEFAULT,$13,$14),($15,$16,$17,DEFAULT,$18,DEFAULT,$19,DEFAULT,$20,$21,DEFAULT,$22,DEFAULT,DEFAULT,$23,$24,$25,$26,DEFAULT,$27,$28),($29,$30,$31,DEFAULT,$32,DEFAULT,$33,DEFAULT,$34,$35,DEFAULT,$36,DEFAULT,DEFAULT,$37,$38,$39,$40,DEFAULT,$41,$42),($43,$44,$45,DEFAULT,$46,DEFAULT,$47,DEFAULT,$48,$49,DEFAULT,$50,DEFAULT,DEFAULT,$51,$52,$53,$54,DEFAULT,$55,$56),($57,$58,$59,DEFAULT,$60,DEFAULT,$61,DEFAULT,$62,$63,DEFAULT,$64,DEFAULT,DEFAULT,$65,$66,$67,$68,DEFAULT,$69,$70),($71,$72,$73,DEFAULT,$74,DEFAULT,$75,DEFAULT,$76,$77,DEFAULT,$78,DEFAULT,DEFAULT,$79,$80,$81,$82,DEFAULT,$83,$84),($85,$86,$87,DEFAULT,$88,DEFAULT,$89,DEFAULT,$90,$91,DEFAULT,$92,DEFAULT,DEFAULT,$93,$94,$95,$96,DEFAULT,$97,$98),($99,$100,$101,DEFAULT,$102,DEFAULT,$103,DEFAULT,$104,$105,DEFAULT,$106,DEFAULT,DEFAULT,$107,$108,$109,$110,DEFAULT,$111,$112) RETURNING "archivable","auto_description","bytes","created_at","description","downloaded","encryption_seed","hidden_at","id","infohash","initiated_at","known_media_id","next_announce_at","paused_at","peers","private","seeding","tracker","updated_at","uploaded","verify_at"`
		var (
			r0c0  sql.NullBool
			r0c1  sql.NullString
			r0c2  ducktype.NullUint64
			r0c3  sql.NullString
			r0c4  sql.NullString
			r0c5  sql.NullString
			r0c6  []byte
			r0c7  sql.NullString
			r0c8  sql.NullInt32
			r0c9  sql.NullBool
			r0c10 sql.NullBool
			r0c11 sql.NullString
			r0c12 ducktype.NullUint64
			r0c13 sql.NullTime
			r1c0  sql.NullBool
			r1c1  sql.NullString
			r1c2  ducktype.NullUint64
			r1c3  sql.NullString
			r1c4  sql.NullString
			r1c5  sql.NullString
			r1c6  []byte
			r1c7  sql.NullString
			r1c8  sql.NullInt32
			r1c9  sql.NullBool
			r1c10 sql.NullBool
			r1c11 sql.NullString
			r1c12 ducktype.NullUint64
			r1c13 sql.NullTime
			r2c0  sql.NullBool
			r2c1  sql.NullString
			r2c2  ducktype.NullUint64
			r2c3  sql.NullString
			r2c4  sql.NullString
			r2c5  sql.NullString
			r2c6  []byte
			r2c7  sql.NullString
			r2c8  sql.NullInt32
			r2c9  sql.NullBool
			r2c10 sql.NullBool
			r2c11 sql.NullString
			r2c12 ducktype.NullUint64
			r2c13 sql.NullTime
			r3c0  sql.NullBool
			r3c1  sql.NullString
			r3c2  ducktype.NullUint64
			r3c3  sql.NullString
			r3c4  sql.NullString
			r3c5  sql.NullString
			r3c6  []byte
			r3c7  sql.NullString
			r3c8  sql.NullInt32
			r3c9  sql.NullBool
			r3c10 sql.NullBool
			r3c11 sql.NullString
			r3c12 ducktype.NullUint64
			r3c13 sql.NullTime
			r4c0  sql.NullBool
			r4c1  sql.NullString
			r4c2  ducktype.NullUint64
			r4c3  sql.NullString
			r4c4  sql.NullString
			r4c5  sql.NullString
			r4c6  []byte
			r4c7  sql.NullString
			r4c8  sql.NullInt32
			r4c9  sql.NullBool
			r4c10 sql.NullBool
			r4c11 sql.NullString
			r4c12 ducktype.NullUint64
			r4c13 sql.NullTime
			r5c0  sql.NullBool
			r5c1  sql.NullString
			r5c2  ducktype.NullUint64
			r5c3  sql.NullString
			r5c4  sql.NullString
			r5c5  sql.NullString
			r5c6  []byte
			r5c7  sql.NullString
			r5c8  sql.NullInt32
			r5c9  sql.NullBool
			r5c10 sql.NullBool
			r5c11 sql.NullString
			r5c12 ducktype.NullUint64
			r5c13 sql.NullTime
			r6c0  sql.NullBool
			r6c1  sql.NullString
			r6c2  ducktype.NullUint64
			r6c3  sql.NullString
			r6c4  sql.NullString
			r6c5  sql.NullString
			r6c6  []byte
			r6c7  sql.NullString
			r6c8  sql.NullInt32
			r6c9  sql.NullBool
			r6c10 sql.NullBool
			r6c11 sql.NullString
			r6c12 ducktype.NullUint64
			r6c13 sql.NullTime
			r7c0  sql.NullBool
			r7c1  sql.NullString
			r7c2  ducktype.NullUint64
			r7c3  sql.NullString
			r7c4  sql.NullString
			r7c5  sql.NullString
			r7c6  []byte
			r7c7  sql.NullString
			r7c8  sql.NullInt32
			r7c9  sql.NullBool
			r7c10 sql.NullBool
			r7c11 sql.NullString
			r7c12 ducktype.NullUint64
			r7c13 sql.NullTime
			err   error
		)
		if r0c0, r0c1, r0c2, r0c3, r0c4, r0c5, r0c6, r0c7, r0c8, r0c9, r0c10, r0c11, r0c12, r0c13, err = transform(p[0]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r1c0, r1c1, r1c2, r1c3, r1c4, r1c5, r1c6, r1c7, r1c8, r1c9, r1c10, r1c11, r1c12, r1c13, err = transform(p[1]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r2c0, r2c1, r2c2, r2c3, r2c4, r2c5, r2c6, r2c7, r2c8, r2c9, r2c10, r2c11, r2c12, r2c13, err = transform(p[2]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r3c0, r3c1, r3c2, r3c3, r3c4, r3c5, r3c6, r3c7, r3c8, r3c9, r3c10, r3c11, r3c12, r3c13, err = transform(p[3]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r4c0, r4c1, r4c2, r4c3, r4c4, r4c5, r4c6, r4c7, r4c8, r4c9, r4c10, r4c11, r4c12, r4c13, err = transform(p[4]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r5c0, r5c1, r5c2, r5c3, r5c4, r5c5, r5c6, r5c7, r5c8, r5c9, r5c10, r5c11, r5c12, r5c13, err = transform(p[5]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r6c0, r6c1, r6c2, r6c3, r6c4, r6c5, r6c6, r6c7, r6c8, r6c9, r6c10, r6c11, r6c12, r6c13, err = transform(p[6]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r7c0, r7c1, r7c2, r7c3, r7c4, r7c5, r7c6, r7c7, r7c8, r7c9, r7c10, r7c11, r7c12, r7c13, err = transform(p[7]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		return NewMetadataScannerStatic(t.q.QueryContext(t.ctx, query, r0c0, r0c1, r0c2, r0c3, r0c4, r0c5, r0c6, r0c7, r0c8, r0c9, r0c10, r0c11, r0c12, r0c13, r1c0, r1c1, r1c2, r1c3, r1c4, r1c5, r1c6, r1c7, r1c8, r1c9, r1c10, r1c11, r1c12, r1c13, r2c0, r2c1, r2c2, r2c3, r2c4, r2c5, r2c6, r2c7, r2c8, r2c9, r2c10, r2c11, r2c12, r2c13, r3c0, r3c1, r3c2, r3c3, r3c4, r3c5, r3c6, r3c7, r3c8, r3c9, r3c10, r3c11, r3c12, r3c13, r4c0, r4c1, r4c2, r4c3, r4c4, r4c5, r4c6, r4c7, r4c8, r4c9, r4c10, r4c11, r4c12, r4c13, r5c0, r5c1, r5c2, r5c3, r5c4, r5c5, r5c6, r5c7, r5c8, r5c9, r5c10, r5c11, r5c12, r5c13, r6c0, r6c1, r6c2, r6c3, r6c4, r6c5, r6c6, r6c7, r6c8, r6c9, r6c10, r6c11, r6c12, r6c13, r7c0, r7c1, r7c2, r7c3, r7c4, r7c5, r7c6, r7c7, r7c8, r7c9, r7c10, r7c11, r7c12, r7c13)), p[8:], true
	case 9:
		const query = `INSERT INTO "torrents_metadata" ("archivable","auto_description","bytes","created_at","description","downloaded","encryption_seed","hidden_at","id","infohash","initiated_at","known_media_id","next_announce_at","paused_at","peers","private","seeding","tracker","updated_at","uploaded","verify_at") VALUES ($1,$2,$3,DEFAULT,$4,DEFAULT,$5,DEFAULT,$6,$7,DEFAULT,$8,DEFAULT,DEFAULT,$9,$10,$11,$12,DEFAULT,$13,$14),($15,$16,$17,DEFAULT,$18,DEFAULT,$19,DEFAULT,$20,$21,DEFAULT,$22,DEFAULT,DEFAULT,$23,$24,$25,$26,DEFAULT,$27,$28),($29,$30,$31,DEFAULT,$32,DEFAULT,$33,DEFAULT,$34,$35,DEFAULT,$36,DEFAULT,DEFAULT,$37,$38,$39,$40,DEFAULT,$41,$42),($43,$44,$45,DEFAULT,$46,DEFAULT,$47,DEFAULT,$48,$49,DEFAULT,$50,DEFAULT,DEFAULT,$51,$52,$53,$54,DEFAULT,$55,$56),($57,$58,$59,DEFAULT,$60,DEFAULT,$61,DEFAULT,$62,$63,DEFAULT,$64,DEFAULT,DEFAULT,$65,$66,$67,$68,DEFAULT,$69,$70),($71,$72,$73,DEFAULT,$74,DEFAULT,$75,DEFAULT,$76,$77,DEFAULT,$78,DEFAULT,DEFAULT,$79,$80,$81,$82,DEFAULT,$83,$84),($85,$86,$87,DEFAULT,$88,DEFAULT,$89,DEFAULT,$90,$91,DEFAULT,$92,DEFAULT,DEFAULT,$93,$94,$95,$96,DEFAULT,$97,$98),($99,$100,$101,DEFAULT,$102,DEFAULT,$103,DEFAULT,$104,$105,DEFAULT,$106,DEFAULT,DEFAULT,$107,$108,$109,$110,DEFAULT,$111,$112),($113,$114,$115,DEFAULT,$116,DEFAULT,$117,DEFAULT,$118,$119,DEFAULT,$120,DEFAULT,DEFAULT,$121,$122,$123,$124,DEFAULT,$125,$126) RETURNING "archivable","auto_description","bytes","created_at","description","downloaded","encryption_seed","hidden_at","id","infohash","initiated_at","known_media_id","next_announce_at","paused_at","peers","private","seeding","tracker","updated_at","uploaded","verify_at"`
		var (
			r0c0  sql.NullBool
			r0c1  sql.NullString
			r0c2  ducktype.NullUint64
			r0c3  sql.NullString
			r0c4  sql.NullString
			r0c5  sql.NullString
			r0c6  []byte
			r0c7  sql.NullString
			r0c8  sql.NullInt32
			r0c9  sql.NullBool
			r0c10 sql.NullBool
			r0c11 sql.NullString
			r0c12 ducktype.NullUint64
			r0c13 sql.NullTime
			r1c0  sql.NullBool
			r1c1  sql.NullString
			r1c2  ducktype.NullUint64
			r1c3  sql.NullString
			r1c4  sql.NullString
			r1c5  sql.NullString
			r1c6  []byte
			r1c7  sql.NullString
			r1c8  sql.NullInt32
			r1c9  sql.NullBool
			r1c10 sql.NullBool
			r1c11 sql.NullString
			r1c12 ducktype.NullUint64
			r1c13 sql.NullTime
			r2c0  sql.NullBool
			r2c1  sql.NullString
			r2c2  ducktype.NullUint64
			r2c3  sql.NullString
			r2c4  sql.NullString
			r2c5  sql.NullString
			r2c6  []byte
			r2c7  sql.NullString
			r2c8  sql.NullInt32
			r2c9  sql.NullBool
			r2c10 sql.NullBool
			r2c11 sql.NullString
			r2c12 ducktype.NullUint64
			r2c13 sql.NullTime
			r3c0  sql.NullBool
			r3c1  sql.NullString
			r3c2  ducktype.NullUint64
			r3c3  sql.NullString
			r3c4  sql.NullString
			r3c5  sql.NullString
			r3c6  []byte
			r3c7  sql.NullString
			r3c8  sql.NullInt32
			r3c9  sql.NullBool
			r3c10 sql.NullBool
			r3c11 sql.NullString
			r3c12 ducktype.NullUint64
			r3c13 sql.NullTime
			r4c0  sql.NullBool
			r4c1  sql.NullString
			r4c2  ducktype.NullUint64
			r4c3  sql.NullString
			r4c4  sql.NullString
			r4c5  sql.NullString
			r4c6  []byte
			r4c7  sql.NullString
			r4c8  sql.NullInt32
			r4c9  sql.NullBool
			r4c10 sql.NullBool
			r4c11 sql.NullString
			r4c12 ducktype.NullUint64
			r4c13 sql.NullTime
			r5c0  sql.NullBool
			r5c1  sql.NullString
			r5c2  ducktype.NullUint64
			r5c3  sql.NullString
			r5c4  sql.NullString
			r5c5  sql.NullString
			r5c6  []byte
			r5c7  sql.NullString
			r5c8  sql.NullInt32
			r5c9  sql.NullBool
			r5c10 sql.NullBool
			r5c11 sql.NullString
			r5c12 ducktype.NullUint64
			r5c13 sql.NullTime
			r6c0  sql.NullBool
			r6c1  sql.NullString
			r6c2  ducktype.NullUint64
			r6c3  sql.NullString
			r6c4  sql.NullString
			r6c5  sql.NullString
			r6c6  []byte
			r6c7  sql.NullString
			r6c8  sql.NullInt32
			r6c9  sql.NullBool
			r6c10 sql.NullBool
			r6c11 sql.NullString
			r6c12 ducktype.NullUint64
			r6c13 sql.NullTime
			r7c0  sql.NullBool
			r7c1  sql.NullString
			r7c2  ducktype.NullUint64
			r7c3  sql.NullString
			r7c4  sql.NullString
			r7c5  sql.NullString
			r7c6  []byte
			r7c7  sql.NullString
			r7c8  sql.NullInt32
			r7c9  sql.NullBool
			r7c10 sql.NullBool
			r7c11 sql.NullString
			r7c12 ducktype.NullUint64
			r7c13 sql.NullTime
			r8c0  sql.NullBool
			r8c1  sql.NullString
			r8c2  ducktype.NullUint64
			r8c3  sql.NullString
			r8c4  sql.NullString
			r8c5  sql.NullString
			r8c6  []byte
			r8c7  sql.NullString
			r8c8  sql.NullInt32
			r8c9  sql.NullBool
			r8c10 sql.NullBool
			r8c11 sql.NullString
			r8c12 ducktype.NullUint64
			r8c13 sql.NullTime
			err   error
		)
		if r0c0, r0c1, r0c2, r0c3, r0c4, r0c5, r0c6, r0c7, r0c8, r0c9, r0c10, r0c11, r0c12, r0c13, err = transform(p[0]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r1c0, r1c1, r1c2, r1c3, r1c4, r1c5, r1c6, r1c7, r1c8, r1c9, r1c10, r1c11, r1c12, r1c13, err = transform(p[1]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r2c0, r2c1, r2c2, r2c3, r2c4, r2c5, r2c6, r2c7, r2c8, r2c9, r2c10, r2c11, r2c12, r2c13, err = transform(p[2]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r3c0, r3c1, r3c2, r3c3, r3c4, r3c5, r3c6, r3c7, r3c8, r3c9, r3c10, r3c11, r3c12, r3c13, err = transform(p[3]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r4c0, r4c1, r4c2, r4c3, r4c4, r4c5, r4c6, r4c7, r4c8, r4c9, r4c10, r4c11, r4c12, r4c13, err = transform(p[4]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r5c0, r5c1, r5c2, r5c3, r5c4, r5c5, r5c6, r5c7, r5c8, r5c9, r5c10, r5c11, r5c12, r5c13, err = transform(p[5]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r6c0, r6c1, r6c2, r6c3, r6c4, r6c5, r6c6, r6c7, r6c8, r6c9, r6c10, r6c11, r6c12, r6c13, err = transform(p[6]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r7c0, r7c1, r7c2, r7c3, r7c4, r7c5, r7c6, r7c7, r7c8, r7c9, r7c10, r7c11, r7c12, r7c13, err = transform(p[7]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r8c0, r8c1, r8c2, r8c3, r8c4, r8c5, r8c6, r8c7, r8c8, r8c9, r8c10, r8c11, r8c12, r8c13, err = transform(p[8]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		return NewMetadataScannerStatic(t.q.QueryContext(t.ctx, query, r0c0, r0c1, r0c2, r0c3, r0c4, r0c5, r0c6, r0c7, r0c8, r0c9, r0c10, r0c11, r0c12, r0c13, r1c0, r1c1, r1c2, r1c3, r1c4, r1c5, r1c6, r1c7, r1c8, r1c9, r1c10, r1c11, r1c12, r1c13, r2c0, r2c1, r2c2, r2c3, r2c4, r2c5, r2c6, r2c7, r2c8, r2c9, r2c10, r2c11, r2c12, r2c13, r3c0, r3c1, r3c2, r3c3, r3c4, r3c5, r3c6, r3c7, r3c8, r3c9, r3c10, r3c11, r3c12, r3c13, r4c0, r4c1, r4c2, r4c3, r4c4, r4c5, r4c6, r4c7, r4c8, r4c9, r4c10, r4c11, r4c12, r4c13, r5c0, r5c1, r5c2, r5c3, r5c4, r5c5, r5c6, r5c7, r5c8, r5c9, r5c10, r5c11, r5c12, r5c13, r6c0, r6c1, r6c2, r6c3, r6c4, r6c5, r6c6, r6c7, r6c8, r6c9, r6c10, r6c11, r6c12, r6c13, r7c0, r7c1, r7c2, r7c3, r7c4, r7c5, r7c6, r7c7, r7c8, r7c9, r7c10, r7c11, r7c12, r7c13, r8c0, r8c1, r8c2, r8c3, r8c4, r8c5, r8c6, r8c7, r8c8, r8c9, r8c10, r8c11, r8c12, r8c13)), p[9:], true
	default:
		const query = `INSERT INTO "torrents_metadata" ("archivable","auto_description","bytes","created_at","description","downloaded","encryption_seed","hidden_at","id","infohash","initiated_at","known_media_id","next_announce_at","paused_at","peers","private","seeding","tracker","updated_at","uploaded","verify_at") VALUES ($1,$2,$3,DEFAULT,$4,DEFAULT,$5,DEFAULT,$6,$7,DEFAULT,$8,DEFAULT,DEFAULT,$9,$10,$11,$12,DEFAULT,$13,$14),($15,$16,$17,DEFAULT,$18,DEFAULT,$19,DEFAULT,$20,$21,DEFAULT,$22,DEFAULT,DEFAULT,$23,$24,$25,$26,DEFAULT,$27,$28),($29,$30,$31,DEFAULT,$32,DEFAULT,$33,DEFAULT,$34,$35,DEFAULT,$36,DEFAULT,DEFAULT,$37,$38,$39,$40,DEFAULT,$41,$42),($43,$44,$45,DEFAULT,$46,DEFAULT,$47,DEFAULT,$48,$49,DEFAULT,$50,DEFAULT,DEFAULT,$51,$52,$53,$54,DEFAULT,$55,$56),($57,$58,$59,DEFAULT,$60,DEFAULT,$61,DEFAULT,$62,$63,DEFAULT,$64,DEFAULT,DEFAULT,$65,$66,$67,$68,DEFAULT,$69,$70),($71,$72,$73,DEFAULT,$74,DEFAULT,$75,DEFAULT,$76,$77,DEFAULT,$78,DEFAULT,DEFAULT,$79,$80,$81,$82,DEFAULT,$83,$84),($85,$86,$87,DEFAULT,$88,DEFAULT,$89,DEFAULT,$90,$91,DEFAULT,$92,DEFAULT,DEFAULT,$93,$94,$95,$96,DEFAULT,$97,$98),($99,$100,$101,DEFAULT,$102,DEFAULT,$103,DEFAULT,$104,$105,DEFAULT,$106,DEFAULT,DEFAULT,$107,$108,$109,$110,DEFAULT,$111,$112),($113,$114,$115,DEFAULT,$116,DEFAULT,$117,DEFAULT,$118,$119,DEFAULT,$120,DEFAULT,DEFAULT,$121,$122,$123,$124,DEFAULT,$125,$126),($127,$128,$129,DEFAULT,$130,DEFAULT,$131,DEFAULT,$132,$133,DEFAULT,$134,DEFAULT,DEFAULT,$135,$136,$137,$138,DEFAULT,$139,$140) RETURNING "archivable","auto_description","bytes","created_at","description","downloaded","encryption_seed","hidden_at","id","infohash","initiated_at","known_media_id","next_announce_at","paused_at","peers","private","seeding","tracker","updated_at","uploaded","verify_at"`
		var (
			r0c0  sql.NullBool
			r0c1  sql.NullString
			r0c2  ducktype.NullUint64
			r0c3  sql.NullString
			r0c4  sql.NullString
			r0c5  sql.NullString
			r0c6  []byte
			r0c7  sql.NullString
			r0c8  sql.NullInt32
			r0c9  sql.NullBool
			r0c10 sql.NullBool
			r0c11 sql.NullString
			r0c12 ducktype.NullUint64
			r0c13 sql.NullTime
			r1c0  sql.NullBool
			r1c1  sql.NullString
			r1c2  ducktype.NullUint64
			r1c3  sql.NullString
			r1c4  sql.NullString
			r1c5  sql.NullString
			r1c6  []byte
			r1c7  sql.NullString
			r1c8  sql.NullInt32
			r1c9  sql.NullBool
			r1c10 sql.NullBool
			r1c11 sql.NullString
			r1c12 ducktype.NullUint64
			r1c13 sql.NullTime
			r2c0  sql.NullBool
			r2c1  sql.NullString
			r2c2  ducktype.NullUint64
			r2c3  sql.NullString
			r2c4  sql.NullString
			r2c5  sql.NullString
			r2c6  []byte
			r2c7  sql.NullString
			r2c8  sql.NullInt32
			r2c9  sql.NullBool
			r2c10 sql.NullBool
			r2c11 sql.NullString
			r2c12 ducktype.NullUint64
			r2c13 sql.NullTime
			r3c0  sql.NullBool
			r3c1  sql.NullString
			r3c2  ducktype.NullUint64
			r3c3  sql.NullString
			r3c4  sql.NullString
			r3c5  sql.NullString
			r3c6  []byte
			r3c7  sql.NullString
			r3c8  sql.NullInt32
			r3c9  sql.NullBool
			r3c10 sql.NullBool
			r3c11 sql.NullString
			r3c12 ducktype.NullUint64
			r3c13 sql.NullTime
			r4c0  sql.NullBool
			r4c1  sql.NullString
			r4c2  ducktype.NullUint64
			r4c3  sql.NullString
			r4c4  sql.NullString
			r4c5  sql.NullString
			r4c6  []byte
			r4c7  sql.NullString
			r4c8  sql.NullInt32
			r4c9  sql.NullBool
			r4c10 sql.NullBool
			r4c11 sql.NullString
			r4c12 ducktype.NullUint64
			r4c13 sql.NullTime
			r5c0  sql.NullBool
			r5c1  sql.NullString
			r5c2  ducktype.NullUint64
			r5c3  sql.NullString
			r5c4  sql.NullString
			r5c5  sql.NullString
			r5c6  []byte
			r5c7  sql.NullString
			r5c8  sql.NullInt32
			r5c9  sql.NullBool
			r5c10 sql.NullBool
			r5c11 sql.NullString
			r5c12 ducktype.NullUint64
			r5c13 sql.NullTime
			r6c0  sql.NullBool
			r6c1  sql.NullString
			r6c2  ducktype.NullUint64
			r6c3  sql.NullString
			r6c4  sql.NullString
			r6c5  sql.NullString
			r6c6  []byte
			r6c7  sql.NullString
			r6c8  sql.NullInt32
			r6c9  sql.NullBool
			r6c10 sql.NullBool
			r6c11 sql.NullString
			r6c12 ducktype.NullUint64
			r6c13 sql.NullTime
			r7c0  sql.NullBool
			r7c1  sql.NullString
			r7c2  ducktype.NullUint64
			r7c3  sql.NullString
			r7c4  sql.NullString
			r7c5  sql.NullString
			r7c6  []byte
			r7c7  sql.NullString
			r7c8  sql.NullInt32
			r7c9  sql.NullBool
			r7c10 sql.NullBool
			r7c11 sql.NullString
			r7c12 ducktype.NullUint64
			r7c13 sql.NullTime
			r8c0  sql.NullBool
			r8c1  sql.NullString
			r8c2  ducktype.NullUint64
			r8c3  sql.NullString
			r8c4  sql.NullString
			r8c5  sql.NullString
			r8c6  []byte
			r8c7  sql.NullString
			r8c8  sql.NullInt32
			r8c9  sql.NullBool
			r8c10 sql.NullBool
			r8c11 sql.NullString
			r8c12 ducktype.NullUint64
			r8c13 sql.NullTime
			r9c0  sql.NullBool
			r9c1  sql.NullString
			r9c2  ducktype.NullUint64
			r9c3  sql.NullString
			r9c4  sql.NullString
			r9c5  sql.NullString
			r9c6  []byte
			r9c7  sql.NullString
			r9c8  sql.NullInt32
			r9c9  sql.NullBool
			r9c10 sql.NullBool
			r9c11 sql.NullString
			r9c12 ducktype.NullUint64
			r9c13 sql.NullTime
			err   error
		)
		if r0c0, r0c1, r0c2, r0c3, r0c4, r0c5, r0c6, r0c7, r0c8, r0c9, r0c10, r0c11, r0c12, r0c13, err = transform(p[0]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r1c0, r1c1, r1c2, r1c3, r1c4, r1c5, r1c6, r1c7, r1c8, r1c9, r1c10, r1c11, r1c12, r1c13, err = transform(p[1]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r2c0, r2c1, r2c2, r2c3, r2c4, r2c5, r2c6, r2c7, r2c8, r2c9, r2c10, r2c11, r2c12, r2c13, err = transform(p[2]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r3c0, r3c1, r3c2, r3c3, r3c4, r3c5, r3c6, r3c7, r3c8, r3c9, r3c10, r3c11, r3c12, r3c13, err = transform(p[3]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r4c0, r4c1, r4c2, r4c3, r4c4, r4c5, r4c6, r4c7, r4c8, r4c9, r4c10, r4c11, r4c12, r4c13, err = transform(p[4]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r5c0, r5c1, r5c2, r5c3, r5c4, r5c5, r5c6, r5c7, r5c8, r5c9, r5c10, r5c11, r5c12, r5c13, err = transform(p[5]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r6c0, r6c1, r6c2, r6c3, r6c4, r6c5, r6c6, r6c7, r6c8, r6c9, r6c10, r6c11, r6c12, r6c13, err = transform(p[6]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r7c0, r7c1, r7c2, r7c3, r7c4, r7c5, r7c6, r7c7, r7c8, r7c9, r7c10, r7c11, r7c12, r7c13, err = transform(p[7]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r8c0, r8c1, r8c2, r8c3, r8c4, r8c5, r8c6, r8c7, r8c8, r8c9, r8c10, r8c11, r8c12, r8c13, err = transform(p[8]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r9c0, r9c1, r9c2, r9c3, r9c4, r9c5, r9c6, r9c7, r9c8, r9c9, r9c10, r9c11, r9c12, r9c13, err = transform(p[9]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		return NewMetadataScannerStatic(t.q.QueryContext(t.ctx, query, r0c0, r0c1, r0c2, r0c3, r0c4, r0c5, r0c6, r0c7, r0c8, r0c9, r0c10, r0c11, r0c12, r0c13, r1c0, r1c1, r1c2, r1c3, r1c4, r1c5, r1c6, r1c7, r1c8, r1c9, r1c10, r1c11, r1c12, r1c13, r2c0, r2c1, r2c2, r2c3, r2c4, r2c5, r2c6, r2c7, r2c8, r2c9, r2c10, r2c11, r2c12, r2c13, r3c0, r3c1, r3c2, r3c3, r3c4, r3c5, r3c6, r3c7, r3c8, r3c9, r3c10, r3c11, r3c12, r3c13, r4c0, r4c1, r4c2, r4c3, r4c4, r4c5, r4c6, r4c7, r4c8, r4c9, r4c10, r4c11, r4c12, r4c13, r5c0, r5c1, r5c2, r5c3, r5c4, r5c5, r5c6, r5c7, r5c8, r5c9, r5c10, r5c11, r5c12, r5c13, r6c0, r6c1, r6c2, r6c3, r6c4, r6c5, r6c6, r6c7, r6c8, r6c9, r6c10, r6c11, r6c12, r6c13, r7c0, r7c1, r7c2, r7c3, r7c4, r7c5, r7c6, r7c7, r7c8, r7c9, r7c10, r7c11, r7c12, r7c13, r8c0, r8c1, r8c2, r8c3, r8c4, r8c5, r8c6, r8c7, r8c8, r8c9, r8c10, r8c11, r8c12, r8c13, r9c0, r9c1, r9c2, r9c3, r9c4, r9c5, r9c6, r9c7, r9c8, r9c9, r9c10, r9c11, r9c12, r9c13)), []Metadata(nil), false
	}
}

// MetadataInsertWithDefaultsStaticColumns generated by genieql
const MetadataInsertWithDefaultsStaticColumns = `$1,$2,$3,DEFAULT,$4,DEFAULT,$5,DEFAULT,$6,$7,DEFAULT,$8,DEFAULT,DEFAULT,$9,$10,$11,$12,DEFAULT,$13,DEFAULT`

// MetadataInsertWithDefaultsExplode generated by genieql
func MetadataInsertWithDefaultsExplode(a *Metadata) ([]interface{}, error) {
	var (
		c0  sql.NullBool        // archivable
		c1  sql.NullString      // auto_description
		c2  ducktype.NullUint64 // bytes
		c3  sql.NullString      // description
		c4  sql.NullString      // encryption_seed
		c5  sql.NullString      // id
		c6  []byte              // infohash
		c7  sql.NullString      // known_media_id
		c8  sql.NullInt32       // peers
		c9  sql.NullBool        // private
		c10 sql.NullBool        // seeding
		c11 sql.NullString      // tracker
		c12 ducktype.NullUint64 // uploaded
	)

	c0.Valid = true
	c0.Bool = a.Archivable

	c1.Valid = true
	c1.String = a.AutoDescription

	c2.Valid = true
	c2.V = a.Bytes

	c3.Valid = true
	c3.String = a.Description

	c4.Valid = true
	c4.String = a.EncryptionSeed

	c5.Valid = true
	c5.String = a.ID

	c6 = a.Infohash

	c7.Valid = true
	c7.String = a.KnownMediaID

	c8.Valid = true
	c8.Int32 = int32(a.Peers)

	c9.Valid = true
	c9.Bool = a.Private

	c10.Valid = true
	c10.Bool = a.Seeding

	c11.Valid = true
	c11.String = a.Tracker

	c12.Valid = true
	c12.V = a.Uploaded

	return []interface{}{c0, c1, c2, c3, c4, c5, c6, c7, c8, c9, c10, c11, c12}, nil
}

// MetadataInsertWithDefaults generated by genieql
func MetadataInsertWithDefaults(ctx context.Context, q sqlx.Queryer, a Metadata) MetadataScannerStaticRow {
	const query = `INSERT INTO "torrents_metadata" ("archivable","auto_description","bytes","created_at","description","downloaded","encryption_seed","hidden_at","id","infohash","initiated_at","known_media_id","next_announce_at","paused_at","peers","private","seeding","tracker","updated_at","uploaded","verify_at") VALUES ($1,$2,$3,DEFAULT,$4,DEFAULT,$5,DEFAULT,$6,$7,DEFAULT,$8,DEFAULT,DEFAULT,$9,$10,$11,$12,DEFAULT,$13,DEFAULT) ON CONFLICT (id) DO UPDATE SET updated_at = DEFAULT, tracker = EXCLUDED.tracker RETURNING "archivable","auto_description","bytes","created_at","description","downloaded","encryption_seed","hidden_at","id","infohash","initiated_at","known_media_id","next_announce_at","paused_at","peers","private","seeding","tracker","updated_at","uploaded","verify_at"`
	var (
		c0  sql.NullBool        // archivable
		c1  sql.NullString      // auto_description
		c2  ducktype.NullUint64 // bytes
		c3  sql.NullString      // description
		c4  sql.NullString      // encryption_seed
		c5  sql.NullString      // id
		c6  []byte              // infohash
		c7  sql.NullString      // known_media_id
		c8  sql.NullInt32       // peers
		c9  sql.NullBool        // private
		c10 sql.NullBool        // seeding
		c11 sql.NullString      // tracker
		c12 ducktype.NullUint64
	)
	c0.Valid = true
	c0.Bool = a.Archivable
	c1.Valid = true
	c1.String = a.AutoDescription
	c2.Valid = true
	c2.V = a.Bytes
	c3.Valid = true
	c3.String = a.Description
	c4.Valid = true
	c4.String = a.EncryptionSeed
	c5.Valid = true
	c5.String = a.ID
	c6 = a.Infohash
	c7.Valid = true
	c7.String = a.KnownMediaID
	c8.Valid = true
	c8.Int32 = int32(a.Peers)
	c9.Valid = true
	c9.Bool = a.Private
	c10.Valid = true
	c10.Bool = a.Seeding
	c11.Valid = true
	c11.String = a.Tracker
	c12.Valid = true
	c12.V = a.Uploaded // uploaded
	return NewMetadataScannerStaticRow(q.QueryRowContext(ctx, query, c0, c1, c2, c3, c4, c5, c6, c7, c8, c9, c10, c11, c12))
}

// RSSInsertWithDefaultsStaticColumns generated by genieql
const RSSInsertWithDefaultsStaticColumns = `$1,$2,$3,DEFAULT,$4,DEFAULT,$5,$6,$7,DEFAULT,DEFAULT,$8`

// RSSInsertWithDefaultsExplode generated by genieql
func RSSInsertWithDefaultsExplode(a *RSS) ([]interface{}, error) {
	var (
		c0 sql.NullBool   // autoarchive
		c1 sql.NullBool   // autodownload
		c2 sql.NullBool   // contributing
		c3 sql.NullString // description
		c4 sql.NullString // encryption_seed
		c5 sql.NullString // id
		c6 sql.NullTime   // last_built_at
		c7 sql.NullString // url
	)

	c0.Valid = true
	c0.Bool = a.Autoarchive

	c1.Valid = true
	c1.Bool = a.Autodownload

	c2.Valid = true
	c2.Bool = a.Contributing

	c3.Valid = true
	c3.String = a.Description

	c4.Valid = true
	c4.String = a.EncryptionSeed

	c5.Valid = true
	c5.String = a.ID

	c6.Valid = true
	c6.Time = a.LastBuiltAt

	c7.Valid = true
	c7.String = a.URL

	return []interface{}{c0, c1, c2, c3, c4, c5, c6, c7}, nil
}

// RSSInsertWithDefaults generated by genieql
func RSSInsertWithDefaults(ctx context.Context, q sqlx.Queryer, a RSS) RSSScannerStaticRow {
	const query = `INSERT INTO "torrents_feed_rss" ("autoarchive","autodownload","contributing","created_at","description","disabled_at","encryption_seed","id","last_built_at","next_check","updated_at","url") VALUES ($1,$2,$3,DEFAULT,$4,DEFAULT,$5,$6,$7,DEFAULT,DEFAULT,$8) ON CONFLICT (id) DO UPDATE SET updated_at = DEFAULT, autodownload = EXCLUDED.autodownload, autoarchive = EXCLUDED.autoarchive, url = EXCLUDED.url, description = EXCLUDED.description RETURNING "autoarchive","autodownload","contributing","created_at","description","disabled_at","encryption_seed","id","last_built_at","next_check","updated_at","url"`
	var (
		c0 sql.NullBool   // autoarchive
		c1 sql.NullBool   // autodownload
		c2 sql.NullBool   // contributing
		c3 sql.NullString // description
		c4 sql.NullString // encryption_seed
		c5 sql.NullString // id
		c6 sql.NullTime   // last_built_at
		c7 sql.NullString
	)
	c0.Valid = true
	c0.Bool = a.Autoarchive
	c1.Valid = true
	c1.Bool = a.Autodownload
	c2.Valid = true
	c2.Bool = a.Contributing
	c3.Valid = true
	c3.String = a.Description
	c4.Valid = true
	c4.String = a.EncryptionSeed
	c5.Valid = true
	c5.String = a.ID
	c6.Valid = true
	c6.Time = a.LastBuiltAt
	c7.Valid = true
	c7.String = a.URL // url
	return NewRSSScannerStaticRow(q.QueryRowContext(ctx, query, c0, c1, c2, c3, c4, c5, c6, c7))
}

// RSSInsertDefaultFeedStaticColumns generated by genieql
const RSSInsertDefaultFeedStaticColumns = `$1,$2,$3,DEFAULT,$4,DEFAULT,$5,$6,$7,DEFAULT,DEFAULT,$8`

// RSSInsertDefaultFeedExplode generated by genieql
func RSSInsertDefaultFeedExplode(a *RSS) ([]interface{}, error) {
	var (
		c0 sql.NullBool   // autoarchive
		c1 sql.NullBool   // autodownload
		c2 sql.NullBool   // contributing
		c3 sql.NullString // description
		c4 sql.NullString // encryption_seed
		c5 sql.NullString // id
		c6 sql.NullTime   // last_built_at
		c7 sql.NullString // url
	)

	c0.Valid = true
	c0.Bool = a.Autoarchive

	c1.Valid = true
	c1.Bool = a.Autodownload

	c2.Valid = true
	c2.Bool = a.Contributing

	c3.Valid = true
	c3.String = a.Description

	c4.Valid = true
	c4.String = a.EncryptionSeed

	c5.Valid = true
	c5.String = a.ID

	c6.Valid = true
	c6.Time = a.LastBuiltAt

	c7.Valid = true
	c7.String = a.URL

	return []interface{}{c0, c1, c2, c3, c4, c5, c6, c7}, nil
}

// RSSInsertDefaultFeed generated by genieql
func RSSInsertDefaultFeed(ctx context.Context, q sqlx.Queryer, a RSS) RSSScannerStaticRow {
	const query = `INSERT INTO "torrents_feed_rss" ("autoarchive","autodownload","contributing","created_at","description","disabled_at","encryption_seed","id","last_built_at","next_check","updated_at","url") VALUES ($1,$2,$3,DEFAULT,$4,DEFAULT,$5,$6,$7,DEFAULT,DEFAULT,$8) ON CONFLICT (id) DO UPDATE SET updated_at = DEFAULT RETURNING "autoarchive","autodownload","contributing","created_at","description","disabled_at","encryption_seed","id","last_built_at","next_check","updated_at","url"`
	var (
		c0 sql.NullBool   // autoarchive
		c1 sql.NullBool   // autodownload
		c2 sql.NullBool   // contributing
		c3 sql.NullString // description
		c4 sql.NullString // encryption_seed
		c5 sql.NullString // id
		c6 sql.NullTime   // last_built_at
		c7 sql.NullString
	)
	c0.Valid = true
	c0.Bool = a.Autoarchive
	c1.Valid = true
	c1.Bool = a.Autodownload
	c2.Valid = true
	c2.Bool = a.Contributing
	c3.Valid = true
	c3.String = a.Description
	c4.Valid = true
	c4.String = a.EncryptionSeed
	c5.Valid = true
	c5.String = a.ID
	c6.Valid = true
	c6.Time = a.LastBuiltAt
	c7.Valid = true
	c7.String = a.URL // url
	return NewRSSScannerStaticRow(q.QueryRowContext(ctx, query, c0, c1, c2, c3, c4, c5, c6, c7))
}

// RSSCooldownByID generated by genieql
func RSSCooldownByID(ctx context.Context, q sqlx.Queryer, id string, ttl int, lastbuild time.Time) RSSScannerStaticRow {
	const query = `UPDATE torrents_feed_rss SET updated_at = DEFAULT, next_check = NOW() + to_minutes($2), last_built_at = $3 WHERE "id" = $1 RETURNING torrents_feed_rss."autoarchive",torrents_feed_rss."autodownload",torrents_feed_rss."contributing",torrents_feed_rss."created_at",torrents_feed_rss."description",torrents_feed_rss."disabled_at",torrents_feed_rss."encryption_seed",torrents_feed_rss."id",torrents_feed_rss."last_built_at",torrents_feed_rss."next_check",torrents_feed_rss."updated_at",torrents_feed_rss."url"`
	var (
		c0 sql.NullString // id
		c1 sql.NullInt64  // ttl
		c2 sql.NullTime   // lastbuild
	)
	c0.Valid = true
	c0.String = id
	c1.Valid = true
	c1.Int64 = int64(ttl)
	c2.Valid = true
	c2.Time = lastbuild
	return NewRSSScannerStaticRow(q.QueryRowContext(ctx, query, c0, c1, c2))
}

// RSSDeleteByID generated by genieql
func RSSDeleteByID(ctx context.Context, q sqlx.Queryer, id string) RSSScannerStaticRow {
	const query = `DELETE FROM torrents_feed_rss WHERE "id" = $1 RETURNING torrents_feed_rss."autoarchive",torrents_feed_rss."autodownload",torrents_feed_rss."contributing",torrents_feed_rss."created_at",torrents_feed_rss."description",torrents_feed_rss."disabled_at",torrents_feed_rss."encryption_seed",torrents_feed_rss."id",torrents_feed_rss."last_built_at",torrents_feed_rss."next_check",torrents_feed_rss."updated_at",torrents_feed_rss."url"`
	var c0 sql.NullString // id
	c0.Valid = true
	c0.String = id
	return NewRSSScannerStaticRow(q.QueryRowContext(ctx, query, c0))
}

// RSSFindByID generated by genieql
func RSSFindByID(ctx context.Context, q sqlx.Queryer, id string) RSSScannerStaticRow {
	const query = `SELECT torrents_feed_rss."autoarchive",torrents_feed_rss."autodownload",torrents_feed_rss."contributing",torrents_feed_rss."created_at",torrents_feed_rss."description",torrents_feed_rss."disabled_at",torrents_feed_rss."encryption_seed",torrents_feed_rss."id",torrents_feed_rss."last_built_at",torrents_feed_rss."next_check",torrents_feed_rss."updated_at",torrents_feed_rss."url" FROM torrents_feed_rss WHERE "id" = $1`
	var c0 sql.NullString // id
	c0.Valid = true
	c0.String = id
	return NewRSSScannerStaticRow(q.QueryRowContext(ctx, query, c0))
}
