//go:build !genieql.ignore
// +build !genieql.ignore

package tracking

import (
	"context"
	"database/sql"
	"time"

	"github.com/gofrs/uuid"
	"github.com/james-lawrence/deeppool/internal/x/sqlx"
)

// DO NOT EDIT: This File was auto generated by the following command:
// genieql auto -v -o genieql.gen.go
// invoked by go generate @ tracking/10_generate.genieql.go line 3

// Metadata generated by genieql
//
//easyjson:json
type Metadata struct {
	Bytes       uint64
	CreatedAt   time.Time
	Description string
	Downloaded  uint64
	HiddenAt    time.Time
	ID          string
	Infohash    []byte
	InitiatedAt time.Time
	PausedAt    time.Time
	UpdatedAt   time.Time
}

// Peer generated by genieql
//
//easyjson:json
type Peer struct {
	Bep51          bool
	Bep51Available uint64
	Bep51TTL       uint16
	CreatedAt      time.Time
	ID             string
	IP             string
	Network        string
	NextCheck      time.Time
	Peer           []byte
	Port           uint16
	UpdatedAt      time.Time
}

// UnknownHash generated by genieql
//
//easyjson:json
type UnknownHash struct {
	Attempts  uint64
	CreatedAt time.Time
	ID        string
	Infohash  []byte
	NextCheck time.Time
	UpdatedAt time.Time
}

// RSS generated by genieql
//
//easyjson:json
type RSS struct {
	Autodownload bool
	CreatedAt    time.Time
	Description  string
	ID           string
	NextCheck    time.Time
	UpdatedAt    time.Time
	URL          string
}

// MetadataScanner scanner interface.
type MetadataScanner interface {
	Scan(i *Metadata) error
	Next() bool
	Close() error
	Err() error
}

type errMetadataScanner struct {
	e error
}

func (t errMetadataScanner) Scan(i *Metadata) error {
	return t.e
}

func (t errMetadataScanner) Next() bool {
	return false
}

func (t errMetadataScanner) Err() error {
	return t.e
}

func (t errMetadataScanner) Close() error {
	return nil
}

// MetadataScannerStaticColumns generated by genieql
const MetadataScannerStaticColumns = `torrents_metadata."bytes",torrents_metadata."created_at",torrents_metadata."description",torrents_metadata."downloaded",torrents_metadata."hidden_at",torrents_metadata."id",torrents_metadata."infohash",torrents_metadata."initiated_at",torrents_metadata."paused_at",torrents_metadata."updated_at"`

// NewMetadataScannerStatic creates a scanner that operates on a static
// set of columns that are always returned in the same order.
func NewMetadataScannerStatic(rows *sql.Rows, err error) MetadataScanner {
	if err != nil {
		return errMetadataScanner{e: err}
	}

	return metadataScannerStatic{
		Rows: rows,
	}
}

// metadataScannerStatic generated by genieql
type metadataScannerStatic struct {
	Rows *sql.Rows
}

// Scan generated by genieql
func (t metadataScannerStatic) Scan(i *Metadata) error {
	var (
		c0 sql.NullInt64
		c1 sql.NullTime
		c2 sql.NullString
		c3 sql.NullInt64
		c4 sql.NullTime
		c5 sql.NullString
		c6 []byte
		c7 sql.NullTime
		c8 sql.NullTime
		c9 sql.NullTime
	)

	if err := t.Rows.Scan(&c0, &c1, &c2, &c3, &c4, &c5, &c6, &c7, &c8, &c9); err != nil {
		return err
	}

	if c0.Valid {
		tmp := uint64(c0.Int64)
		i.Bytes = tmp
	}

	if c1.Valid {
		tmp := c1.Time
		i.CreatedAt = tmp
	}

	if c2.Valid {
		tmp := string(c2.String)
		i.Description = tmp
	}

	if c3.Valid {
		tmp := uint64(c3.Int64)
		i.Downloaded = tmp
	}

	if c4.Valid {
		tmp := c4.Time
		i.HiddenAt = tmp
	}

	if c5.Valid {
		if uid, err := uuid.FromBytes([]byte(c5.String)); err != nil {
			return err
		} else {
			i.ID = uid.String()
		}
	}

	i.Infohash = c6

	if c7.Valid {
		tmp := c7.Time
		i.InitiatedAt = tmp
	}

	if c8.Valid {
		tmp := c8.Time
		i.PausedAt = tmp
	}

	if c9.Valid {
		tmp := c9.Time
		i.UpdatedAt = tmp
	}

	return t.Rows.Err()
}

// Err generated by genieql
func (t metadataScannerStatic) Err() error {
	return t.Rows.Err()
}

// Close generated by genieql
func (t metadataScannerStatic) Close() error {
	if t.Rows == nil {
		return nil
	}
	return t.Rows.Close()
}

// Next generated by genieql
func (t metadataScannerStatic) Next() bool {
	return t.Rows.Next()
}

// NewMetadataScannerStaticRow creates a scanner that operates on a static
// set of columns that are always returned in the same order, only scans a single row.
func NewMetadataScannerStaticRow(row *sql.Row) MetadataScannerStaticRow {
	return MetadataScannerStaticRow{
		row: row,
	}
}

// MetadataScannerStaticRow generated by genieql
type MetadataScannerStaticRow struct {
	err error
	row *sql.Row
}

// Scan generated by genieql
func (t MetadataScannerStaticRow) Scan(i *Metadata) error {
	var (
		c0 sql.NullInt64
		c1 sql.NullTime
		c2 sql.NullString
		c3 sql.NullInt64
		c4 sql.NullTime
		c5 sql.NullString
		c6 []byte
		c7 sql.NullTime
		c8 sql.NullTime
		c9 sql.NullTime
	)

	if t.err != nil {
		return t.err
	}

	if err := t.row.Scan(&c0, &c1, &c2, &c3, &c4, &c5, &c6, &c7, &c8, &c9); err != nil {
		return err
	}

	if c0.Valid {
		tmp := uint64(c0.Int64)
		i.Bytes = tmp
	}

	if c1.Valid {
		tmp := c1.Time
		i.CreatedAt = tmp
	}

	if c2.Valid {
		tmp := string(c2.String)
		i.Description = tmp
	}

	if c3.Valid {
		tmp := uint64(c3.Int64)
		i.Downloaded = tmp
	}

	if c4.Valid {
		tmp := c4.Time
		i.HiddenAt = tmp
	}

	if c5.Valid {
		if uid, err := uuid.FromBytes([]byte(c5.String)); err != nil {
			return err
		} else {
			i.ID = uid.String()
		}
	}

	i.Infohash = c6

	if c7.Valid {
		tmp := c7.Time
		i.InitiatedAt = tmp
	}

	if c8.Valid {
		tmp := c8.Time
		i.PausedAt = tmp
	}

	if c9.Valid {
		tmp := c9.Time
		i.UpdatedAt = tmp
	}

	return nil
}

// Err set an error to return by scan
func (t MetadataScannerStaticRow) Err(err error) MetadataScannerStaticRow {
	t.err = err
	return t
}

// NewMetadataScannerDynamic creates a scanner that operates on a dynamic
// set of columns that can be returned in any subset/order.
func NewMetadataScannerDynamic(rows *sql.Rows, err error) MetadataScanner {
	if err != nil {
		return errMetadataScanner{e: err}
	}

	return metadataScannerDynamic{
		Rows: rows,
	}
}

// metadataScannerDynamic generated by genieql
type metadataScannerDynamic struct {
	Rows *sql.Rows
}

// Scan generated by genieql
func (t metadataScannerDynamic) Scan(i *Metadata) error {
	const (
		cn0 = "bytes"
		cn1 = "created_at"
		cn2 = "description"
		cn3 = "downloaded"
		cn4 = "hidden_at"
		cn5 = "id"
		cn6 = "infohash"
		cn7 = "initiated_at"
		cn8 = "paused_at"
		cn9 = "updated_at"
	)
	var (
		ignored sql.RawBytes
		err     error
		columns []string
		dst     []interface{}
		c0      sql.NullInt64
		c1      sql.NullTime
		c2      sql.NullString
		c3      sql.NullInt64
		c4      sql.NullTime
		c5      sql.NullString
		c6      []byte
		c7      sql.NullTime
		c8      sql.NullTime
		c9      sql.NullTime
	)

	if columns, err = t.Rows.Columns(); err != nil {
		return err
	}

	dst = make([]interface{}, 0, len(columns))

	for _, column := range columns {
		switch column {
		case cn0:
			dst = append(dst, &c0)
		case cn1:
			dst = append(dst, &c1)
		case cn2:
			dst = append(dst, &c2)
		case cn3:
			dst = append(dst, &c3)
		case cn4:
			dst = append(dst, &c4)
		case cn5:
			dst = append(dst, &c5)
		case cn6:
			dst = append(dst, &c6)
		case cn7:
			dst = append(dst, &c7)
		case cn8:
			dst = append(dst, &c8)
		case cn9:
			dst = append(dst, &c9)
		default:
			dst = append(dst, &ignored)
		}
	}

	if err := t.Rows.Scan(dst...); err != nil {
		return err
	}

	for _, column := range columns {
		switch column {
		case cn0:
			if c0.Valid {
				tmp := uint64(c0.Int64)
				i.Bytes = tmp
			}

		case cn1:
			if c1.Valid {
				tmp := c1.Time
				i.CreatedAt = tmp
			}

		case cn2:
			if c2.Valid {
				tmp := string(c2.String)
				i.Description = tmp
			}

		case cn3:
			if c3.Valid {
				tmp := uint64(c3.Int64)
				i.Downloaded = tmp
			}

		case cn4:
			if c4.Valid {
				tmp := c4.Time
				i.HiddenAt = tmp
			}

		case cn5:
			if c5.Valid {
				if uid, err := uuid.FromBytes([]byte(c5.String)); err != nil {
					return err
				} else {
					i.ID = uid.String()
				}
			}

		case cn6:
			i.Infohash = c6

		case cn7:
			if c7.Valid {
				tmp := c7.Time
				i.InitiatedAt = tmp
			}

		case cn8:
			if c8.Valid {
				tmp := c8.Time
				i.PausedAt = tmp
			}

		case cn9:
			if c9.Valid {
				tmp := c9.Time
				i.UpdatedAt = tmp
			}

		}
	}

	return t.Rows.Err()
}

// Err generated by genieql
func (t metadataScannerDynamic) Err() error {
	return t.Rows.Err()
}

// Close generated by genieql
func (t metadataScannerDynamic) Close() error {
	if t.Rows == nil {
		return nil
	}
	return t.Rows.Close()
}

// Next generated by genieql
func (t metadataScannerDynamic) Next() bool {
	return t.Rows.Next()
}

// PeerScanner scanner interface.
type PeerScanner interface {
	Scan(i *Peer) error
	Next() bool
	Close() error
	Err() error
}

type errPeerScanner struct {
	e error
}

func (t errPeerScanner) Scan(i *Peer) error {
	return t.e
}

func (t errPeerScanner) Next() bool {
	return false
}

func (t errPeerScanner) Err() error {
	return t.e
}

func (t errPeerScanner) Close() error {
	return nil
}

// PeerScannerStaticColumns generated by genieql
const PeerScannerStaticColumns = `torrents_peers."bep51",torrents_peers."bep51_available",torrents_peers."bep51_ttl",torrents_peers."created_at",torrents_peers."id",torrents_peers."ip",torrents_peers."network",torrents_peers."next_check",torrents_peers."peer",torrents_peers."port",torrents_peers."updated_at"`

// NewPeerScannerStatic creates a scanner that operates on a static
// set of columns that are always returned in the same order.
func NewPeerScannerStatic(rows *sql.Rows, err error) PeerScanner {
	if err != nil {
		return errPeerScanner{e: err}
	}

	return peerScannerStatic{
		Rows: rows,
	}
}

// peerScannerStatic generated by genieql
type peerScannerStatic struct {
	Rows *sql.Rows
}

// Scan generated by genieql
func (t peerScannerStatic) Scan(i *Peer) error {
	var (
		c0  sql.NullBool
		c1  sql.NullInt64
		c2  sql.NullInt32
		c3  sql.NullTime
		c4  sql.NullString
		c5  sql.NullString
		c6  sql.NullString
		c7  sql.NullTime
		c8  []byte
		c9  sql.NullInt32
		c10 sql.NullTime
	)

	if err := t.Rows.Scan(&c0, &c1, &c2, &c3, &c4, &c5, &c6, &c7, &c8, &c9, &c10); err != nil {
		return err
	}

	if c0.Valid {
		tmp := c0.Bool
		i.Bep51 = tmp
	}

	if c1.Valid {
		tmp := uint64(c1.Int64)
		i.Bep51Available = tmp
	}

	if c2.Valid {
		tmp := uint16(c2.Int32)
		i.Bep51TTL = tmp
	}

	if c3.Valid {
		tmp := c3.Time
		i.CreatedAt = tmp
	}

	if c4.Valid {
		if uid, err := uuid.FromBytes([]byte(c4.String)); err != nil {
			return err
		} else {
			i.ID = uid.String()
		}
	}

	if c5.Valid {
		tmp := string(c5.String)
		i.IP = tmp
	}

	if c6.Valid {
		tmp := string(c6.String)
		i.Network = tmp
	}

	if c7.Valid {
		tmp := c7.Time
		i.NextCheck = tmp
	}

	i.Peer = c8

	if c9.Valid {
		tmp := uint16(c9.Int32)
		i.Port = tmp
	}

	if c10.Valid {
		tmp := c10.Time
		i.UpdatedAt = tmp
	}

	return t.Rows.Err()
}

// Err generated by genieql
func (t peerScannerStatic) Err() error {
	return t.Rows.Err()
}

// Close generated by genieql
func (t peerScannerStatic) Close() error {
	if t.Rows == nil {
		return nil
	}
	return t.Rows.Close()
}

// Next generated by genieql
func (t peerScannerStatic) Next() bool {
	return t.Rows.Next()
}

// NewPeerScannerStaticRow creates a scanner that operates on a static
// set of columns that are always returned in the same order, only scans a single row.
func NewPeerScannerStaticRow(row *sql.Row) PeerScannerStaticRow {
	return PeerScannerStaticRow{
		row: row,
	}
}

// PeerScannerStaticRow generated by genieql
type PeerScannerStaticRow struct {
	err error
	row *sql.Row
}

// Scan generated by genieql
func (t PeerScannerStaticRow) Scan(i *Peer) error {
	var (
		c0  sql.NullBool
		c1  sql.NullInt64
		c2  sql.NullInt32
		c3  sql.NullTime
		c4  sql.NullString
		c5  sql.NullString
		c6  sql.NullString
		c7  sql.NullTime
		c8  []byte
		c9  sql.NullInt32
		c10 sql.NullTime
	)

	if t.err != nil {
		return t.err
	}

	if err := t.row.Scan(&c0, &c1, &c2, &c3, &c4, &c5, &c6, &c7, &c8, &c9, &c10); err != nil {
		return err
	}

	if c0.Valid {
		tmp := c0.Bool
		i.Bep51 = tmp
	}

	if c1.Valid {
		tmp := uint64(c1.Int64)
		i.Bep51Available = tmp
	}

	if c2.Valid {
		tmp := uint16(c2.Int32)
		i.Bep51TTL = tmp
	}

	if c3.Valid {
		tmp := c3.Time
		i.CreatedAt = tmp
	}

	if c4.Valid {
		if uid, err := uuid.FromBytes([]byte(c4.String)); err != nil {
			return err
		} else {
			i.ID = uid.String()
		}
	}

	if c5.Valid {
		tmp := string(c5.String)
		i.IP = tmp
	}

	if c6.Valid {
		tmp := string(c6.String)
		i.Network = tmp
	}

	if c7.Valid {
		tmp := c7.Time
		i.NextCheck = tmp
	}

	i.Peer = c8

	if c9.Valid {
		tmp := uint16(c9.Int32)
		i.Port = tmp
	}

	if c10.Valid {
		tmp := c10.Time
		i.UpdatedAt = tmp
	}

	return nil
}

// Err set an error to return by scan
func (t PeerScannerStaticRow) Err(err error) PeerScannerStaticRow {
	t.err = err
	return t
}

// NewPeerScannerDynamic creates a scanner that operates on a dynamic
// set of columns that can be returned in any subset/order.
func NewPeerScannerDynamic(rows *sql.Rows, err error) PeerScanner {
	if err != nil {
		return errPeerScanner{e: err}
	}

	return peerScannerDynamic{
		Rows: rows,
	}
}

// peerScannerDynamic generated by genieql
type peerScannerDynamic struct {
	Rows *sql.Rows
}

// Scan generated by genieql
func (t peerScannerDynamic) Scan(i *Peer) error {
	const (
		cn0  = "bep51"
		cn1  = "bep51_available"
		cn2  = "bep51_ttl"
		cn3  = "created_at"
		cn4  = "id"
		cn5  = "ip"
		cn6  = "network"
		cn7  = "next_check"
		cn8  = "peer"
		cn9  = "port"
		cn10 = "updated_at"
	)
	var (
		ignored sql.RawBytes
		err     error
		columns []string
		dst     []interface{}
		c0      sql.NullBool
		c1      sql.NullInt64
		c2      sql.NullInt32
		c3      sql.NullTime
		c4      sql.NullString
		c5      sql.NullString
		c6      sql.NullString
		c7      sql.NullTime
		c8      []byte
		c9      sql.NullInt32
		c10     sql.NullTime
	)

	if columns, err = t.Rows.Columns(); err != nil {
		return err
	}

	dst = make([]interface{}, 0, len(columns))

	for _, column := range columns {
		switch column {
		case cn0:
			dst = append(dst, &c0)
		case cn1:
			dst = append(dst, &c1)
		case cn2:
			dst = append(dst, &c2)
		case cn3:
			dst = append(dst, &c3)
		case cn4:
			dst = append(dst, &c4)
		case cn5:
			dst = append(dst, &c5)
		case cn6:
			dst = append(dst, &c6)
		case cn7:
			dst = append(dst, &c7)
		case cn8:
			dst = append(dst, &c8)
		case cn9:
			dst = append(dst, &c9)
		case cn10:
			dst = append(dst, &c10)
		default:
			dst = append(dst, &ignored)
		}
	}

	if err := t.Rows.Scan(dst...); err != nil {
		return err
	}

	for _, column := range columns {
		switch column {
		case cn0:
			if c0.Valid {
				tmp := c0.Bool
				i.Bep51 = tmp
			}

		case cn1:
			if c1.Valid {
				tmp := uint64(c1.Int64)
				i.Bep51Available = tmp
			}

		case cn2:
			if c2.Valid {
				tmp := uint16(c2.Int32)
				i.Bep51TTL = tmp
			}

		case cn3:
			if c3.Valid {
				tmp := c3.Time
				i.CreatedAt = tmp
			}

		case cn4:
			if c4.Valid {
				if uid, err := uuid.FromBytes([]byte(c4.String)); err != nil {
					return err
				} else {
					i.ID = uid.String()
				}
			}

		case cn5:
			if c5.Valid {
				tmp := string(c5.String)
				i.IP = tmp
			}

		case cn6:
			if c6.Valid {
				tmp := string(c6.String)
				i.Network = tmp
			}

		case cn7:
			if c7.Valid {
				tmp := c7.Time
				i.NextCheck = tmp
			}

		case cn8:
			i.Peer = c8

		case cn9:
			if c9.Valid {
				tmp := uint16(c9.Int32)
				i.Port = tmp
			}

		case cn10:
			if c10.Valid {
				tmp := c10.Time
				i.UpdatedAt = tmp
			}

		}
	}

	return t.Rows.Err()
}

// Err generated by genieql
func (t peerScannerDynamic) Err() error {
	return t.Rows.Err()
}

// Close generated by genieql
func (t peerScannerDynamic) Close() error {
	if t.Rows == nil {
		return nil
	}
	return t.Rows.Close()
}

// Next generated by genieql
func (t peerScannerDynamic) Next() bool {
	return t.Rows.Next()
}

// UnknownHashScanner scanner interface.
type UnknownHashScanner interface {
	Scan(i *UnknownHash) error
	Next() bool
	Close() error
	Err() error
}

type errUnknownHashScanner struct {
	e error
}

func (t errUnknownHashScanner) Scan(i *UnknownHash) error {
	return t.e
}

func (t errUnknownHashScanner) Next() bool {
	return false
}

func (t errUnknownHashScanner) Err() error {
	return t.e
}

func (t errUnknownHashScanner) Close() error {
	return nil
}

// UnknownHashScannerStaticColumns generated by genieql
const UnknownHashScannerStaticColumns = `torrents_unknown_infohashes."attempts",torrents_unknown_infohashes."created_at",torrents_unknown_infohashes."id",torrents_unknown_infohashes."infohash",torrents_unknown_infohashes."next_check",torrents_unknown_infohashes."updated_at"`

// NewUnknownHashScannerStatic creates a scanner that operates on a static
// set of columns that are always returned in the same order.
func NewUnknownHashScannerStatic(rows *sql.Rows, err error) UnknownHashScanner {
	if err != nil {
		return errUnknownHashScanner{e: err}
	}

	return unknownHashScannerStatic{
		Rows: rows,
	}
}

// unknownHashScannerStatic generated by genieql
type unknownHashScannerStatic struct {
	Rows *sql.Rows
}

// Scan generated by genieql
func (t unknownHashScannerStatic) Scan(i *UnknownHash) error {
	var (
		c0 sql.NullInt64
		c1 sql.NullTime
		c2 sql.NullString
		c3 []byte
		c4 sql.NullTime
		c5 sql.NullTime
	)

	if err := t.Rows.Scan(&c0, &c1, &c2, &c3, &c4, &c5); err != nil {
		return err
	}

	if c0.Valid {
		tmp := uint64(c0.Int64)
		i.Attempts = tmp
	}

	if c1.Valid {
		tmp := c1.Time
		i.CreatedAt = tmp
	}

	if c2.Valid {
		if uid, err := uuid.FromBytes([]byte(c2.String)); err != nil {
			return err
		} else {
			i.ID = uid.String()
		}
	}

	i.Infohash = c3

	if c4.Valid {
		tmp := c4.Time
		i.NextCheck = tmp
	}

	if c5.Valid {
		tmp := c5.Time
		i.UpdatedAt = tmp
	}

	return t.Rows.Err()
}

// Err generated by genieql
func (t unknownHashScannerStatic) Err() error {
	return t.Rows.Err()
}

// Close generated by genieql
func (t unknownHashScannerStatic) Close() error {
	if t.Rows == nil {
		return nil
	}
	return t.Rows.Close()
}

// Next generated by genieql
func (t unknownHashScannerStatic) Next() bool {
	return t.Rows.Next()
}

// NewUnknownHashScannerStaticRow creates a scanner that operates on a static
// set of columns that are always returned in the same order, only scans a single row.
func NewUnknownHashScannerStaticRow(row *sql.Row) UnknownHashScannerStaticRow {
	return UnknownHashScannerStaticRow{
		row: row,
	}
}

// UnknownHashScannerStaticRow generated by genieql
type UnknownHashScannerStaticRow struct {
	err error
	row *sql.Row
}

// Scan generated by genieql
func (t UnknownHashScannerStaticRow) Scan(i *UnknownHash) error {
	var (
		c0 sql.NullInt64
		c1 sql.NullTime
		c2 sql.NullString
		c3 []byte
		c4 sql.NullTime
		c5 sql.NullTime
	)

	if t.err != nil {
		return t.err
	}

	if err := t.row.Scan(&c0, &c1, &c2, &c3, &c4, &c5); err != nil {
		return err
	}

	if c0.Valid {
		tmp := uint64(c0.Int64)
		i.Attempts = tmp
	}

	if c1.Valid {
		tmp := c1.Time
		i.CreatedAt = tmp
	}

	if c2.Valid {
		if uid, err := uuid.FromBytes([]byte(c2.String)); err != nil {
			return err
		} else {
			i.ID = uid.String()
		}
	}

	i.Infohash = c3

	if c4.Valid {
		tmp := c4.Time
		i.NextCheck = tmp
	}

	if c5.Valid {
		tmp := c5.Time
		i.UpdatedAt = tmp
	}

	return nil
}

// Err set an error to return by scan
func (t UnknownHashScannerStaticRow) Err(err error) UnknownHashScannerStaticRow {
	t.err = err
	return t
}

// NewUnknownHashScannerDynamic creates a scanner that operates on a dynamic
// set of columns that can be returned in any subset/order.
func NewUnknownHashScannerDynamic(rows *sql.Rows, err error) UnknownHashScanner {
	if err != nil {
		return errUnknownHashScanner{e: err}
	}

	return unknownHashScannerDynamic{
		Rows: rows,
	}
}

// unknownHashScannerDynamic generated by genieql
type unknownHashScannerDynamic struct {
	Rows *sql.Rows
}

// Scan generated by genieql
func (t unknownHashScannerDynamic) Scan(i *UnknownHash) error {
	const (
		cn0 = "attempts"
		cn1 = "created_at"
		cn2 = "id"
		cn3 = "infohash"
		cn4 = "next_check"
		cn5 = "updated_at"
	)
	var (
		ignored sql.RawBytes
		err     error
		columns []string
		dst     []interface{}
		c0      sql.NullInt64
		c1      sql.NullTime
		c2      sql.NullString
		c3      []byte
		c4      sql.NullTime
		c5      sql.NullTime
	)

	if columns, err = t.Rows.Columns(); err != nil {
		return err
	}

	dst = make([]interface{}, 0, len(columns))

	for _, column := range columns {
		switch column {
		case cn0:
			dst = append(dst, &c0)
		case cn1:
			dst = append(dst, &c1)
		case cn2:
			dst = append(dst, &c2)
		case cn3:
			dst = append(dst, &c3)
		case cn4:
			dst = append(dst, &c4)
		case cn5:
			dst = append(dst, &c5)
		default:
			dst = append(dst, &ignored)
		}
	}

	if err := t.Rows.Scan(dst...); err != nil {
		return err
	}

	for _, column := range columns {
		switch column {
		case cn0:
			if c0.Valid {
				tmp := uint64(c0.Int64)
				i.Attempts = tmp
			}

		case cn1:
			if c1.Valid {
				tmp := c1.Time
				i.CreatedAt = tmp
			}

		case cn2:
			if c2.Valid {
				if uid, err := uuid.FromBytes([]byte(c2.String)); err != nil {
					return err
				} else {
					i.ID = uid.String()
				}
			}

		case cn3:
			i.Infohash = c3

		case cn4:
			if c4.Valid {
				tmp := c4.Time
				i.NextCheck = tmp
			}

		case cn5:
			if c5.Valid {
				tmp := c5.Time
				i.UpdatedAt = tmp
			}

		}
	}

	return t.Rows.Err()
}

// Err generated by genieql
func (t unknownHashScannerDynamic) Err() error {
	return t.Rows.Err()
}

// Close generated by genieql
func (t unknownHashScannerDynamic) Close() error {
	if t.Rows == nil {
		return nil
	}
	return t.Rows.Close()
}

// Next generated by genieql
func (t unknownHashScannerDynamic) Next() bool {
	return t.Rows.Next()
}

// RSSScanner scanner interface.
type RSSScanner interface {
	Scan(i *RSS) error
	Next() bool
	Close() error
	Err() error
}

type errRSSScanner struct {
	e error
}

func (t errRSSScanner) Scan(i *RSS) error {
	return t.e
}

func (t errRSSScanner) Next() bool {
	return false
}

func (t errRSSScanner) Err() error {
	return t.e
}

func (t errRSSScanner) Close() error {
	return nil
}

// RSSScannerStaticColumns generated by genieql
const RSSScannerStaticColumns = `torrents_feed_rss."autodownload",torrents_feed_rss."created_at",torrents_feed_rss."description",torrents_feed_rss."id",torrents_feed_rss."next_check",torrents_feed_rss."updated_at",torrents_feed_rss."url"`

// NewRSSScannerStatic creates a scanner that operates on a static
// set of columns that are always returned in the same order.
func NewRSSScannerStatic(rows *sql.Rows, err error) RSSScanner {
	if err != nil {
		return errRSSScanner{e: err}
	}

	return rSSScannerStatic{
		Rows: rows,
	}
}

// rSSScannerStatic generated by genieql
type rSSScannerStatic struct {
	Rows *sql.Rows
}

// Scan generated by genieql
func (t rSSScannerStatic) Scan(i *RSS) error {
	var (
		c0 sql.NullBool
		c1 sql.NullTime
		c2 sql.NullString
		c3 sql.NullString
		c4 sql.NullTime
		c5 sql.NullTime
		c6 sql.NullString
	)

	if err := t.Rows.Scan(&c0, &c1, &c2, &c3, &c4, &c5, &c6); err != nil {
		return err
	}

	if c0.Valid {
		tmp := c0.Bool
		i.Autodownload = tmp
	}

	if c1.Valid {
		tmp := c1.Time
		i.CreatedAt = tmp
	}

	if c2.Valid {
		tmp := string(c2.String)
		i.Description = tmp
	}

	if c3.Valid {
		if uid, err := uuid.FromBytes([]byte(c3.String)); err != nil {
			return err
		} else {
			i.ID = uid.String()
		}
	}

	if c4.Valid {
		tmp := c4.Time
		i.NextCheck = tmp
	}

	if c5.Valid {
		tmp := c5.Time
		i.UpdatedAt = tmp
	}

	if c6.Valid {
		tmp := string(c6.String)
		i.URL = tmp
	}

	return t.Rows.Err()
}

// Err generated by genieql
func (t rSSScannerStatic) Err() error {
	return t.Rows.Err()
}

// Close generated by genieql
func (t rSSScannerStatic) Close() error {
	if t.Rows == nil {
		return nil
	}
	return t.Rows.Close()
}

// Next generated by genieql
func (t rSSScannerStatic) Next() bool {
	return t.Rows.Next()
}

// NewRSSScannerStaticRow creates a scanner that operates on a static
// set of columns that are always returned in the same order, only scans a single row.
func NewRSSScannerStaticRow(row *sql.Row) RSSScannerStaticRow {
	return RSSScannerStaticRow{
		row: row,
	}
}

// RSSScannerStaticRow generated by genieql
type RSSScannerStaticRow struct {
	err error
	row *sql.Row
}

// Scan generated by genieql
func (t RSSScannerStaticRow) Scan(i *RSS) error {
	var (
		c0 sql.NullBool
		c1 sql.NullTime
		c2 sql.NullString
		c3 sql.NullString
		c4 sql.NullTime
		c5 sql.NullTime
		c6 sql.NullString
	)

	if t.err != nil {
		return t.err
	}

	if err := t.row.Scan(&c0, &c1, &c2, &c3, &c4, &c5, &c6); err != nil {
		return err
	}

	if c0.Valid {
		tmp := c0.Bool
		i.Autodownload = tmp
	}

	if c1.Valid {
		tmp := c1.Time
		i.CreatedAt = tmp
	}

	if c2.Valid {
		tmp := string(c2.String)
		i.Description = tmp
	}

	if c3.Valid {
		if uid, err := uuid.FromBytes([]byte(c3.String)); err != nil {
			return err
		} else {
			i.ID = uid.String()
		}
	}

	if c4.Valid {
		tmp := c4.Time
		i.NextCheck = tmp
	}

	if c5.Valid {
		tmp := c5.Time
		i.UpdatedAt = tmp
	}

	if c6.Valid {
		tmp := string(c6.String)
		i.URL = tmp
	}

	return nil
}

// Err set an error to return by scan
func (t RSSScannerStaticRow) Err(err error) RSSScannerStaticRow {
	t.err = err
	return t
}

// NewRSSScannerDynamic creates a scanner that operates on a dynamic
// set of columns that can be returned in any subset/order.
func NewRSSScannerDynamic(rows *sql.Rows, err error) RSSScanner {
	if err != nil {
		return errRSSScanner{e: err}
	}

	return rSSScannerDynamic{
		Rows: rows,
	}
}

// rSSScannerDynamic generated by genieql
type rSSScannerDynamic struct {
	Rows *sql.Rows
}

// Scan generated by genieql
func (t rSSScannerDynamic) Scan(i *RSS) error {
	const (
		cn0 = "autodownload"
		cn1 = "created_at"
		cn2 = "description"
		cn3 = "id"
		cn4 = "next_check"
		cn5 = "updated_at"
		cn6 = "url"
	)
	var (
		ignored sql.RawBytes
		err     error
		columns []string
		dst     []interface{}
		c0      sql.NullBool
		c1      sql.NullTime
		c2      sql.NullString
		c3      sql.NullString
		c4      sql.NullTime
		c5      sql.NullTime
		c6      sql.NullString
	)

	if columns, err = t.Rows.Columns(); err != nil {
		return err
	}

	dst = make([]interface{}, 0, len(columns))

	for _, column := range columns {
		switch column {
		case cn0:
			dst = append(dst, &c0)
		case cn1:
			dst = append(dst, &c1)
		case cn2:
			dst = append(dst, &c2)
		case cn3:
			dst = append(dst, &c3)
		case cn4:
			dst = append(dst, &c4)
		case cn5:
			dst = append(dst, &c5)
		case cn6:
			dst = append(dst, &c6)
		default:
			dst = append(dst, &ignored)
		}
	}

	if err := t.Rows.Scan(dst...); err != nil {
		return err
	}

	for _, column := range columns {
		switch column {
		case cn0:
			if c0.Valid {
				tmp := c0.Bool
				i.Autodownload = tmp
			}

		case cn1:
			if c1.Valid {
				tmp := c1.Time
				i.CreatedAt = tmp
			}

		case cn2:
			if c2.Valid {
				tmp := string(c2.String)
				i.Description = tmp
			}

		case cn3:
			if c3.Valid {
				if uid, err := uuid.FromBytes([]byte(c3.String)); err != nil {
					return err
				} else {
					i.ID = uid.String()
				}
			}

		case cn4:
			if c4.Valid {
				tmp := c4.Time
				i.NextCheck = tmp
			}

		case cn5:
			if c5.Valid {
				tmp := c5.Time
				i.UpdatedAt = tmp
			}

		case cn6:
			if c6.Valid {
				tmp := string(c6.String)
				i.URL = tmp
			}

		}
	}

	return t.Rows.Err()
}

// Err generated by genieql
func (t rSSScannerDynamic) Err() error {
	return t.Rows.Err()
}

// Close generated by genieql
func (t rSSScannerDynamic) Close() error {
	if t.Rows == nil {
		return nil
	}
	return t.Rows.Close()
}

// Next generated by genieql
func (t rSSScannerDynamic) Next() bool {
	return t.Rows.Next()
}

// MetadataInsertWithDefaultsStaticColumns generated by genieql
const MetadataInsertWithDefaultsStaticColumns = `$1,DEFAULT,$2,$3,$4,$5,$6,$7,$8,DEFAULT`

// MetadataInsertWithDefaultsExplode generated by genieql
func MetadataInsertWithDefaultsExplode(a *Metadata) ([]interface{}, error) {
	var (
		c0 sql.NullInt64  // bytes
		c1 sql.NullString // description
		c2 sql.NullInt64  // downloaded
		c3 sql.NullTime   // hidden_at
		c4 sql.NullString // id
		c5 []byte         // infohash
		c6 sql.NullTime   // initiated_at
		c7 sql.NullTime   // paused_at
	)

	c0.Valid = true
	c0.Int64 = int64(a.Bytes)

	c1.Valid = true
	c1.String = a.Description

	c2.Valid = true
	c2.Int64 = int64(a.Downloaded)

	c3.Valid = true
	c3.Time = a.HiddenAt

	c4.Valid = true
	c4.String = a.ID

	c5 = a.Infohash

	c6.Valid = true
	c6.Time = a.InitiatedAt

	c7.Valid = true
	c7.Time = a.PausedAt

	return []interface{}{c0, c1, c2, c3, c4, c5, c6, c7}, nil
}

// MetadataInsertWithDefaults generated by genieql
func MetadataInsertWithDefaults(ctx context.Context, q sqlx.Queryer, a Metadata) MetadataScannerStaticRow {
	const query = `INSERT INTO "torrents_metadata" ("bytes","created_at","description","downloaded","hidden_at","id","infohash","initiated_at","paused_at","updated_at") VALUES ($1,DEFAULT,$2,$3,$4,$5,$6,$7,$8,DEFAULT) ON CONFLICT (id) DO UPDATE SET updated_at = DEFAULT RETURNING "bytes","created_at","description","downloaded","hidden_at","id","infohash","initiated_at","paused_at","updated_at"`
	var (
		c0 sql.NullInt64  // bytes
		c1 sql.NullString // description
		c2 sql.NullInt64  // downloaded
		c3 sql.NullTime   // hidden_at
		c4 sql.NullString // id
		c5 []byte         // infohash
		c6 sql.NullTime   // initiated_at
		c7 sql.NullTime
	)
	c0.Valid = true
	c0.Int64 = int64(a.Bytes)
	c1.Valid = true
	c1.String = a.Description
	c2.Valid = true
	c2.Int64 = int64(a.Downloaded)
	c3.Valid = true
	c3.Time = a.HiddenAt
	c4.Valid = true
	c4.String = a.ID
	c5 = a.Infohash
	c6.Valid = true
	c6.Time = a.InitiatedAt
	c7.Valid = true
	c7.Time = a.PausedAt // paused_at
	return NewMetadataScannerStaticRow(q.QueryRowContext(ctx, query, c0, c1, c2, c3, c4, c5, c6, c7))
}

// MetadataBatchInsertWithDefaults generated by genieql
func NewMetadataBatchInsertWithDefaults(ctx context.Context, q sqlx.Queryer, p ...Metadata) MetadataScanner {
	return &metadataBatchInsertWithDefaults{ctx: ctx, q: q, remaining: p}
}

type metadataBatchInsertWithDefaults struct {
	ctx       context.Context
	q         sqlx.Queryer
	remaining []Metadata
	scanner   MetadataScanner
}

func (t *metadataBatchInsertWithDefaults) Scan(p *Metadata) error {
	return t.scanner.Scan(p)
}

func (t *metadataBatchInsertWithDefaults) Err() error {
	if t.scanner == nil {
		return nil
	}
	return t.scanner.Err()
}

func (t *metadataBatchInsertWithDefaults) Close() error {
	if t.scanner == nil {
		return nil
	}
	return t.scanner.Close()
}

func (t *metadataBatchInsertWithDefaults) Next() bool {
	var advanced bool
	if t.scanner != nil && t.scanner.Next() {
		return true
	}
	if len(t.remaining) > 0 && t.Close() == nil {
		t.scanner, t.remaining, advanced = t.advance(t.remaining...)
		return advanced && t.scanner.Next()
	}
	return false
}

func (t *metadataBatchInsertWithDefaults) advance(p ...Metadata) (MetadataScanner, []Metadata, bool) {
	transform := func(p Metadata) (c0 sql.NullInt64, c1 sql.NullString, c2 sql.NullInt64, c3 sql.NullTime, c4 []byte, c5 sql.NullTime, c6 sql.NullTime, err error) {
		c0.Valid = true
		c0.Int64 = int64(p.Bytes)
		c1.Valid = true
		c1.String = p.Description
		c2.Valid = true
		c2.Int64 = int64(p.Downloaded)
		c3.Valid = true
		c3.Time = p.HiddenAt
		c4 = p.Infohash
		c5.Valid = true
		c5.Time = p.InitiatedAt
		c6.Valid = true
		c6.Time = p.PausedAt
		return c0, c1, c2, c3, c4, c5, c6, nil
	}
	switch len(p) {
	case 0:
		return nil, []Metadata(nil), false
	case 1:
		const query = `INSERT INTO "torrents_metadata" ("bytes","created_at","description","downloaded","hidden_at","id","infohash","initiated_at","paused_at","updated_at") VALUES ($1,DEFAULT,$2,$3,$4,DEFAULT,$5,$6,$7,DEFAULT) RETURNING "bytes","created_at","description","downloaded","hidden_at","id","infohash","initiated_at","paused_at","updated_at"`
		var (
			r0c0 sql.NullInt64
			r0c1 sql.NullString
			r0c2 sql.NullInt64
			r0c3 sql.NullTime
			r0c4 []byte
			r0c5 sql.NullTime
			r0c6 sql.NullTime
			err  error
		)
		if r0c0, r0c1, r0c2, r0c3, r0c4, r0c5, r0c6, err = transform(p[0]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		return NewMetadataScannerStatic(t.q.QueryContext(t.ctx, query, r0c0, r0c1, r0c2, r0c3, r0c4, r0c5, r0c6)), p[1:], true
	case 2:
		const query = `INSERT INTO "torrents_metadata" ("bytes","created_at","description","downloaded","hidden_at","id","infohash","initiated_at","paused_at","updated_at") VALUES ($1,DEFAULT,$2,$3,$4,DEFAULT,$5,$6,$7,DEFAULT),($8,DEFAULT,$9,$10,$11,DEFAULT,$12,$13,$14,DEFAULT) RETURNING "bytes","created_at","description","downloaded","hidden_at","id","infohash","initiated_at","paused_at","updated_at"`
		var (
			r0c0 sql.NullInt64
			r0c1 sql.NullString
			r0c2 sql.NullInt64
			r0c3 sql.NullTime
			r0c4 []byte
			r0c5 sql.NullTime
			r0c6 sql.NullTime
			r1c0 sql.NullInt64
			r1c1 sql.NullString
			r1c2 sql.NullInt64
			r1c3 sql.NullTime
			r1c4 []byte
			r1c5 sql.NullTime
			r1c6 sql.NullTime
			err  error
		)
		if r0c0, r0c1, r0c2, r0c3, r0c4, r0c5, r0c6, err = transform(p[0]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r1c0, r1c1, r1c2, r1c3, r1c4, r1c5, r1c6, err = transform(p[1]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		return NewMetadataScannerStatic(t.q.QueryContext(t.ctx, query, r0c0, r0c1, r0c2, r0c3, r0c4, r0c5, r0c6, r1c0, r1c1, r1c2, r1c3, r1c4, r1c5, r1c6)), p[2:], true
	case 3:
		const query = `INSERT INTO "torrents_metadata" ("bytes","created_at","description","downloaded","hidden_at","id","infohash","initiated_at","paused_at","updated_at") VALUES ($1,DEFAULT,$2,$3,$4,DEFAULT,$5,$6,$7,DEFAULT),($8,DEFAULT,$9,$10,$11,DEFAULT,$12,$13,$14,DEFAULT),($15,DEFAULT,$16,$17,$18,DEFAULT,$19,$20,$21,DEFAULT) RETURNING "bytes","created_at","description","downloaded","hidden_at","id","infohash","initiated_at","paused_at","updated_at"`
		var (
			r0c0 sql.NullInt64
			r0c1 sql.NullString
			r0c2 sql.NullInt64
			r0c3 sql.NullTime
			r0c4 []byte
			r0c5 sql.NullTime
			r0c6 sql.NullTime
			r1c0 sql.NullInt64
			r1c1 sql.NullString
			r1c2 sql.NullInt64
			r1c3 sql.NullTime
			r1c4 []byte
			r1c5 sql.NullTime
			r1c6 sql.NullTime
			r2c0 sql.NullInt64
			r2c1 sql.NullString
			r2c2 sql.NullInt64
			r2c3 sql.NullTime
			r2c4 []byte
			r2c5 sql.NullTime
			r2c6 sql.NullTime
			err  error
		)
		if r0c0, r0c1, r0c2, r0c3, r0c4, r0c5, r0c6, err = transform(p[0]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r1c0, r1c1, r1c2, r1c3, r1c4, r1c5, r1c6, err = transform(p[1]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r2c0, r2c1, r2c2, r2c3, r2c4, r2c5, r2c6, err = transform(p[2]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		return NewMetadataScannerStatic(t.q.QueryContext(t.ctx, query, r0c0, r0c1, r0c2, r0c3, r0c4, r0c5, r0c6, r1c0, r1c1, r1c2, r1c3, r1c4, r1c5, r1c6, r2c0, r2c1, r2c2, r2c3, r2c4, r2c5, r2c6)), p[3:], true
	case 4:
		const query = `INSERT INTO "torrents_metadata" ("bytes","created_at","description","downloaded","hidden_at","id","infohash","initiated_at","paused_at","updated_at") VALUES ($1,DEFAULT,$2,$3,$4,DEFAULT,$5,$6,$7,DEFAULT),($8,DEFAULT,$9,$10,$11,DEFAULT,$12,$13,$14,DEFAULT),($15,DEFAULT,$16,$17,$18,DEFAULT,$19,$20,$21,DEFAULT),($22,DEFAULT,$23,$24,$25,DEFAULT,$26,$27,$28,DEFAULT) RETURNING "bytes","created_at","description","downloaded","hidden_at","id","infohash","initiated_at","paused_at","updated_at"`
		var (
			r0c0 sql.NullInt64
			r0c1 sql.NullString
			r0c2 sql.NullInt64
			r0c3 sql.NullTime
			r0c4 []byte
			r0c5 sql.NullTime
			r0c6 sql.NullTime
			r1c0 sql.NullInt64
			r1c1 sql.NullString
			r1c2 sql.NullInt64
			r1c3 sql.NullTime
			r1c4 []byte
			r1c5 sql.NullTime
			r1c6 sql.NullTime
			r2c0 sql.NullInt64
			r2c1 sql.NullString
			r2c2 sql.NullInt64
			r2c3 sql.NullTime
			r2c4 []byte
			r2c5 sql.NullTime
			r2c6 sql.NullTime
			r3c0 sql.NullInt64
			r3c1 sql.NullString
			r3c2 sql.NullInt64
			r3c3 sql.NullTime
			r3c4 []byte
			r3c5 sql.NullTime
			r3c6 sql.NullTime
			err  error
		)
		if r0c0, r0c1, r0c2, r0c3, r0c4, r0c5, r0c6, err = transform(p[0]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r1c0, r1c1, r1c2, r1c3, r1c4, r1c5, r1c6, err = transform(p[1]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r2c0, r2c1, r2c2, r2c3, r2c4, r2c5, r2c6, err = transform(p[2]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r3c0, r3c1, r3c2, r3c3, r3c4, r3c5, r3c6, err = transform(p[3]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		return NewMetadataScannerStatic(t.q.QueryContext(t.ctx, query, r0c0, r0c1, r0c2, r0c3, r0c4, r0c5, r0c6, r1c0, r1c1, r1c2, r1c3, r1c4, r1c5, r1c6, r2c0, r2c1, r2c2, r2c3, r2c4, r2c5, r2c6, r3c0, r3c1, r3c2, r3c3, r3c4, r3c5, r3c6)), p[4:], true
	case 5:
		const query = `INSERT INTO "torrents_metadata" ("bytes","created_at","description","downloaded","hidden_at","id","infohash","initiated_at","paused_at","updated_at") VALUES ($1,DEFAULT,$2,$3,$4,DEFAULT,$5,$6,$7,DEFAULT),($8,DEFAULT,$9,$10,$11,DEFAULT,$12,$13,$14,DEFAULT),($15,DEFAULT,$16,$17,$18,DEFAULT,$19,$20,$21,DEFAULT),($22,DEFAULT,$23,$24,$25,DEFAULT,$26,$27,$28,DEFAULT),($29,DEFAULT,$30,$31,$32,DEFAULT,$33,$34,$35,DEFAULT) RETURNING "bytes","created_at","description","downloaded","hidden_at","id","infohash","initiated_at","paused_at","updated_at"`
		var (
			r0c0 sql.NullInt64
			r0c1 sql.NullString
			r0c2 sql.NullInt64
			r0c3 sql.NullTime
			r0c4 []byte
			r0c5 sql.NullTime
			r0c6 sql.NullTime
			r1c0 sql.NullInt64
			r1c1 sql.NullString
			r1c2 sql.NullInt64
			r1c3 sql.NullTime
			r1c4 []byte
			r1c5 sql.NullTime
			r1c6 sql.NullTime
			r2c0 sql.NullInt64
			r2c1 sql.NullString
			r2c2 sql.NullInt64
			r2c3 sql.NullTime
			r2c4 []byte
			r2c5 sql.NullTime
			r2c6 sql.NullTime
			r3c0 sql.NullInt64
			r3c1 sql.NullString
			r3c2 sql.NullInt64
			r3c3 sql.NullTime
			r3c4 []byte
			r3c5 sql.NullTime
			r3c6 sql.NullTime
			r4c0 sql.NullInt64
			r4c1 sql.NullString
			r4c2 sql.NullInt64
			r4c3 sql.NullTime
			r4c4 []byte
			r4c5 sql.NullTime
			r4c6 sql.NullTime
			err  error
		)
		if r0c0, r0c1, r0c2, r0c3, r0c4, r0c5, r0c6, err = transform(p[0]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r1c0, r1c1, r1c2, r1c3, r1c4, r1c5, r1c6, err = transform(p[1]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r2c0, r2c1, r2c2, r2c3, r2c4, r2c5, r2c6, err = transform(p[2]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r3c0, r3c1, r3c2, r3c3, r3c4, r3c5, r3c6, err = transform(p[3]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r4c0, r4c1, r4c2, r4c3, r4c4, r4c5, r4c6, err = transform(p[4]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		return NewMetadataScannerStatic(t.q.QueryContext(t.ctx, query, r0c0, r0c1, r0c2, r0c3, r0c4, r0c5, r0c6, r1c0, r1c1, r1c2, r1c3, r1c4, r1c5, r1c6, r2c0, r2c1, r2c2, r2c3, r2c4, r2c5, r2c6, r3c0, r3c1, r3c2, r3c3, r3c4, r3c5, r3c6, r4c0, r4c1, r4c2, r4c3, r4c4, r4c5, r4c6)), p[5:], true
	case 6:
		const query = `INSERT INTO "torrents_metadata" ("bytes","created_at","description","downloaded","hidden_at","id","infohash","initiated_at","paused_at","updated_at") VALUES ($1,DEFAULT,$2,$3,$4,DEFAULT,$5,$6,$7,DEFAULT),($8,DEFAULT,$9,$10,$11,DEFAULT,$12,$13,$14,DEFAULT),($15,DEFAULT,$16,$17,$18,DEFAULT,$19,$20,$21,DEFAULT),($22,DEFAULT,$23,$24,$25,DEFAULT,$26,$27,$28,DEFAULT),($29,DEFAULT,$30,$31,$32,DEFAULT,$33,$34,$35,DEFAULT),($36,DEFAULT,$37,$38,$39,DEFAULT,$40,$41,$42,DEFAULT) RETURNING "bytes","created_at","description","downloaded","hidden_at","id","infohash","initiated_at","paused_at","updated_at"`
		var (
			r0c0 sql.NullInt64
			r0c1 sql.NullString
			r0c2 sql.NullInt64
			r0c3 sql.NullTime
			r0c4 []byte
			r0c5 sql.NullTime
			r0c6 sql.NullTime
			r1c0 sql.NullInt64
			r1c1 sql.NullString
			r1c2 sql.NullInt64
			r1c3 sql.NullTime
			r1c4 []byte
			r1c5 sql.NullTime
			r1c6 sql.NullTime
			r2c0 sql.NullInt64
			r2c1 sql.NullString
			r2c2 sql.NullInt64
			r2c3 sql.NullTime
			r2c4 []byte
			r2c5 sql.NullTime
			r2c6 sql.NullTime
			r3c0 sql.NullInt64
			r3c1 sql.NullString
			r3c2 sql.NullInt64
			r3c3 sql.NullTime
			r3c4 []byte
			r3c5 sql.NullTime
			r3c6 sql.NullTime
			r4c0 sql.NullInt64
			r4c1 sql.NullString
			r4c2 sql.NullInt64
			r4c3 sql.NullTime
			r4c4 []byte
			r4c5 sql.NullTime
			r4c6 sql.NullTime
			r5c0 sql.NullInt64
			r5c1 sql.NullString
			r5c2 sql.NullInt64
			r5c3 sql.NullTime
			r5c4 []byte
			r5c5 sql.NullTime
			r5c6 sql.NullTime
			err  error
		)
		if r0c0, r0c1, r0c2, r0c3, r0c4, r0c5, r0c6, err = transform(p[0]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r1c0, r1c1, r1c2, r1c3, r1c4, r1c5, r1c6, err = transform(p[1]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r2c0, r2c1, r2c2, r2c3, r2c4, r2c5, r2c6, err = transform(p[2]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r3c0, r3c1, r3c2, r3c3, r3c4, r3c5, r3c6, err = transform(p[3]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r4c0, r4c1, r4c2, r4c3, r4c4, r4c5, r4c6, err = transform(p[4]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r5c0, r5c1, r5c2, r5c3, r5c4, r5c5, r5c6, err = transform(p[5]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		return NewMetadataScannerStatic(t.q.QueryContext(t.ctx, query, r0c0, r0c1, r0c2, r0c3, r0c4, r0c5, r0c6, r1c0, r1c1, r1c2, r1c3, r1c4, r1c5, r1c6, r2c0, r2c1, r2c2, r2c3, r2c4, r2c5, r2c6, r3c0, r3c1, r3c2, r3c3, r3c4, r3c5, r3c6, r4c0, r4c1, r4c2, r4c3, r4c4, r4c5, r4c6, r5c0, r5c1, r5c2, r5c3, r5c4, r5c5, r5c6)), p[6:], true
	case 7:
		const query = `INSERT INTO "torrents_metadata" ("bytes","created_at","description","downloaded","hidden_at","id","infohash","initiated_at","paused_at","updated_at") VALUES ($1,DEFAULT,$2,$3,$4,DEFAULT,$5,$6,$7,DEFAULT),($8,DEFAULT,$9,$10,$11,DEFAULT,$12,$13,$14,DEFAULT),($15,DEFAULT,$16,$17,$18,DEFAULT,$19,$20,$21,DEFAULT),($22,DEFAULT,$23,$24,$25,DEFAULT,$26,$27,$28,DEFAULT),($29,DEFAULT,$30,$31,$32,DEFAULT,$33,$34,$35,DEFAULT),($36,DEFAULT,$37,$38,$39,DEFAULT,$40,$41,$42,DEFAULT),($43,DEFAULT,$44,$45,$46,DEFAULT,$47,$48,$49,DEFAULT) RETURNING "bytes","created_at","description","downloaded","hidden_at","id","infohash","initiated_at","paused_at","updated_at"`
		var (
			r0c0 sql.NullInt64
			r0c1 sql.NullString
			r0c2 sql.NullInt64
			r0c3 sql.NullTime
			r0c4 []byte
			r0c5 sql.NullTime
			r0c6 sql.NullTime
			r1c0 sql.NullInt64
			r1c1 sql.NullString
			r1c2 sql.NullInt64
			r1c3 sql.NullTime
			r1c4 []byte
			r1c5 sql.NullTime
			r1c6 sql.NullTime
			r2c0 sql.NullInt64
			r2c1 sql.NullString
			r2c2 sql.NullInt64
			r2c3 sql.NullTime
			r2c4 []byte
			r2c5 sql.NullTime
			r2c6 sql.NullTime
			r3c0 sql.NullInt64
			r3c1 sql.NullString
			r3c2 sql.NullInt64
			r3c3 sql.NullTime
			r3c4 []byte
			r3c5 sql.NullTime
			r3c6 sql.NullTime
			r4c0 sql.NullInt64
			r4c1 sql.NullString
			r4c2 sql.NullInt64
			r4c3 sql.NullTime
			r4c4 []byte
			r4c5 sql.NullTime
			r4c6 sql.NullTime
			r5c0 sql.NullInt64
			r5c1 sql.NullString
			r5c2 sql.NullInt64
			r5c3 sql.NullTime
			r5c4 []byte
			r5c5 sql.NullTime
			r5c6 sql.NullTime
			r6c0 sql.NullInt64
			r6c1 sql.NullString
			r6c2 sql.NullInt64
			r6c3 sql.NullTime
			r6c4 []byte
			r6c5 sql.NullTime
			r6c6 sql.NullTime
			err  error
		)
		if r0c0, r0c1, r0c2, r0c3, r0c4, r0c5, r0c6, err = transform(p[0]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r1c0, r1c1, r1c2, r1c3, r1c4, r1c5, r1c6, err = transform(p[1]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r2c0, r2c1, r2c2, r2c3, r2c4, r2c5, r2c6, err = transform(p[2]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r3c0, r3c1, r3c2, r3c3, r3c4, r3c5, r3c6, err = transform(p[3]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r4c0, r4c1, r4c2, r4c3, r4c4, r4c5, r4c6, err = transform(p[4]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r5c0, r5c1, r5c2, r5c3, r5c4, r5c5, r5c6, err = transform(p[5]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r6c0, r6c1, r6c2, r6c3, r6c4, r6c5, r6c6, err = transform(p[6]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		return NewMetadataScannerStatic(t.q.QueryContext(t.ctx, query, r0c0, r0c1, r0c2, r0c3, r0c4, r0c5, r0c6, r1c0, r1c1, r1c2, r1c3, r1c4, r1c5, r1c6, r2c0, r2c1, r2c2, r2c3, r2c4, r2c5, r2c6, r3c0, r3c1, r3c2, r3c3, r3c4, r3c5, r3c6, r4c0, r4c1, r4c2, r4c3, r4c4, r4c5, r4c6, r5c0, r5c1, r5c2, r5c3, r5c4, r5c5, r5c6, r6c0, r6c1, r6c2, r6c3, r6c4, r6c5, r6c6)), p[7:], true
	case 8:
		const query = `INSERT INTO "torrents_metadata" ("bytes","created_at","description","downloaded","hidden_at","id","infohash","initiated_at","paused_at","updated_at") VALUES ($1,DEFAULT,$2,$3,$4,DEFAULT,$5,$6,$7,DEFAULT),($8,DEFAULT,$9,$10,$11,DEFAULT,$12,$13,$14,DEFAULT),($15,DEFAULT,$16,$17,$18,DEFAULT,$19,$20,$21,DEFAULT),($22,DEFAULT,$23,$24,$25,DEFAULT,$26,$27,$28,DEFAULT),($29,DEFAULT,$30,$31,$32,DEFAULT,$33,$34,$35,DEFAULT),($36,DEFAULT,$37,$38,$39,DEFAULT,$40,$41,$42,DEFAULT),($43,DEFAULT,$44,$45,$46,DEFAULT,$47,$48,$49,DEFAULT),($50,DEFAULT,$51,$52,$53,DEFAULT,$54,$55,$56,DEFAULT) RETURNING "bytes","created_at","description","downloaded","hidden_at","id","infohash","initiated_at","paused_at","updated_at"`
		var (
			r0c0 sql.NullInt64
			r0c1 sql.NullString
			r0c2 sql.NullInt64
			r0c3 sql.NullTime
			r0c4 []byte
			r0c5 sql.NullTime
			r0c6 sql.NullTime
			r1c0 sql.NullInt64
			r1c1 sql.NullString
			r1c2 sql.NullInt64
			r1c3 sql.NullTime
			r1c4 []byte
			r1c5 sql.NullTime
			r1c6 sql.NullTime
			r2c0 sql.NullInt64
			r2c1 sql.NullString
			r2c2 sql.NullInt64
			r2c3 sql.NullTime
			r2c4 []byte
			r2c5 sql.NullTime
			r2c6 sql.NullTime
			r3c0 sql.NullInt64
			r3c1 sql.NullString
			r3c2 sql.NullInt64
			r3c3 sql.NullTime
			r3c4 []byte
			r3c5 sql.NullTime
			r3c6 sql.NullTime
			r4c0 sql.NullInt64
			r4c1 sql.NullString
			r4c2 sql.NullInt64
			r4c3 sql.NullTime
			r4c4 []byte
			r4c5 sql.NullTime
			r4c6 sql.NullTime
			r5c0 sql.NullInt64
			r5c1 sql.NullString
			r5c2 sql.NullInt64
			r5c3 sql.NullTime
			r5c4 []byte
			r5c5 sql.NullTime
			r5c6 sql.NullTime
			r6c0 sql.NullInt64
			r6c1 sql.NullString
			r6c2 sql.NullInt64
			r6c3 sql.NullTime
			r6c4 []byte
			r6c5 sql.NullTime
			r6c6 sql.NullTime
			r7c0 sql.NullInt64
			r7c1 sql.NullString
			r7c2 sql.NullInt64
			r7c3 sql.NullTime
			r7c4 []byte
			r7c5 sql.NullTime
			r7c6 sql.NullTime
			err  error
		)
		if r0c0, r0c1, r0c2, r0c3, r0c4, r0c5, r0c6, err = transform(p[0]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r1c0, r1c1, r1c2, r1c3, r1c4, r1c5, r1c6, err = transform(p[1]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r2c0, r2c1, r2c2, r2c3, r2c4, r2c5, r2c6, err = transform(p[2]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r3c0, r3c1, r3c2, r3c3, r3c4, r3c5, r3c6, err = transform(p[3]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r4c0, r4c1, r4c2, r4c3, r4c4, r4c5, r4c6, err = transform(p[4]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r5c0, r5c1, r5c2, r5c3, r5c4, r5c5, r5c6, err = transform(p[5]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r6c0, r6c1, r6c2, r6c3, r6c4, r6c5, r6c6, err = transform(p[6]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r7c0, r7c1, r7c2, r7c3, r7c4, r7c5, r7c6, err = transform(p[7]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		return NewMetadataScannerStatic(t.q.QueryContext(t.ctx, query, r0c0, r0c1, r0c2, r0c3, r0c4, r0c5, r0c6, r1c0, r1c1, r1c2, r1c3, r1c4, r1c5, r1c6, r2c0, r2c1, r2c2, r2c3, r2c4, r2c5, r2c6, r3c0, r3c1, r3c2, r3c3, r3c4, r3c5, r3c6, r4c0, r4c1, r4c2, r4c3, r4c4, r4c5, r4c6, r5c0, r5c1, r5c2, r5c3, r5c4, r5c5, r5c6, r6c0, r6c1, r6c2, r6c3, r6c4, r6c5, r6c6, r7c0, r7c1, r7c2, r7c3, r7c4, r7c5, r7c6)), p[8:], true
	case 9:
		const query = `INSERT INTO "torrents_metadata" ("bytes","created_at","description","downloaded","hidden_at","id","infohash","initiated_at","paused_at","updated_at") VALUES ($1,DEFAULT,$2,$3,$4,DEFAULT,$5,$6,$7,DEFAULT),($8,DEFAULT,$9,$10,$11,DEFAULT,$12,$13,$14,DEFAULT),($15,DEFAULT,$16,$17,$18,DEFAULT,$19,$20,$21,DEFAULT),($22,DEFAULT,$23,$24,$25,DEFAULT,$26,$27,$28,DEFAULT),($29,DEFAULT,$30,$31,$32,DEFAULT,$33,$34,$35,DEFAULT),($36,DEFAULT,$37,$38,$39,DEFAULT,$40,$41,$42,DEFAULT),($43,DEFAULT,$44,$45,$46,DEFAULT,$47,$48,$49,DEFAULT),($50,DEFAULT,$51,$52,$53,DEFAULT,$54,$55,$56,DEFAULT),($57,DEFAULT,$58,$59,$60,DEFAULT,$61,$62,$63,DEFAULT) RETURNING "bytes","created_at","description","downloaded","hidden_at","id","infohash","initiated_at","paused_at","updated_at"`
		var (
			r0c0 sql.NullInt64
			r0c1 sql.NullString
			r0c2 sql.NullInt64
			r0c3 sql.NullTime
			r0c4 []byte
			r0c5 sql.NullTime
			r0c6 sql.NullTime
			r1c0 sql.NullInt64
			r1c1 sql.NullString
			r1c2 sql.NullInt64
			r1c3 sql.NullTime
			r1c4 []byte
			r1c5 sql.NullTime
			r1c6 sql.NullTime
			r2c0 sql.NullInt64
			r2c1 sql.NullString
			r2c2 sql.NullInt64
			r2c3 sql.NullTime
			r2c4 []byte
			r2c5 sql.NullTime
			r2c6 sql.NullTime
			r3c0 sql.NullInt64
			r3c1 sql.NullString
			r3c2 sql.NullInt64
			r3c3 sql.NullTime
			r3c4 []byte
			r3c5 sql.NullTime
			r3c6 sql.NullTime
			r4c0 sql.NullInt64
			r4c1 sql.NullString
			r4c2 sql.NullInt64
			r4c3 sql.NullTime
			r4c4 []byte
			r4c5 sql.NullTime
			r4c6 sql.NullTime
			r5c0 sql.NullInt64
			r5c1 sql.NullString
			r5c2 sql.NullInt64
			r5c3 sql.NullTime
			r5c4 []byte
			r5c5 sql.NullTime
			r5c6 sql.NullTime
			r6c0 sql.NullInt64
			r6c1 sql.NullString
			r6c2 sql.NullInt64
			r6c3 sql.NullTime
			r6c4 []byte
			r6c5 sql.NullTime
			r6c6 sql.NullTime
			r7c0 sql.NullInt64
			r7c1 sql.NullString
			r7c2 sql.NullInt64
			r7c3 sql.NullTime
			r7c4 []byte
			r7c5 sql.NullTime
			r7c6 sql.NullTime
			r8c0 sql.NullInt64
			r8c1 sql.NullString
			r8c2 sql.NullInt64
			r8c3 sql.NullTime
			r8c4 []byte
			r8c5 sql.NullTime
			r8c6 sql.NullTime
			err  error
		)
		if r0c0, r0c1, r0c2, r0c3, r0c4, r0c5, r0c6, err = transform(p[0]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r1c0, r1c1, r1c2, r1c3, r1c4, r1c5, r1c6, err = transform(p[1]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r2c0, r2c1, r2c2, r2c3, r2c4, r2c5, r2c6, err = transform(p[2]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r3c0, r3c1, r3c2, r3c3, r3c4, r3c5, r3c6, err = transform(p[3]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r4c0, r4c1, r4c2, r4c3, r4c4, r4c5, r4c6, err = transform(p[4]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r5c0, r5c1, r5c2, r5c3, r5c4, r5c5, r5c6, err = transform(p[5]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r6c0, r6c1, r6c2, r6c3, r6c4, r6c5, r6c6, err = transform(p[6]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r7c0, r7c1, r7c2, r7c3, r7c4, r7c5, r7c6, err = transform(p[7]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r8c0, r8c1, r8c2, r8c3, r8c4, r8c5, r8c6, err = transform(p[8]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		return NewMetadataScannerStatic(t.q.QueryContext(t.ctx, query, r0c0, r0c1, r0c2, r0c3, r0c4, r0c5, r0c6, r1c0, r1c1, r1c2, r1c3, r1c4, r1c5, r1c6, r2c0, r2c1, r2c2, r2c3, r2c4, r2c5, r2c6, r3c0, r3c1, r3c2, r3c3, r3c4, r3c5, r3c6, r4c0, r4c1, r4c2, r4c3, r4c4, r4c5, r4c6, r5c0, r5c1, r5c2, r5c3, r5c4, r5c5, r5c6, r6c0, r6c1, r6c2, r6c3, r6c4, r6c5, r6c6, r7c0, r7c1, r7c2, r7c3, r7c4, r7c5, r7c6, r8c0, r8c1, r8c2, r8c3, r8c4, r8c5, r8c6)), p[9:], true
	default:
		const query = `INSERT INTO "torrents_metadata" ("bytes","created_at","description","downloaded","hidden_at","id","infohash","initiated_at","paused_at","updated_at") VALUES ($1,DEFAULT,$2,$3,$4,DEFAULT,$5,$6,$7,DEFAULT),($8,DEFAULT,$9,$10,$11,DEFAULT,$12,$13,$14,DEFAULT),($15,DEFAULT,$16,$17,$18,DEFAULT,$19,$20,$21,DEFAULT),($22,DEFAULT,$23,$24,$25,DEFAULT,$26,$27,$28,DEFAULT),($29,DEFAULT,$30,$31,$32,DEFAULT,$33,$34,$35,DEFAULT),($36,DEFAULT,$37,$38,$39,DEFAULT,$40,$41,$42,DEFAULT),($43,DEFAULT,$44,$45,$46,DEFAULT,$47,$48,$49,DEFAULT),($50,DEFAULT,$51,$52,$53,DEFAULT,$54,$55,$56,DEFAULT),($57,DEFAULT,$58,$59,$60,DEFAULT,$61,$62,$63,DEFAULT),($64,DEFAULT,$65,$66,$67,DEFAULT,$68,$69,$70,DEFAULT) RETURNING "bytes","created_at","description","downloaded","hidden_at","id","infohash","initiated_at","paused_at","updated_at"`
		var (
			r0c0 sql.NullInt64
			r0c1 sql.NullString
			r0c2 sql.NullInt64
			r0c3 sql.NullTime
			r0c4 []byte
			r0c5 sql.NullTime
			r0c6 sql.NullTime
			r1c0 sql.NullInt64
			r1c1 sql.NullString
			r1c2 sql.NullInt64
			r1c3 sql.NullTime
			r1c4 []byte
			r1c5 sql.NullTime
			r1c6 sql.NullTime
			r2c0 sql.NullInt64
			r2c1 sql.NullString
			r2c2 sql.NullInt64
			r2c3 sql.NullTime
			r2c4 []byte
			r2c5 sql.NullTime
			r2c6 sql.NullTime
			r3c0 sql.NullInt64
			r3c1 sql.NullString
			r3c2 sql.NullInt64
			r3c3 sql.NullTime
			r3c4 []byte
			r3c5 sql.NullTime
			r3c6 sql.NullTime
			r4c0 sql.NullInt64
			r4c1 sql.NullString
			r4c2 sql.NullInt64
			r4c3 sql.NullTime
			r4c4 []byte
			r4c5 sql.NullTime
			r4c6 sql.NullTime
			r5c0 sql.NullInt64
			r5c1 sql.NullString
			r5c2 sql.NullInt64
			r5c3 sql.NullTime
			r5c4 []byte
			r5c5 sql.NullTime
			r5c6 sql.NullTime
			r6c0 sql.NullInt64
			r6c1 sql.NullString
			r6c2 sql.NullInt64
			r6c3 sql.NullTime
			r6c4 []byte
			r6c5 sql.NullTime
			r6c6 sql.NullTime
			r7c0 sql.NullInt64
			r7c1 sql.NullString
			r7c2 sql.NullInt64
			r7c3 sql.NullTime
			r7c4 []byte
			r7c5 sql.NullTime
			r7c6 sql.NullTime
			r8c0 sql.NullInt64
			r8c1 sql.NullString
			r8c2 sql.NullInt64
			r8c3 sql.NullTime
			r8c4 []byte
			r8c5 sql.NullTime
			r8c6 sql.NullTime
			r9c0 sql.NullInt64
			r9c1 sql.NullString
			r9c2 sql.NullInt64
			r9c3 sql.NullTime
			r9c4 []byte
			r9c5 sql.NullTime
			r9c6 sql.NullTime
			err  error
		)
		if r0c0, r0c1, r0c2, r0c3, r0c4, r0c5, r0c6, err = transform(p[0]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r1c0, r1c1, r1c2, r1c3, r1c4, r1c5, r1c6, err = transform(p[1]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r2c0, r2c1, r2c2, r2c3, r2c4, r2c5, r2c6, err = transform(p[2]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r3c0, r3c1, r3c2, r3c3, r3c4, r3c5, r3c6, err = transform(p[3]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r4c0, r4c1, r4c2, r4c3, r4c4, r4c5, r4c6, err = transform(p[4]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r5c0, r5c1, r5c2, r5c3, r5c4, r5c5, r5c6, err = transform(p[5]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r6c0, r6c1, r6c2, r6c3, r6c4, r6c5, r6c6, err = transform(p[6]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r7c0, r7c1, r7c2, r7c3, r7c4, r7c5, r7c6, err = transform(p[7]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r8c0, r8c1, r8c2, r8c3, r8c4, r8c5, r8c6, err = transform(p[8]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		if r9c0, r9c1, r9c2, r9c3, r9c4, r9c5, r9c6, err = transform(p[9]); err != nil {
			return NewMetadataScannerStatic(nil, err), []Metadata(nil), false
		}
		return NewMetadataScannerStatic(t.q.QueryContext(t.ctx, query, r0c0, r0c1, r0c2, r0c3, r0c4, r0c5, r0c6, r1c0, r1c1, r1c2, r1c3, r1c4, r1c5, r1c6, r2c0, r2c1, r2c2, r2c3, r2c4, r2c5, r2c6, r3c0, r3c1, r3c2, r3c3, r3c4, r3c5, r3c6, r4c0, r4c1, r4c2, r4c3, r4c4, r4c5, r4c6, r5c0, r5c1, r5c2, r5c3, r5c4, r5c5, r5c6, r6c0, r6c1, r6c2, r6c3, r6c4, r6c5, r6c6, r7c0, r7c1, r7c2, r7c3, r7c4, r7c5, r7c6, r8c0, r8c1, r8c2, r8c3, r8c4, r8c5, r8c6, r9c0, r9c1, r9c2, r9c3, r9c4, r9c5, r9c6)), []Metadata(nil), false
	}
}

// MetadataDeleteByID generated by genieql
func MetadataDeleteByID(ctx context.Context, q sqlx.Queryer, id string) MetadataScannerStaticRow {
	const query = `DELETE FROM torrents_metadata WHERE "id" = $1 RETURNING torrents_metadata."bytes",torrents_metadata."created_at",torrents_metadata."description",torrents_metadata."downloaded",torrents_metadata."hidden_at",torrents_metadata."id",torrents_metadata."infohash",torrents_metadata."initiated_at",torrents_metadata."paused_at",torrents_metadata."updated_at"`
	var c0 sql.NullString // id
	c0.Valid = true
	c0.String = id
	return NewMetadataScannerStaticRow(q.QueryRowContext(ctx, query, c0))
}

// MetadataFindByID generated by genieql
func MetadataFindByID(ctx context.Context, q sqlx.Queryer, id string) MetadataScannerStaticRow {
	const query = `SELECT torrents_metadata."bytes",torrents_metadata."created_at",torrents_metadata."description",torrents_metadata."downloaded",torrents_metadata."hidden_at",torrents_metadata."id",torrents_metadata."infohash",torrents_metadata."initiated_at",torrents_metadata."paused_at",torrents_metadata."updated_at" FROM torrents_metadata WHERE "id" = $1`
	var c0 sql.NullString // id
	c0.Valid = true
	c0.String = id
	return NewMetadataScannerStaticRow(q.QueryRowContext(ctx, query, c0))
}

// MetadataPausedByID generated by genieql
func MetadataPausedByID(ctx context.Context, q sqlx.Queryer, id string) MetadataScannerStaticRow {
	const query = `UPDATE torrents_metadata SET paused_at = NOW(), initiated_at = 'infinity' WHERE "id" = $1 RETURNING torrents_metadata."bytes",torrents_metadata."created_at",torrents_metadata."description",torrents_metadata."downloaded",torrents_metadata."hidden_at",torrents_metadata."id",torrents_metadata."infohash",torrents_metadata."initiated_at",torrents_metadata."paused_at",torrents_metadata."updated_at"`
	var c0 sql.NullString // id
	c0.Valid = true
	c0.String = id
	return NewMetadataScannerStaticRow(q.QueryRowContext(ctx, query, c0))
}

// MetadataDownloadByID generated by genieql
func MetadataDownloadByID(ctx context.Context, q sqlx.Queryer, id string) MetadataScannerStaticRow {
	const query = `UPDATE torrents_metadata SET paused_at = 'infinity', initiated_at = NOW() WHERE "id" = $1 RETURNING torrents_metadata."bytes",torrents_metadata."created_at",torrents_metadata."description",torrents_metadata."downloaded",torrents_metadata."hidden_at",torrents_metadata."id",torrents_metadata."infohash",torrents_metadata."initiated_at",torrents_metadata."paused_at",torrents_metadata."updated_at"`
	var c0 sql.NullString // id
	c0.Valid = true
	c0.String = id
	return NewMetadataScannerStaticRow(q.QueryRowContext(ctx, query, c0))
}

// MetadataProgressByID generated by genieql
func MetadataProgressByID(ctx context.Context, q sqlx.Queryer, id string, completed uint64) MetadataScannerStaticRow {
	const query = `UPDATE torrents_metadata SET downloaded = $2 WHERE "id" = $1 RETURNING torrents_metadata."bytes",torrents_metadata."created_at",torrents_metadata."description",torrents_metadata."downloaded",torrents_metadata."hidden_at",torrents_metadata."id",torrents_metadata."infohash",torrents_metadata."initiated_at",torrents_metadata."paused_at",torrents_metadata."updated_at"`
	var c0 sql.NullString // id
	c0.Valid = true
	c0.String = id
	return NewMetadataScannerStaticRow(q.QueryRowContext(ctx, query, c0, completed))
}

// PeerInsertWithDefaultsStaticColumns generated by genieql
const PeerInsertWithDefaultsStaticColumns = `$1,$2,$3,DEFAULT,$4,$5,$6,DEFAULT,$7,$8,DEFAULT`

// PeerInsertWithDefaultsExplode generated by genieql
func PeerInsertWithDefaultsExplode(a *Peer) ([]interface{}, error) {
	var (
		c0 sql.NullBool   // bep51
		c1 sql.NullInt64  // bep51_available
		c2 sql.NullInt32  // bep51_ttl
		c3 sql.NullString // id
		c4 sql.NullString // ip
		c5 sql.NullString // network
		c6 []byte         // peer
		c7 sql.NullInt32  // port
	)

	c0.Valid = true
	c0.Bool = a.Bep51

	c1.Valid = true
	c1.Int64 = int64(a.Bep51Available)

	c2.Valid = true
	c2.Int32 = int32(a.Bep51TTL)

	c3.Valid = true
	c3.String = a.ID

	c4.Valid = true
	c4.String = a.IP

	c5.Valid = true
	c5.String = a.Network

	c6 = a.Peer

	c7.Valid = true
	c7.Int32 = int32(a.Port)

	return []interface{}{c0, c1, c2, c3, c4, c5, c6, c7}, nil
}

// PeerInsertWithDefaults generated by genieql
func PeerInsertWithDefaults(ctx context.Context, q sqlx.Queryer, a Peer) PeerScannerStaticRow {
	const query = `INSERT INTO "torrents_peers" ("bep51","bep51_available","bep51_ttl","created_at","id","ip","network","next_check","peer","port","updated_at") VALUES ($1,$2,$3,DEFAULT,$4,$5,$6,DEFAULT,$7,$8,DEFAULT) ON CONFLICT (id) DO UPDATE SET updated_at = DEFAULT, ip = EXCLUDED.ip, port = EXCLUDED.port, bep51_available = EXCLUDED.bep51_available RETURNING "bep51","bep51_available","bep51_ttl","created_at","id","ip","network","next_check","peer","port","updated_at"`
	var (
		c0 sql.NullBool   // bep51
		c1 sql.NullInt64  // bep51_available
		c2 sql.NullInt32  // bep51_ttl
		c3 sql.NullString // id
		c4 sql.NullString // ip
		c5 sql.NullString // network
		c6 []byte         // peer
		c7 sql.NullInt32
	)
	c0.Valid = true
	c0.Bool = a.Bep51
	c1.Valid = true
	c1.Int64 = int64(a.Bep51Available)
	c2.Valid = true
	c2.Int32 = int32(a.Bep51TTL)
	c3.Valid = true
	c3.String = a.ID
	c4.Valid = true
	c4.String = a.IP
	c5.Valid = true
	c5.String = a.Network
	c6 = a.Peer
	c7.Valid = true
	c7.Int32 = int32(a.Port) // port
	return NewPeerScannerStaticRow(q.QueryRowContext(ctx, query, c0, c1, c2, c3, c4, c5, c6, c7))
}

// PeerMarkNextCheckStaticColumns generated by genieql
const PeerMarkNextCheckStaticColumns = `$1,$2,$3,DEFAULT,$4,$5,$6,DEFAULT,$7,$8,DEFAULT`

// PeerMarkNextCheckExplode generated by genieql
func PeerMarkNextCheckExplode(a *Peer) ([]interface{}, error) {
	var (
		c0 sql.NullBool   // bep51
		c1 sql.NullInt64  // bep51_available
		c2 sql.NullInt32  // bep51_ttl
		c3 sql.NullString // id
		c4 sql.NullString // ip
		c5 sql.NullString // network
		c6 []byte         // peer
		c7 sql.NullInt32  // port
	)

	c0.Valid = true
	c0.Bool = a.Bep51

	c1.Valid = true
	c1.Int64 = int64(a.Bep51Available)

	c2.Valid = true
	c2.Int32 = int32(a.Bep51TTL)

	c3.Valid = true
	c3.String = a.ID

	c4.Valid = true
	c4.String = a.IP

	c5.Valid = true
	c5.String = a.Network

	c6 = a.Peer

	c7.Valid = true
	c7.Int32 = int32(a.Port)

	return []interface{}{c0, c1, c2, c3, c4, c5, c6, c7}, nil
}

// PeerMarkNextCheck generated by genieql
func PeerMarkNextCheck(ctx context.Context, q sqlx.Queryer, a Peer) PeerScannerStaticRow {
	const query = `INSERT INTO "torrents_peers" ("bep51","bep51_available","bep51_ttl","created_at","id","ip","network","next_check","peer","port","updated_at") VALUES ($1,$2,$3,DEFAULT,$4,$5,$6,DEFAULT,$7,$8,DEFAULT) ON CONFLICT (id) DO UPDATE SET updated_at = NOW(), next_check = NOW() + to_seconds(EXCLUDED.bep51_ttl) RETURNING "bep51","bep51_available","bep51_ttl","created_at","id","ip","network","next_check","peer","port","updated_at"`
	var (
		c0 sql.NullBool   // bep51
		c1 sql.NullInt64  // bep51_available
		c2 sql.NullInt32  // bep51_ttl
		c3 sql.NullString // id
		c4 sql.NullString // ip
		c5 sql.NullString // network
		c6 []byte         // peer
		c7 sql.NullInt32
	)
	c0.Valid = true
	c0.Bool = a.Bep51
	c1.Valid = true
	c1.Int64 = int64(a.Bep51Available)
	c2.Valid = true
	c2.Int32 = int32(a.Bep51TTL)
	c3.Valid = true
	c3.String = a.ID
	c4.Valid = true
	c4.String = a.IP
	c5.Valid = true
	c5.String = a.Network
	c6 = a.Peer
	c7.Valid = true
	c7.Int32 = int32(a.Port) // port
	return NewPeerScannerStaticRow(q.QueryRowContext(ctx, query, c0, c1, c2, c3, c4, c5, c6, c7))
}

// UnknownHashInsertWithDefaultsStaticColumns generated by genieql
const UnknownHashInsertWithDefaultsStaticColumns = `$1,DEFAULT,$2,$3,$4,DEFAULT`

// UnknownHashInsertWithDefaultsExplode generated by genieql
func UnknownHashInsertWithDefaultsExplode(a *UnknownHash) ([]interface{}, error) {
	var (
		c0 sql.NullInt64  // attempts
		c1 sql.NullString // id
		c2 []byte         // infohash
		c3 sql.NullTime   // next_check
	)

	c0.Valid = true
	c0.Int64 = int64(a.Attempts)

	c1.Valid = true
	c1.String = a.ID

	c2 = a.Infohash

	c3.Valid = true
	c3.Time = a.NextCheck

	return []interface{}{c0, c1, c2, c3}, nil
}

// UnknownHashInsertWithDefaults generated by genieql
func UnknownHashInsertWithDefaults(ctx context.Context, q sqlx.Queryer, a UnknownHash) UnknownHashScannerStaticRow {
	const query = `INSERT INTO "torrents_unknown_infohashes" ("attempts","created_at","id","infohash","next_check","updated_at") VALUES ($1,DEFAULT,$2,$3,$4,DEFAULT) ON CONFLICT (id) DO UPDATE SET updated_at = DEFAULT RETURNING "attempts","created_at","id","infohash","next_check","updated_at"`
	var (
		c0 sql.NullInt64  // attempts
		c1 sql.NullString // id
		c2 []byte         // infohash
		c3 sql.NullTime
	)
	c0.Valid = true
	c0.Int64 = int64(a.Attempts)
	c1.Valid = true
	c1.String = a.ID
	c2 = a.Infohash
	c3.Valid = true
	c3.Time = a.NextCheck // next_check
	return NewUnknownHashScannerStaticRow(q.QueryRowContext(ctx, query, c0, c1, c2, c3))
}

// UnknownHashDeleteByID generated by genieql
func UnknownHashDeleteByID(ctx context.Context, q sqlx.Queryer, id string) UnknownHashScannerStaticRow {
	const query = `DELETE FROM torrents_unknown_infohashes WHERE "id" = $1 RETURNING torrents_unknown_infohashes."attempts",torrents_unknown_infohashes."created_at",torrents_unknown_infohashes."id",torrents_unknown_infohashes."infohash",torrents_unknown_infohashes."next_check",torrents_unknown_infohashes."updated_at"`
	var c0 sql.NullString // id
	c0.Valid = true
	c0.String = id
	return NewUnknownHashScannerStaticRow(q.QueryRowContext(ctx, query, c0))
}

// UnknownHashCooldownStaticColumns generated by genieql
const UnknownHashCooldownStaticColumns = `$1,DEFAULT,$2,$3,$4,DEFAULT`

// UnknownHashCooldownExplode generated by genieql
func UnknownHashCooldownExplode(a *UnknownHash) ([]interface{}, error) {
	var (
		c0 sql.NullInt64  // attempts
		c1 sql.NullString // id
		c2 []byte         // infohash
		c3 sql.NullTime   // next_check
	)

	c0.Valid = true
	c0.Int64 = int64(a.Attempts)

	c1.Valid = true
	c1.String = a.ID

	c2 = a.Infohash

	c3.Valid = true
	c3.Time = a.NextCheck

	return []interface{}{c0, c1, c2, c3}, nil
}

// UnknownHashCooldown generated by genieql
func UnknownHashCooldown(ctx context.Context, q sqlx.Queryer, a UnknownHash) UnknownHashScannerStaticRow {
	const query = `INSERT INTO "torrents_unknown_infohashes" ("attempts","created_at","id","infohash","next_check","updated_at") VALUES ($1,DEFAULT,$2,$3,$4,DEFAULT) ON CONFLICT (id) DO UPDATE SET updated_at = DEFAULT, attempts = EXCLUDED.attempts + 1, next_check = NOW() + least(to_hours(CAST(EXCLUDED.attempts AS INT)), to_hours(24)) RETURNING "attempts","created_at","id","infohash","next_check","updated_at"`
	var (
		c0 sql.NullInt64  // attempts
		c1 sql.NullString // id
		c2 []byte         // infohash
		c3 sql.NullTime
	)
	c0.Valid = true
	c0.Int64 = int64(a.Attempts)
	c1.Valid = true
	c1.String = a.ID
	c2 = a.Infohash
	c3.Valid = true
	c3.Time = a.NextCheck // next_check
	return NewUnknownHashScannerStaticRow(q.QueryRowContext(ctx, query, c0, c1, c2, c3))
}

// RSSInsertWithDefaultsStaticColumns generated by genieql
const RSSInsertWithDefaultsStaticColumns = `$1,DEFAULT,$2,$3,DEFAULT,DEFAULT,$4`

// RSSInsertWithDefaultsExplode generated by genieql
func RSSInsertWithDefaultsExplode(a *RSS) ([]interface{}, error) {
	var (
		c0 sql.NullBool   // autodownload
		c1 sql.NullString // description
		c2 sql.NullString // id
		c3 sql.NullString // url
	)

	c0.Valid = true
	c0.Bool = a.Autodownload

	c1.Valid = true
	c1.String = a.Description

	c2.Valid = true
	c2.String = a.ID

	c3.Valid = true
	c3.String = a.URL

	return []interface{}{c0, c1, c2, c3}, nil
}

// RSSInsertWithDefaults generated by genieql
func RSSInsertWithDefaults(ctx context.Context, q sqlx.Queryer, a RSS) RSSScannerStaticRow {
	const query = `INSERT INTO "torrents_feed_rss" ("autodownload","created_at","description","id","next_check","updated_at","url") VALUES ($1,DEFAULT,$2,$3,DEFAULT,DEFAULT,$4) ON CONFLICT (id) DO UPDATE SET updated_at = DEFAULT, autodownload = EXCLUDED.autodownload, url = EXCLUDED.url RETURNING "autodownload","created_at","description","id","next_check","updated_at","url"`
	var (
		c0 sql.NullBool   // autodownload
		c1 sql.NullString // description
		c2 sql.NullString // id
		c3 sql.NullString
	)
	c0.Valid = true
	c0.Bool = a.Autodownload
	c1.Valid = true
	c1.String = a.Description
	c2.Valid = true
	c2.String = a.ID
	c3.Valid = true
	c3.String = a.URL // url
	return NewRSSScannerStaticRow(q.QueryRowContext(ctx, query, c0, c1, c2, c3))
}

// RSSCooldownStaticColumns generated by genieql
const RSSCooldownStaticColumns = `$1,DEFAULT,$2,$3,$4,DEFAULT,$5`

// RSSCooldownExplode generated by genieql
func RSSCooldownExplode(a *RSS) ([]interface{}, error) {
	var (
		c0 sql.NullBool   // autodownload
		c1 sql.NullString // description
		c2 sql.NullString // id
		c3 sql.NullTime   // next_check
		c4 sql.NullString // url
	)

	c0.Valid = true
	c0.Bool = a.Autodownload

	c1.Valid = true
	c1.String = a.Description

	c2.Valid = true
	c2.String = a.ID

	c3.Valid = true
	c3.Time = a.NextCheck

	c4.Valid = true
	c4.String = a.URL

	return []interface{}{c0, c1, c2, c3, c4}, nil
}

// RSSCooldown generated by genieql
func RSSCooldown(ctx context.Context, q sqlx.Queryer, a RSS) RSSScannerStaticRow {
	const query = `INSERT INTO "torrents_feed_rss" ("autodownload","created_at","description","id","next_check","updated_at","url") VALUES ($1,DEFAULT,$2,$3,$4,DEFAULT,$5) ON CONFLICT (id) DO UPDATE SET updated_at = DEFAULT, next_check = NOW() + to_hours(24) RETURNING "autodownload","created_at","description","id","next_check","updated_at","url"`
	var (
		c0 sql.NullBool   // autodownload
		c1 sql.NullString // description
		c2 sql.NullString // id
		c3 sql.NullTime   // next_check
		c4 sql.NullString
	)
	c0.Valid = true
	c0.Bool = a.Autodownload
	c1.Valid = true
	c1.String = a.Description
	c2.Valid = true
	c2.String = a.ID
	c3.Valid = true
	c3.Time = a.NextCheck
	c4.Valid = true
	c4.String = a.URL // url
	return NewRSSScannerStaticRow(q.QueryRowContext(ctx, query, c0, c1, c2, c3, c4))
}

// RSSDeleteByID generated by genieql
func RSSDeleteByID(ctx context.Context, q sqlx.Queryer, id string) RSSScannerStaticRow {
	const query = `DELETE FROM torrents_feed_rss WHERE "id" = $1 RETURNING torrents_feed_rss."autodownload",torrents_feed_rss."created_at",torrents_feed_rss."description",torrents_feed_rss."id",torrents_feed_rss."next_check",torrents_feed_rss."updated_at",torrents_feed_rss."url"`
	var c0 sql.NullString // id
	c0.Valid = true
	c0.String = id
	return NewRSSScannerStaticRow(q.QueryRowContext(ctx, query, c0))
}
